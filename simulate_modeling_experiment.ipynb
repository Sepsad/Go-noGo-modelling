{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import seaborn as sns\n",
    "sns.set_theme(style=\"darkgrid\")\n",
    "from agent import run_experiment, Bandit, Agent\n",
    "from fitting import ML\n",
    "bandit = Bandit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "dfs = []\n",
    "for i in range(10):\n",
    "    df = run_experiment(bandit, n_runs=30, params={'alpha': 0.1, 'beta': 1, 'noise': 0, 'bias': 0, 'Pav': 0})\n",
    "    df.rename(columns={'context': 'stimulus'}, inplace=True)\n",
    "    df['ID'] = i\n",
    "    dfs.append(df)\n",
    "\n",
    "simulated_df = pd.concat(dfs).reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration:  0 Improvement:  inf Model:  [-0.57445005 -0.59570283  0.98335679  0.60266174]\n",
      "Iteration:  0 Improvement:  0.4002536441859911 Model:  [-0.91913244 -0.70152221  0.91924607  0.76418296]\n",
      "Iteration:  0 Improvement:  0.2665060371295198 Model:  [-1.18008169 -0.64979547  0.92751568  0.75051133]\n",
      "Iteration:  0 Improvement:  0.2052846768644425 Model:  [-1.37454702 -0.58536085  0.91436187  0.75007402]\n",
      "Iteration:  0 Improvement:  0.16125082046392786 Model:  [-1.52465653 -0.52659828  0.9129569   0.74633906]\n",
      "Iteration:  0 Improvement:  0.1262815208132843 Model:  [-1.6410337  -0.47770761  0.90978139  0.74460814]\n",
      "Iteration:  0 Improvement:  0.10030860628475723 Model:  [-1.73268827 -0.43758102  0.91688761  0.74382519]\n",
      "Iteration:  0 Improvement:  0.07982247185953302 Model:  [-1.80516331 -0.40493676  0.90960693  0.74324214]\n",
      "Iteration:  0 Improvement:  0.0655068565591923 Model:  [-1.86394848 -0.37779794  0.91954327  0.74369512]\n",
      "Iteration:  0 Improvement:  0.05244120685159735 Model:  [-1.91125079 -0.35555089  0.91535055  0.74344579]\n",
      "Iteration:  0 Improvement:  0.04323288371687172 Model:  [-1.9502298  -0.33688916  0.91620905  0.7442954 ]\n",
      "Iteration:  0 Improvement:  0.049850551346444484 Model:  [-1.98235166 -0.32126364  0.92463351  0.77803166]\n",
      "Iteration:  0 Improvement:  0.04895995615798913 Model:  [-2.00882832 -0.30706571  0.92881721  0.73960017]\n",
      "Iteration:  0 Improvement:  0.028834067518651838 Model:  [-2.03090452 -0.29725629  0.91401626  0.74496223]\n",
      "Iteration:  0 Improvement:  0.022772603533464025 Model:  [-2.04965367 -0.28786034  0.92288232  0.74537503]\n",
      "Iteration:  0 Improvement:  0.019247213404090337 Model:  [-2.06512584 -0.28007896  0.92305965  0.7537706 ]\n",
      "Iteration:  0 Improvement:  0.01695143006829007 Model:  [-2.07820507 -0.27313116  0.93046293  0.75013683]\n",
      "Iteration:  0 Improvement:  0.11082511974210688 Model:  [-2.08907616 -0.26769352  0.93457323  0.86021664]\n",
      "Iteration:  0 Improvement:  0.13651241281457258 Model:  [-2.09871471 -0.25903358  0.91433903  0.72583539]\n",
      "Iteration:  0 Improvement:  0.03591163939576601 Model:  [-2.10747433 -0.25834919  0.92530189  0.75888478]\n",
      "Iteration:  0 Improvement:  0.01982369091779025 Model:  [-2.11397263 -0.25458038  0.94247569  0.75243439]\n",
      "Iteration:  0 Improvement:  0.04991209695447134 Model:  [-2.11919666 -0.25206668  0.91568207  0.79414422]\n",
      "Iteration:  0 Improvement:  0.05681948990989678 Model:  [-2.12443481 -0.24778566  0.95240159  0.75131472]\n",
      "Iteration:  0 Improvement:  0.04128219970428839 Model:  [-2.1281835  -0.2472271   0.91135551  0.74906193]\n",
      "Iteration:  0 Improvement:  0.026270257620556143 Model:  [-2.13197706 -0.24546912  0.93110756  0.76586971]\n",
      "Iteration:  0 Improvement:  0.014330782726301419 Model:  [-2.13485164 -0.24345843  0.93875148  0.75426644]\n",
      "****Converged***\n",
      "Iteration:  0 Improvement:  0.008182185258806783 Model:  [-2.13714809 -0.24263271  0.94611989  0.75685471]\n",
      "iteration: 0 and result is: [-2.13714809 -0.24263271  0.94611989  0.75685471] in 27 emit\n"
     ]
    }
   ],
   "source": [
    "model = ML(simulated_df, optimization_method='L-BFGS-B', model_type='RW')\n",
    "estimated = model.fit_EM_alg(iterations=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>alpha</th>\n",
       "      <th>beta</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.101616</td>\n",
       "      <td>1.143516</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.086781</td>\n",
       "      <td>0.627951</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.081503</td>\n",
       "      <td>0.404135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.116968</td>\n",
       "      <td>0.593205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.089658</td>\n",
       "      <td>0.566921</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.121012</td>\n",
       "      <td>0.907868</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.101415</td>\n",
       "      <td>0.868270</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.092273</td>\n",
       "      <td>1.058719</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.197677</td>\n",
       "      <td>1.056669</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.097477</td>\n",
       "      <td>1.026694</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      alpha      beta\n",
       "0  0.101616  1.143516\n",
       "1  0.086781  0.627951\n",
       "2  0.081503  0.404135\n",
       "3  0.116968  0.593205\n",
       "4  0.089658  0.566921\n",
       "5  0.121012  0.907868\n",
       "6  0.101415  0.868270\n",
       "7  0.092273  1.058719\n",
       "8  0.197677  1.056669\n",
       "9  0.097477  1.026694"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "estimated_df = pd.DataFrame(estimated)\n",
    "estimated_df['alpha'] = 1/(1+np.exp(-estimated_df['alpha']))\n",
    "estimated_df['beta'] = np.exp(estimated_df['beta'])\n",
    "estimated_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/5p/j5wvkpqj2_n5r5h100pdscbr0000gn/T/ipykernel_64422/762183683.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mscipy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimize\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mminimize\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mML\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msimulated_df\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimization_method\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'L-BFGS-B'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_type\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'RW'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mestimated\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_EM_alg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterations\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/Desktop/Stuffs/Research/goNoGo/Modelling/modelling_gng/fitting.py\u001b[0m in \u001b[0;36mfit_EM_alg\u001b[0;34m(self, iterations)\u001b[0m\n\u001b[1;32m     74\u001b[0m                         \u001b[0minitial_guess\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minit\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m                     \u001b[0;31m# print(n)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 76\u001b[0;31m                     res = self.estimate_params(\n\u001b[0m\u001b[1;32m     77\u001b[0m                         g, prior=Z, initial_guess=initial_guess)\n\u001b[1;32m     78\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/Stuffs/Research/goNoGo/Modelling/modelling_gng/fitting.py\u001b[0m in \u001b[0;36mestimate_params\u001b[0;34m(self, subject_df, prior, initial_guess)\u001b[0m\n\u001b[1;32m    184\u001b[0m         \u001b[0mx0\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minitial_guess\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    185\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 186\u001b[0;31m         res = minimize(lambda params: self.neg_log_likelihood(params, subject_df=subject_df, prior=prior),\n\u001b[0m\u001b[1;32m    187\u001b[0m                        \u001b[0mx0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    188\u001b[0m                        \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimization_method\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/homebrew/lib/python3.9/site-packages/scipy/optimize/_minimize.py\u001b[0m in \u001b[0;36mminimize\u001b[0;34m(fun, x0, args, method, jac, hess, hessp, bounds, constraints, tol, callback, options)\u001b[0m\n\u001b[1;32m    621\u001b[0m                                   **options)\n\u001b[1;32m    622\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mmeth\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'l-bfgs-b'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 623\u001b[0;31m         return _minimize_lbfgsb(fun, x0, args, jac, bounds,\n\u001b[0m\u001b[1;32m    624\u001b[0m                                 callback=callback, **options)\n\u001b[1;32m    625\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mmeth\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'tnc'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/homebrew/lib/python3.9/site-packages/scipy/optimize/lbfgsb.py\u001b[0m in \u001b[0;36m_minimize_lbfgsb\u001b[0;34m(fun, x0, args, jac, bounds, disp, maxcor, ftol, gtol, eps, maxfun, maxiter, iprint, callback, maxls, finite_diff_rel_step, **unknown_options)\u001b[0m\n\u001b[1;32m    358\u001b[0m             \u001b[0;31m# until the completion of the current minimization iteration.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    359\u001b[0m             \u001b[0;31m# Overwrite f and g:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 360\u001b[0;31m             \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc_and_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    361\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mtask_str\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mb'NEW_X'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    362\u001b[0m             \u001b[0;31m# new iteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/homebrew/lib/python3.9/site-packages/scipy/optimize/_differentiable_functions.py\u001b[0m in \u001b[0;36mfun_and_grad\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    265\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray_equal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    266\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_update_x_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 267\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_update_fun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    268\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_update_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    269\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/homebrew/lib/python3.9/site-packages/scipy/optimize/_differentiable_functions.py\u001b[0m in \u001b[0;36m_update_fun\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    231\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_update_fun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    232\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf_updated\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 233\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_update_fun_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    234\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf_updated\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    235\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/homebrew/lib/python3.9/site-packages/scipy/optimize/_differentiable_functions.py\u001b[0m in \u001b[0;36mupdate_fun\u001b[0;34m()\u001b[0m\n\u001b[1;32m    135\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    136\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mupdate_fun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 137\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfun_wrapped\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    138\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    139\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_update_fun_impl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mupdate_fun\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/homebrew/lib/python3.9/site-packages/scipy/optimize/_differentiable_functions.py\u001b[0m in \u001b[0;36mfun_wrapped\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m    132\u001b[0m             \u001b[0;31m# Overwriting results in undefined behaviour because\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m             \u001b[0;31m# fun(self.x) will change self.x, with the two no longer linked.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 134\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    135\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    136\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mupdate_fun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/Stuffs/Research/goNoGo/Modelling/modelling_gng/fitting.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(params)\u001b[0m\n\u001b[1;32m    184\u001b[0m         \u001b[0mx0\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minitial_guess\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    185\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 186\u001b[0;31m         res = minimize(lambda params: self.neg_log_likelihood(params, subject_df=subject_df, prior=prior),\n\u001b[0m\u001b[1;32m    187\u001b[0m                        \u001b[0mx0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    188\u001b[0m                        \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimization_method\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/Stuffs/Research/goNoGo/Modelling/modelling_gng/fitting.py\u001b[0m in \u001b[0;36mneg_log_likelihood\u001b[0;34m(self, params, subject_df, prior)\u001b[0m\n\u001b[1;32m    171\u001b[0m             \u001b[0mla\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mq\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mq_max\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mq\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mq_max\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    172\u001b[0m             \u001b[0mp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mla\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 173\u001b[0;31m             \u001b[0mp_with_noise\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mnoise\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mnoise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    174\u001b[0m             \u001b[0mprob_log\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprob_log\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp_with_noise\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0maction\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    175\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/homebrew/lib/python3.9/site-packages/pandas/core/ops/common.py\u001b[0m in \u001b[0;36mnew_method\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m     67\u001b[0m         \u001b[0mother\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mitem_from_zerodim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mother\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 69\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mother\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     70\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mnew_method\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/homebrew/lib/python3.9/site-packages/pandas/core/arraylike.py\u001b[0m in \u001b[0;36m__mul__\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m    106\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0munpack_zerodim_and_defer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"__mul__\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__mul__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mother\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 108\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_arith_method\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mother\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moperator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmul\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    109\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0munpack_zerodim_and_defer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"__rmul__\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/homebrew/lib/python3.9/site-packages/pandas/core/series.py\u001b[0m in \u001b[0;36m_arith_method\u001b[0;34m(self, other, op)\u001b[0m\n\u001b[1;32m   5523\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5524\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merrstate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"ignore\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5525\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marithmetic_op\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5526\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5527\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_construct_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mres_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/homebrew/lib/python3.9/site-packages/pandas/core/ops/array_ops.py\u001b[0m in \u001b[0;36marithmetic_op\u001b[0;34m(left, right, op)\u001b[0m\n\u001b[1;32m    222\u001b[0m         \u001b[0m_bool_arith_check\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mleft\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mright\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    223\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 224\u001b[0;31m         \u001b[0mres_values\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_na_arithmetic_op\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mleft\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mright\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    225\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    226\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mres_values\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/homebrew/lib/python3.9/site-packages/pandas/core/ops/array_ops.py\u001b[0m in \u001b[0;36m_na_arithmetic_op\u001b[0;34m(left, right, op, is_cmp)\u001b[0m\n\u001b[1;32m    164\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    165\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 166\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mleft\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mright\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    167\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    168\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mis_object_dtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mleft\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mis_object_dtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mright\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_cmp\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/homebrew/lib/python3.9/site-packages/pandas/core/computation/expressions.py\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(op, a, b, use_numexpr)\u001b[0m\n\u001b[1;32m    237\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0muse_numexpr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    238\u001b[0m             \u001b[0;31m# error: \"None\" not callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 239\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0m_evaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop_str\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    240\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0m_evaluate_standard\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop_str\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    241\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/homebrew/lib/python3.9/site-packages/pandas/core/computation/expressions.py\u001b[0m in \u001b[0;36m_evaluate_standard\u001b[0;34m(op, op_str, a, b)\u001b[0m\n\u001b[1;32m     67\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0m_TEST_MODE\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m         \u001b[0m_store_test_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 69\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     70\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from scipy.optimize import minimize\n",
    "model = ML(simulated_df, optimization_method='L-BFGS-B', model_type='RW')\n",
    "estimated = model.fit_EM_alg(iterations=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            5     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  8.48220D+02    |proj g|=  2.08540D+03\n",
      "\n",
      "At iterate    1    f=  3.99762D+01    |proj g|=  1.69958D+02\n",
      "\n",
      "At iterate    2    f=  1.63703D+01    |proj g|=  1.00591D+02\n",
      "\n",
      "At iterate    3    f=  2.73198D+00    |proj g|=  4.96538D+01\n",
      "\n",
      "At iterate    4    f=  1.01393D+00    |proj g|=  2.20827D+01\n",
      "\n",
      "At iterate    5    f=  1.07202D-01    |proj g|=  1.03271D+01\n",
      "\n",
      "At iterate    6    f=  2.30119D-02    |proj g|=  8.24714D-01\n",
      "\n",
      "At iterate    7    f=  2.22778D-02    |proj g|=  1.74719D-01\n",
      "\n",
      "At iterate    8    f=  2.22432D-02    |proj g|=  1.18025D-01\n",
      "\n",
      "At iterate    9    f=  2.22175D-02    |proj g|=  1.05950D-01\n",
      "\n",
      "At iterate   10    f=  2.21319D-02    |proj g|=  2.88369D-01\n",
      "\n",
      "At iterate   11    f=  2.19305D-02    |proj g|=  5.83881D-01\n",
      "\n",
      "At iterate   12    f=  2.13934D-02    |proj g|=  1.06517D+00\n",
      "\n",
      "At iterate   13    f=  2.00866D-02    |proj g|=  1.76543D+00\n",
      "\n",
      "At iterate   14    f=  1.72121D-02    |proj g|=  2.62916D+00\n",
      "\n",
      "At iterate   15    f=  1.25070D-02    |proj g|=  3.20983D+00\n",
      "\n",
      "At iterate   16    f=  7.12117D-03    |proj g|=  3.34551D+00\n",
      "\n",
      "At iterate   17    f=  4.34333D-03    |proj g|=  2.35250D+00\n",
      "\n",
      "At iterate   18    f=  2.25273D-04    |proj g|=  4.22948D-01\n",
      "\n",
      "At iterate   19    f=  1.96229D-05    |proj g|=  1.19866D-01\n",
      "\n",
      "At iterate   20    f=  2.57509D-06    |proj g|=  3.79886D-02\n",
      "\n",
      "At iterate   21    f=  1.03855D-07    |proj g|=  1.27817D-02\n",
      "\n",
      "At iterate   22    f=  5.70002D-09    |proj g|=  2.12575D-03\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/5p/j5wvkpqj2_n5r5h100pdscbr0000gn/T/ipykernel_64422/1172764397.py:6: OptimizeWarning: Unknown solver options: xtol\n",
      "  res = minimize(rosen, x0, method='L-BFGS-B',\n",
      " This problem is unconstrained.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "At iterate   23    f=  4.21875D-10    |proj g|=  4.36406D-04\n",
      "\n",
      "At iterate   24    f=  1.50406D-11    |proj g|=  1.26543D-05\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    5     24     26      1     0     0   1.265D-05   1.504D-11\n",
      "  F =   1.5040599835337574E-011\n",
      "\n",
      "CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH             \n"
     ]
    }
   ],
   "source": [
    "def rosen(x):\n",
    "    return sum(100.0*(x[1:]-x[:-1]**2.0)**2.0 + (1-x[:-1])**2.0)\n",
    "\n",
    "\n",
    "x0 = np.array([1.3, 0.7, 0.8, 1.9, 1.2])\n",
    "res = minimize(rosen, x0, method='L-BFGS-B',\n",
    "            options={'xtol': 1e-8, 'disp': True})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "      fun: 1.5040599835337574e-11\n",
       " hess_inv: <5x5 LbfgsInvHessProduct with dtype=float64>\n",
       "      jac: array([ 3.72625864e-08, -1.26542701e-05,  1.17958103e-05, -1.22710527e-05,\n",
       "        5.96996087e-06])\n",
       "  message: 'CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH'\n",
       "     nfev: 156\n",
       "      nit: 24\n",
       "     njev: 26\n",
       "   status: 0\n",
       "  success: True\n",
       "        x: array([0.99999957, 0.99999915, 0.99999834, 0.99999667, 0.99999336])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simulate_model_experiment():\n",
    "    dfs = []\n",
    "\n",
    "    alphas = [ 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]\n",
    "    betas = [1, 3, 5, 7, 10, 15, 20, 25, 30, 35, 40]\n",
    "\n",
    "    for a in alphas:\n",
    "        for b in betas:\n",
    "            df = run_experiment(bandit, n_runs=30, params={'alpha': a, 'beta': b, 'noise': 0, 'bias': 0, 'Pav': 0})\n",
    "            df.rename(columns={'context': 'stimulus'}, inplace=True)\n",
    "            df['ID'] = (str(a) + '_' + str(b))\n",
    "            dfs.append(df)\n",
    "\n",
    "\n",
    "    simulated_df = pd.concat(dfs).reset_index(drop=True)\n",
    "\n",
    "    model = ML(simulated_df, optimization_method='L-BFGS-B', model_type='RW')\n",
    "    estimated = model.fit_EM_alg(iterations=1)\n",
    "    estimated_df = pd.DataFrame(estimated)\n",
    "    estimated_df['alpha'] = 1/(1+np.exp(-estimated_df['alpha']))\n",
    "    estimated_df['beta'] = np.exp(estimated_df['beta'])\n",
    "    return estimated_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sepsad/Desktop/Stuffs/Research/goNoGo/Modelling/modelling_gng/fitting.py:174: RuntimeWarning: divide by zero encountered in log\n",
      "  prob_log = prob_log + np.log(p_with_noise[action])\n",
      "/opt/homebrew/lib/python3.9/site-packages/scipy/optimize/_numdiff.py:557: RuntimeWarning: invalid value encountered in subtract\n",
      "  df = fun(x) - f0\n",
      "/Users/sepsad/Desktop/Stuffs/Research/goNoGo/Modelling/modelling_gng/fitting.py:174: RuntimeWarning: divide by zero encountered in log\n",
      "  prob_log = prob_log + np.log(p_with_noise[action])\n",
      "/opt/homebrew/lib/python3.9/site-packages/scipy/optimize/_numdiff.py:557: RuntimeWarning: invalid value encountered in subtract\n",
      "  df = fun(x) - f0\n",
      "/Users/sepsad/Desktop/Stuffs/Research/goNoGo/Modelling/modelling_gng/fitting.py:174: RuntimeWarning: divide by zero encountered in log\n",
      "  prob_log = prob_log + np.log(p_with_noise[action])\n",
      "/opt/homebrew/lib/python3.9/site-packages/scipy/optimize/_numdiff.py:557: RuntimeWarning: invalid value encountered in subtract\n",
      "  df = fun(x) - f0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration:  0 Improvement:  inf Model:  [-0.02862807  1.8702587   0.90741616  0.93252299]\n",
      "Iteration:  0 Improvement:  inf Model:  [0.01146835 1.81872531 0.86431907 0.89965876]\n",
      "Iteration:  0 Improvement:  inf Model:  [-0.01013786  1.88056476  0.90652559  0.92680204]\n",
      "Iteration:  0 Improvement:  0.4115629790652879 Model:  [-0.16483331  2.23079626  1.03310305  1.00357013]\n",
      "Iteration:  0 Improvement:  0.3645242874996006 Model:  [-0.06271621  2.1159169   1.03580738  0.99786019]\n",
      "Iteration:  0 Improvement:  0.3481827995099615 Model:  [-0.07565586  2.17436808  1.05926915  1.01216989]\n",
      "Iteration:  0 Improvement:  0.074593031600573 Model:  [-0.21720055  2.27943698  1.0275618   1.02418971]\n",
      "Iteration:  0 Improvement:  0.044630646281495004 Model:  [-0.1029424   2.20377033  1.04439723  1.02488497]\n",
      "Iteration:  0 Improvement:  0.04669816095690902 Model:  [-0.09544328  2.14101792  1.01586564  1.00691134]\n",
      "Iteration:  0 Improvement:  0.025896668315086756 Model:  [-0.23613923  2.28925243  1.04210979  1.02618394]\n",
      "Iteration:  0 Improvement:  0.014035422350832957 Model:  [-0.11323676  2.20994278  1.05142196  1.02677529]\n",
      "Iteration:  0 Improvement:  0.02321239138569664 Model:  [-0.10694742  2.14705288  1.0338168   1.01382547]\n",
      "Iteration:  0 Improvement:  0.011557546808084714 Model:  [-0.24231181  2.29057198  1.04673443  1.03468967]\n",
      "Iteration:  0 Improvement:  0.012732555498207702 Model:  [-0.11679618  2.21057484  1.06321989  1.02991502]\n",
      "****Converged***\n",
      "Iteration:  0 Improvement:  0.005297085029566908 Model:  [-0.11126363  2.14645404  1.03479185  1.0109759 ]\n",
      "iteration: 0 and result is: [-0.11126363  2.14645404  1.03479185  1.0109759 ] in 5 emit\n",
      "Iteration:  0 Improvement:  0.012508879079559639 Model:  [-0.11803568  2.20959988  1.06935354  1.04070221]\n",
      "Iteration:  0 Improvement:  0.01676568300617677 Model:  [-0.24448735  2.29008739  1.06232429  1.0404409 ]\n",
      "Iteration:  0 Improvement:  0.034916654129259005 Model:  [-0.11871314  2.20824085  1.10423569  1.04102258]\n",
      "****Converged***\n",
      "Iteration:  0 Improvement:  0.008206938406993216 Model:  [-0.24517448  2.28844938  1.05532993  1.03653225]\n",
      "iteration: 0 and result is: [-0.24517448  2.28844938  1.05532993  1.03653225] in 7 emit\n",
      "Iteration:  0 Improvement:  inf Model:  [-0.12110186  1.91926473  0.9244604   0.88373829]\n",
      "Iteration:  0 Improvement:  0.061473854370746345 Model:  [-0.11871631  2.20519668  1.04466211  1.02616472]\n",
      "Iteration:  0 Improvement:  0.4188013326398055 Model:  [-0.26053628  2.25288567  1.08301763  1.0234139 ]\n",
      "Iteration:  0 Improvement:  inf Model:  [0.00668655 1.84603928 0.89186773 0.9274803 ]\n",
      "Iteration:  0 Improvement:  0.011977919360093249 Model:  [-0.11851013  2.21049894  1.05466579  1.02226083]\n",
      "Iteration:  0 Improvement:  0.06778485729702616 Model:  [-0.31508836  2.286515    1.06134094  1.02766213]\n",
      "Iteration:  0 Improvement:  0.02679428051212327 Model:  [-0.11841834  2.21085527  1.07480159  1.03993419]\n",
      "Iteration:  0 Improvement:  0.4414116578464617 Model:  [-0.15042635  2.21091722  1.05966347  1.02165283]\n",
      "Iteration:  0 Improvement:  0.03190598204951525 Model:  [-0.33374432  2.29664309  1.08365693  1.03599069]\n",
      "Iteration:  0 Improvement:  0.014601712339897478 Model:  [-0.11882367  2.2080804   1.06437371  1.0301054 ]\n",
      "Iteration:  0 Improvement:  0.0824472544735462 Model:  [-0.20970411  2.25871994  1.03553201  1.0420555 ]\n",
      "Iteration:  0 Improvement:  0.010417756396889551 Model:  [-0.34043039  2.29676784  1.07566906  1.0359229 ]\n",
      "****Converged***\n",
      "Iteration:  0 Improvement:  0.008140156446540533 Model:  [-0.11864723  2.20910676  1.07229493  1.03166485]\n",
      "iteration: 0 and result is: [-0.11864723  2.20910676  1.07229493  1.03166485] in 12 emit\n",
      "Iteration:  0 Improvement:  0.027507849030467702 Model:  [-0.23036183  2.27080371  1.04896371  1.04392957]\n",
      "Iteration:  0 Improvement:  0.08146807878199884 Model:  [-0.34245836  2.29773745  1.09975354  1.11371707]\n",
      "****Converged***\n",
      "Iteration:  0 Improvement:  0.008175363486844785 Model:  [-0.23732583  2.2728709   1.05006267  1.04751543]\n",
      "iteration: 0 and result is: [-0.23732583  2.2728709   1.05006267  1.04751543] in 5 emit\n",
      "Iteration:  0 Improvement:  inf Model:  [-0.05523335  1.83353536  0.87203395  0.89472523]\n",
      "Iteration:  0 Improvement:  0.09774815175307522 Model:  [-0.34476372  2.28935637  1.07015705  1.02096368]\n",
      "Iteration:  0 Improvement:  0.019316254179689605 Model:  [-0.34317719  2.29834273  1.07416469  1.03751013]\n",
      "Iteration:  0 Improvement:  0.4684256948342368 Model:  [-0.23137932  2.21943016  1.04717375  0.9885681 ]\n",
      "Iteration:  0 Improvement:  inf Model:  [-0.05611165  1.86069083  0.88050589  0.88010542]\n",
      "Iteration:  0 Improvement:  0.07043355208568783 Model:  [-0.34338002  2.29813491  1.14322447  1.05135018]\n",
      "Iteration:  0 Improvement:  0.08721858552418808 Model:  [-0.29952491  2.27074774  1.03256822  0.99935905]\n",
      "Iteration:  0 Improvement:  0.08731438721922775 Model:  [-0.34445863  2.2913449   1.06009726  1.02553543]\n",
      "Iteration:  0 Improvement:  0.4047116350870716 Model:  [-0.18626153  2.18859175  1.05181044  0.98004667]\n",
      "Iteration:  0 Improvement:  0.03322453969265091 Model:  [-0.32583046  2.28474092  1.04723214  1.00038299]\n",
      "Iteration:  0 Improvement:  0.018149920159795812 Model:  [-0.34310529  2.29910831  1.07533157  1.03147122]\n",
      "Iteration:  0 Improvement:  0.06526273275928023 Model:  [-0.23569468  2.22402053  1.031076    0.99146913]\n",
      "Iteration:  0 Improvement:  0.01380991788534961 Model:  [-0.33501355  2.2875639   1.05482159  1.00677171]\n",
      "Iteration:  0 Improvement:  0.01624491925970338 Model:  [-0.34331908  2.298727    1.09122353  1.03481063]\n",
      "Iteration:  0 Improvement:  0.02868932569617002 Model:  [-0.25490398  2.23433416  1.04933922  0.99523264]\n",
      "Iteration:  0 Improvement:  0.017658902537897172 Model:  [-0.33825657  2.28754711  1.07059664  1.01401512]\n",
      "Iteration:  0 Improvement:  0.018337551081089854 Model:  [-0.34362761  2.29707329  1.08565552  1.05220123]\n",
      "****Converged***\n",
      "Iteration:  0 Improvement:  0.009820445186929622 Model:  [-0.26123488  2.23522182  1.04591338  1.00185356]\n",
      "iteration: 0 and result is: [-0.26123488  2.23522182  1.04591338  1.00185356] in 5 emit\n",
      "Iteration:  0 Improvement:  0.013719938961950262 Model:  [-0.33922362  2.28590043  1.06006048  1.00543728]\n",
      "Iteration:  0 Improvement:  0.02195767301538018 Model:  [-0.34390793  2.2956764   1.10580096  1.04358319]\n",
      "Iteration:  0 Improvement:  0.012564688849247715 Model:  [-0.33941267  2.28711599  1.07134997  1.01081368]\n",
      "Iteration:  0 Improvement:  0.024082113403747274 Model:  [-0.34401388  2.2945601   1.08506541  1.0313878 ]\n",
      "Iteration:  0 Improvement:  inf Model:  [0.01189757 1.84773486 0.88343599 0.86521163]\n",
      "****Converged***\n",
      "Iteration:  0 Improvement:  0.004465149878834694 Model:  [-0.33948677  2.2860399   1.07567949  1.01098484]\n",
      "iteration: 0 and result is: [-0.33948677  2.2860399   1.07567949  1.01098484] in 9 emit\n",
      "****Converged***\n",
      "Iteration:  0 Improvement:  0.00859455052684263 Model:  [-0.34353828  2.29712278  1.07871352  1.03655755]\n",
      "iteration: 0 and result is: [-0.34353828  2.29712278  1.07871352  1.03655755] in 16 emit\n",
      "Iteration:  0 Improvement:  0.4269879449239351 Model:  [-0.13020421  2.17919398  1.07910622  0.98342247]\n",
      "Iteration:  0 Improvement:  inf Model:  [-0.01705176  1.86656892  0.88220791  0.89042842]\n",
      "Iteration:  0 Improvement:  0.07121328175520916 Model:  [-0.18474971  2.21152519  1.04743658  0.99033955]\n",
      "Iteration:  0 Improvement:  inf Model:  [-0.05530007  1.91569717  0.84983306  0.92406229]\n",
      "Iteration:  0 Improvement:  0.028010376799989033 Model:  [-0.2053056   2.22263416  1.06243986  0.99401778]\n",
      "Iteration:  0 Improvement:  0.38915450367931637 Model:  [-0.10650732  2.19623977  1.03865373  0.99182254]\n",
      "Iteration:  0 Improvement:  0.34466210306383394 Model:  [-0.14152413  2.18940836  1.00479698  1.0355331 ]\n",
      "Iteration:  0 Improvement:  0.0136451748974806 Model:  [-0.21258029  2.22418951  1.06607328  1.00486438]\n",
      "Iteration:  0 Improvement:  0.054502361272179674 Model:  [-0.14380297  2.23117602  1.02872096  1.00795761]\n",
      "Iteration:  0 Improvement:  0.0448072918056793 Model:  [-0.17482455  2.21497897  0.9898289   1.04010211]\n",
      "Iteration:  0 Improvement:  0.013158854916481213 Model:  [-0.21513067  2.22366988  1.07301967  1.01573308]\n",
      "Iteration:  0 Improvement:  0.017437277783148603 Model:  [-0.15753445  2.23833819  1.03671681  1.00848189]\n",
      "Iteration:  0 Improvement:  0.015853068124452478 Model:  [-0.18602072  2.22130172  0.99812855  1.04423783]\n",
      "Iteration:  0 Improvement:  0.01597427427619169 Model:  [-0.21597189  2.22223241  1.08884832  1.01437025]\n",
      "Iteration:  0 Improvement:  0.010079162073909421 Model:  [-0.16220374  2.23940946  1.04311597  1.01462114]\n",
      "****Converged***\n",
      "Iteration:  0 Improvement:  0.009552544945902075 Model:  [-0.18972808  2.22183879  1.00454686  1.05023979]\n",
      "iteration: 0 and result is: [-0.18972808  2.22183879  1.00454686  1.05023979] in 5 emit\n",
      "Iteration:  0 Improvement:  0.022746002118906133 Model:  [-0.21606311  2.22079486  1.06852167  1.02447633]\n",
      "Iteration:  0 Improvement:  0.02390766651187905 Model:  [-0.16386438  2.23874882  1.06330153  1.02730678]\n",
      "Iteration:  0 Improvement:  0.0331137719818065 Model:  [-0.21620056  2.22141259  1.06373327  0.99171671]\n",
      "Iteration:  0 Improvement:  0.021889647540972074 Model:  [-0.16458007  2.23601279  1.04335301  1.0187502 ]\n",
      "Iteration:  0 Improvement:  inf Model:  [-0.03930484  1.85855142  0.87492531  0.91205297]\n",
      "Iteration:  0 Improvement:  0.017835794566196276 Model:  [-0.21613425  2.22466925  1.06436146  1.00924128]\n",
      "Iteration:  0 Improvement:  0.012627675168467772 Model:  [-0.16459402  2.23785035  1.03745942  1.00773444]\n",
      "Iteration:  0 Improvement:  0.04469511868345777 Model:  [-0.21636144  2.22373854  1.10902267  1.01069445]\n",
      "Iteration:  0 Improvement:  0.37014241865960495 Model:  [-0.15714869  2.15980455  1.01738589  1.0219155 ]\n",
      "Iteration:  0 Improvement:  0.03431709028874269 Model:  [-0.16446731  2.23957042  1.07018701  1.0179125 ]\n",
      "Iteration:  0 Improvement:  0.05535860523467437 Model:  [-0.21612002  2.21971992  1.05394823  1.00679918]\n",
      "Iteration:  0 Improvement:  0.04655038875025101 Model:  [-0.16463566  2.23637289  1.02499194  1.00723111]\n",
      "Iteration:  0 Improvement:  0.06385245623185254 Model:  [-0.20850827  2.19556494  1.00626969  1.02799452]\n",
      "Iteration:  0 Improvement:  0.012310302785381592 Model:  [-0.21614441  2.22391379  1.06310247  0.99971721]\n",
      "Iteration:  0 Improvement:  0.0154018856518071 Model:  [-0.16442602  2.24038395  1.03972004  1.00518936]\n",
      "Iteration:  0 Improvement:  0.03257237711427152 Model:  [-0.23007604  2.20721095  1.02661419  1.0347962 ]\n",
      "Iteration:  0 Improvement:  0.014867759368067104 Model:  [-0.21628208  2.22450432  1.07580736  1.00741581]\n",
      "Iteration:  0 Improvement:  0.025719195609809974 Model:  [-0.16445784  2.24004922  1.05712232  1.02412411]\n",
      "Iteration:  0 Improvement:  0.019037883830015465 Model:  [-0.23768941  2.20856454  1.03823095  1.04774597]\n",
      "Iteration:  0 Improvement:  0.012029368243460356 Model:  [-0.21633517  2.22289954  1.08722987  1.00400205]\n",
      "Iteration:  0 Improvement:  0.013833361320266392 Model:  [-0.16477763  2.2370307   1.04701209  1.01518368]\n",
      "****Converged***\n",
      "Iteration:  0 Improvement:  0.007583341844665452 Model:  [-0.24005438  2.20709504  1.04528456  1.04777955]\n",
      "iteration: 0 and result is: [-0.24005438  2.20709504  1.04528456  1.04777955] in 6 emit\n",
      "Iteration:  0 Improvement:  0.01750444809220207 Model:  [-0.21617287  2.22192977  1.07856832  1.01918153]\n",
      "****Converged***\n",
      "Iteration:  0 Improvement:  0.004657738960598857 Model:  [-0.16463111  2.2380315   1.05146515  1.01426626]\n",
      "iteration: 0 and result is: [-0.16463111  2.2380315   1.05146515  1.01426626] in 14 emit\n",
      "Iteration:  0 Improvement:  0.01559092290643168 Model:  [-0.21619823  2.22121883  1.07634019  1.00376705]\n",
      "Iteration:  0 Improvement:  inf Model:  [0.02404513 1.89083562 0.87064332 0.90823586]\n",
      "Iteration:  0 Improvement:  0.011428618724794668 Model:  [-0.21612473  2.2225535   1.08283637  1.01307437]\n",
      "Iteration:  0 Improvement:  inf Model:  [-0.03466084  1.82606364  0.92303399  0.87928902]\n",
      "Iteration:  0 Improvement:  0.025614498772859564 Model:  [-0.21617312  2.22147768  1.10696735  1.00455154]\n",
      "Iteration:  0 Improvement:  0.3755377728621553 Model:  [-0.06204628  2.18634091  1.0521644   1.02375039]\n",
      "Iteration:  0 Improvement:  0.42366327708347973 Model:  [-0.16348028  2.1803632   1.07883887  0.99371274]\n",
      "Iteration:  0 Improvement:  0.055063970561133234 Model:  [-0.21591221  2.21996751  1.05240408  0.99730295]\n",
      "Iteration:  0 Improvement:  0.05262216491661958 Model:  [-0.09847257  2.21176396  1.02451455  1.02935146]\n",
      "Iteration:  0 Improvement:  0.012073530815583551 Model:  [-0.21604523  2.2248794   1.06339506  0.99821077]\n",
      "Iteration:  0 Improvement:  0.07016732569546533 Model:  [-0.21911283  2.21856415  1.06139581  1.00176883]\n",
      "Iteration:  0 Improvement:  0.023964181084487803 Model:  [-0.1124729   2.21921013  1.04124499  1.03590278]\n",
      "****Converged***\n",
      "Iteration:  0 Improvement:  0.009657916247328624 Model:  [-0.21630786  2.22477819  1.0726849   1.00083662]\n",
      "iteration: 0 and result is: [-0.21630786  2.22477819  1.0726849   1.00083662] in 22 emit\n",
      "Iteration:  0 Improvement:  0.026169361774347966 Model:  [-0.24047676  2.22923572  1.0716611   1.00479526]\n",
      "****Converged***\n",
      "Iteration:  0 Improvement:  0.006976893140592927 Model:  [-0.11770545  2.21920044  1.03754078  1.0331503 ]\n",
      "iteration: 0 and result is: [-0.11770545  2.21920044  1.03754078  1.0331503 ] in 5 emit\n",
      "****Converged***\n",
      "Iteration:  0 Improvement:  0.009158627700348837 Model:  [-0.24830576  2.2311677   1.07174858  1.00913658]\n",
      "iteration: 0 and result is: [-0.24830576  2.2311677   1.07174858  1.00913658] in 5 emit\n",
      "Iteration:  0 Improvement:  inf Model:  [-0.04862061  1.86096912  0.86352073  0.85315668]\n",
      "Iteration:  0 Improvement:  inf Model:  [-0.0918488   1.8226246   0.9081394   0.95483464]\n",
      "Iteration:  0 Improvement:  inf Model:  [0.0057958  1.83861885 0.9089522  0.91637431]\n",
      "Iteration:  0 Improvement:  0.4238880806985578 Model:  [-0.15717077  2.19853801  1.06096603  0.97547006]\n",
      "Iteration:  0 Improvement:  0.3952721454837807 Model:  [-0.26414299  2.15568152  1.02533084  0.99835521]\n",
      "Iteration:  0 Improvement:  0.35444934538028017 Model:  [-0.08143518  2.12887454  1.06077243  1.01994722]\n",
      "Iteration:  0 Improvement:  0.062111591500683384 Model:  [-0.19914179  2.22825191  1.02800756  0.98674423]\n",
      "Iteration:  0 Improvement:  0.0931469099818014 Model:  [-0.33937735  2.20818532  1.02707527  1.01436913]\n",
      "Iteration:  0 Improvement:  0.02824800499823716 Model:  [-0.2144068   2.23777664  1.04922235  0.9916576 ]\n",
      "Iteration:  0 Improvement:  0.06851003482887888 Model:  [-0.13282531  2.17057967  1.0521461   1.03540518]\n",
      "Iteration:  0 Improvement:  0.033968779154749135 Model:  [-0.36882341  2.22129312  1.03779406  1.01468541]\n",
      "Iteration:  0 Improvement:  0.0138134307181875 Model:  [-0.21939722  2.23793775  1.06176122  0.99459995]\n",
      "Iteration:  0 Improvement:  0.020540616307441847 Model:  [-0.15097198  2.17927953  1.05606985  1.03664288]\n",
      "Iteration:  0 Improvement:  0.01395550068427515 Model:  [-0.37915316  2.22475756  1.04494219  1.01968084]\n",
      "Iteration:  0 Improvement:  0.020023268718150928 Model:  [-0.22086818  2.2368584   1.05679908  1.01391264]\n",
      "Iteration:  0 Improvement:  0.010544992011388216 Model:  [-0.1571535   2.18112614  1.06348224  1.04046809]\n",
      "Iteration:  0 Improvement:  0.017645665440814647 Model:  [-0.38276388  2.22520641  1.05177098  1.03553954]\n",
      "Iteration:  0 Improvement:  0.034696304738970785 Model:  [-0.22151951  2.23557587  1.08315134  0.99138881]\n",
      "Iteration:  0 Improvement:  0.014303642465252108 Model:  [-0.15929647  2.18078788  1.07229767  1.0515214 ]\n",
      "Iteration:  0 Improvement:  0.02362379440001984 Model:  [-0.38430889  2.22404322  1.07380337  1.0272379 ]\n",
      "Iteration:  0 Improvement:  0.03742664783038565 Model:  [-0.22119668  2.23492381  1.04576544  0.99297599]\n",
      "Iteration:  0 Improvement:  0.023526443694961107 Model:  [-0.16011952  2.17920344  1.09543486  1.0553913 ]\n",
      "Iteration:  0 Improvement:  0.030204762446662266 Model:  [-0.38396605  2.22278387  1.04397028  1.02269796]\n",
      "****Converged***\n",
      "Iteration:  0 Improvement:  0.0035357113942443537 Model:  [-0.22141979  2.23795216  1.04616254  0.99474316]\n",
      "iteration: 0 and result is: [-0.22141979  2.23795216  1.04616254  0.99474316] in 9 emit\n",
      "Iteration:  0 Improvement:  0.04117822355038302 Model:  [-0.16057143  2.17683358  1.05713008  1.04047252]\n",
      "Iteration:  0 Improvement:  0.016679710552231834 Model:  [-0.38434576  2.22508977  1.0510809   1.03760401]\n",
      "Iteration:  0 Improvement:  0.013277885859698173 Model:  [-0.16016197  2.18066702  1.06982663  1.04095952]\n",
      "Iteration:  0 Improvement:  0.03710806498420896 Model:  [-0.3848998   2.22405975  1.08809443  1.03522927]\n",
      "Iteration:  0 Improvement:  inf Model:  [0.00757674 1.90184694 0.90298466 0.8394411 ]\n",
      "Iteration:  0 Improvement:  0.010930825443741065 Model:  [-0.16031915  2.18028622  1.08024834  1.04423076]\n",
      "Iteration:  0 Improvement:  0.06196448292028774 Model:  [-0.38406191  2.22127043  1.02927368  1.01596182]\n",
      "****Converged***\n",
      "Iteration:  0 Improvement:  0.0024850622483503964 Model:  [-0.16048204  2.17913656  1.08237167  1.04479537]\n",
      "iteration: 0 and result is: [-0.16048204  2.17913656  1.08237167  1.04479537] in 11 emit\n",
      "Iteration:  0 Improvement:  0.0259152073362764 Model:  [-0.38442912  2.22639693  1.05443763  1.01941985]\n",
      "Iteration:  0 Improvement:  0.40395546997424725 Model:  [-0.0920716   2.20015214  1.09562223  1.00422887]\n",
      "****Converged***\n",
      "Iteration:  0 Improvement:  0.004398721848281493 Model:  [-0.38439932  2.22516064  1.05023001  1.01908015]\n",
      "iteration: 0 and result is: [-0.38439932  2.22516064  1.05023001  1.01908015] in 13 emit\n",
      "Iteration:  0 Improvement:  0.0564427458919154 Model:  [-0.13315228  2.21827267  1.06159516  1.00076966]\n",
      "Iteration:  0 Improvement:  inf Model:  [0.00763085 1.82693625 0.8798038  0.88742529]\n",
      "Iteration:  0 Improvement:  0.018998877431407008 Model:  [-0.14784486  2.22592407  1.0694828   1.00570186]\n",
      "Iteration:  0 Improvement:  inf Model:  [-0.01518875  1.88886835  0.87856171  0.92834967]\n",
      "Iteration:  0 Improvement:  0.40113067937132507 Model:  [-0.08091707  2.16583836  1.0352847   1.0058995 ]\n",
      "Iteration:  0 Improvement:  0.011516529834232172 Model:  [-0.15320415  2.22688164  1.07958443  1.0047279 ]\n",
      "Iteration:  0 Improvement:  0.035819859019015333 Model:  [-0.15512236  2.22658753  1.09668749  1.03614098]\n",
      "Iteration:  0 Improvement:  0.0544737747730221 Model:  [-0.11916659  2.20070923  1.01943936  1.01200803]\n",
      "Iteration:  0 Improvement:  0.384726164589121 Model:  [-0.10899589  2.19780338  1.0593435   1.03366603]\n",
      "Iteration:  0 Improvement:  0.03811504341802475 Model:  [-0.15597289  2.22288308  1.07616194  1.00425036]\n",
      "Iteration:  0 Improvement:  0.02344549951248432 Model:  [-0.13419602  2.21008958  1.03345003  1.01829437]\n",
      "Iteration:  0 Improvement:  0.05720313962685529 Model:  [-0.1480567   2.22923898  1.03485291  1.04625438]\n",
      "****Converged***\n",
      "Iteration:  0 Improvement:  0.006215446258008425 Model:  [-0.15586546  2.22632278  1.07518618  1.00933332]\n",
      "iteration: 0 and result is: [-0.15586546  2.22632278  1.07518618  1.00933332] in 8 emit\n",
      "****Converged***\n",
      "Iteration:  0 Improvement:  0.007757312985427788 Model:  [-0.13932872  2.21071149  1.03569435  1.02362425]\n",
      "iteration: 0 and result is: [-0.13932872  2.21071149  1.03569435  1.02362425] in 5 emit\n",
      "Iteration:  0 Improvement:  0.02316391842555253 Model:  [-0.16254977  2.23763167  1.05050934  1.04956452]\n",
      "Iteration:  0 Improvement:  0.011197683945893036 Model:  [-0.16768041  2.23821701  1.05955896  1.05366653]\n",
      "Iteration:  0 Improvement:  inf Model:  [0.02612312 1.79276869 0.91330109 0.86149291]\n",
      "Iteration:  0 Improvement:  inf Model:  [-0.09828645  1.8774693   0.89323036  0.89856583]\n",
      "****Converged***\n",
      "Iteration:  0 Improvement:  0.0027726049408460128 Model:  [-0.16947011  2.23743791  1.0596972   1.05563075]\n",
      "iteration: 0 and result is: [-0.16947011  2.23743791  1.0596972   1.05563075] in 6 emit\n",
      "Iteration:  0 Improvement:  0.41078640860123117 Model:  [-0.06521068  2.14343557  1.07260518  0.97130436]\n",
      "Iteration:  0 Improvement:  0.40332635927326915 Model:  [-0.23312131  2.18775491  1.07552815  1.0209671 ]\n",
      "Iteration:  0 Improvement:  inf Model:  [-0.0602249   1.913151    0.86143414  0.92121163]\n",
      "Iteration:  0 Improvement:  0.053061504224499595 Model:  [-0.10388753  2.1763404   1.06114924  0.98158338]\n",
      "Iteration:  0 Improvement:  0.062175206145747786 Model:  [-0.2829427   2.21773722  1.0543253   1.02689037]\n",
      "Iteration:  0 Improvement:  0.02255029305540845 Model:  [-0.11948146  2.18387722  1.07470093  0.98657269]\n",
      "Iteration:  0 Improvement:  0.3837695247578011 Model:  [-0.1732375   2.22431764  1.02261297  1.02939622]\n",
      "Iteration:  0 Improvement:  0.030709729232354772 Model:  [-0.30174893  2.22723764  1.07613988  1.03171519]\n",
      "Iteration:  0 Improvement:  0.011941911561123824 Model:  [-0.12508221  2.18425292  1.08485647  0.98939489]\n",
      "****Converged***\n",
      "Iteration:  0 Improvement:  0.008275116072827333 Model:  [-0.30794714  2.22776021  1.08158549  1.03207851]\n",
      "iteration: 0 and result is: [-0.30794714  2.22776021  1.08158549  1.03207851] in 5 emit\n",
      "Iteration:  0 Improvement:  0.06504543981654612 Model:  [-0.22255682  2.26007917  1.00063011  1.03542791]\n",
      "Iteration:  0 Improvement:  0.013260326950292512 Model:  [-0.12690827  2.18343902  1.09525302  0.99737932]\n",
      "Iteration:  0 Improvement:  0.026808094201231595 Model:  [-0.24107455  2.27025052  1.01705646  1.03700459]\n",
      "Iteration:  0 Improvement:  0.017174000693662345 Model:  [-0.12747421  2.18187618  1.1116126   0.99242475]\n",
      "Iteration:  0 Improvement:  inf Model:  [-0.0941336   1.91828656  0.90798072  0.94693768]\n",
      "Iteration:  0 Improvement:  0.015317114027431156 Model:  [-0.24716993  2.27151658  1.02517593  1.04840334]\n",
      "Iteration:  0 Improvement:  0.013212045283103378 Model:  [-0.1270976   2.18051876  1.10207581  0.98339018]\n",
      "Iteration:  0 Improvement:  0.025378301104299502 Model:  [-0.24937487  2.27038751  1.05014113  1.05223224]\n",
      "Iteration:  0 Improvement:  0.3869150375054047 Model:  [-0.22621383  2.23128278  1.06367328  1.04719362]\n",
      "****Converged***\n",
      "Iteration:  0 Improvement:  0.004846923409065352 Model:  [-0.12690976  2.1817633   1.1042891   0.98751448]\n",
      "iteration: 0 and result is: [-0.12690976  2.1817633   1.1042891   0.98751448] in 9 emit\n",
      "Iteration:  0 Improvement:  0.03223154824532269 Model:  [-0.24968498  2.26796307  1.02175208  1.03716703]\n",
      "Iteration:  0 Improvement:  0.0680092142015778 Model:  [-0.27525084  2.27079073  1.04180269  1.06066297]\n",
      "****Converged***\n",
      "Iteration:  0 Improvement:  0.0067616865427436055 Model:  [-0.24977508  2.27105985  1.01603586  1.03531041]\n",
      "iteration: 0 and result is: [-0.24977508  2.27105985  1.01603586  1.03531041] in 8 emit\n",
      "Iteration:  0 Improvement:  inf Model:  [-0.00294517  1.86729323  0.87337308  0.91871935]\n",
      "Iteration:  0 Improvement:  0.02721016356523784 Model:  [-0.29306709  2.28137148  1.05870483  1.06569681]\n",
      "****Converged***\n",
      "Iteration:  0 Improvement:  0.009256520382635195 Model:  [-0.29877411  2.28262226  1.06179858  1.07217581]\n",
      "iteration: 0 and result is: [-0.29877411  2.28262226  1.06179858  1.07217581] in 5 emit\n",
      "Iteration:  0 Improvement:  0.43438315098651975 Model:  [-0.12914861  2.23069841  1.05039905  1.01546591]\n",
      "Iteration:  0 Improvement:  inf Model:  [-0.04286563  1.91537727  0.91271523  0.90527432]\n",
      "Iteration:  0 Improvement:  0.07019184953169147 Model:  [-0.18067413  2.27537017  1.0442642   1.0309195 ]\n",
      "Iteration:  0 Improvement:  inf Model:  [-0.0485566   1.85316724  0.9067136   0.89538704]\n",
      "Iteration:  0 Improvement:  0.392635633003215 Model:  [-0.17255781  2.21670842  1.10777693  0.99743261]\n",
      "Iteration:  0 Improvement:  0.02361421197998094 Model:  [-0.20009297  2.28524791  1.05328688  1.03216904]\n",
      "Iteration:  0 Improvement:  0.06649154036653014 Model:  [-0.22445426  2.24426676  1.07831027  1.00743945]\n",
      "Iteration:  0 Improvement:  0.3908297796134152 Model:  [-0.1399841   2.19346152  1.04542073  0.99207762]\n",
      "Iteration:  0 Improvement:  0.012944645961122846 Model:  [-0.20671127  2.28686025  1.05374884  1.04316672]\n",
      "Iteration:  0 Improvement:  0.02711830988235004 Model:  [-0.24527212  2.25377684  1.09248647  1.00418167]\n",
      "Iteration:  0 Improvement:  0.05401698111039588 Model:  [-0.17643372  2.22983358  1.04282521  1.00818962]\n",
      "Iteration:  0 Improvement:  0.02316755802558639 Model:  [-0.20920953  2.28653476  1.06928536  1.06016687]\n",
      "Iteration:  0 Improvement:  0.04500806711036547 Model:  [-0.26887928  2.27301673  1.09875815  1.03672272]\n",
      "Iteration:  0 Improvement:  0.014215492528353512 Model:  [-0.189002    2.23588836  1.04428554  1.00588193]\n",
      "Iteration:  0 Improvement:  0.01787663668132953 Model:  [-0.21024607  2.28388199  1.07357687  1.0430483 ]\n",
      "Iteration:  0 Improvement:  0.013475370048764384 Model:  [-0.27868886  2.27482049  1.10591977  1.03117154]\n",
      "Iteration:  0 Improvement:  0.032394973151766364 Model:  [-0.19300746  2.23729967  1.05986862  1.03396335]\n",
      "Iteration:  0 Improvement:  0.014122126589942493 Model:  [-0.21001835  2.28426205  1.08726151  1.04650793]\n",
      "Iteration:  0 Improvement:  0.024844642442607857 Model:  [-0.28204656  2.27542429  1.12915601  1.03927677]\n",
      "Iteration:  0 Improvement:  0.025212705879570828 Model:  [-0.19497116  2.23438722  1.06719875  1.01009682]\n",
      "Iteration:  0 Improvement:  0.015578745065031348 Model:  [-0.20982044  2.28279804  1.07409756  1.05470703]\n",
      "Iteration:  0 Improvement:  0.03173463674231472 Model:  [-0.28327737  2.27308441  1.09892678  1.02998745]\n",
      "Iteration:  0 Improvement:  0.01737815131552486 Model:  [-0.19504517  2.23511296  1.04986508  1.01110269]\n",
      "Iteration:  0 Improvement:  0.012954879859873593 Model:  [-0.2100814   2.28312947  1.06508979  1.04540589]\n",
      "****Converged***\n",
      "Iteration:  0 Improvement:  0.008534702926015193 Model:  [-0.28357586  2.27609394  1.10589848  1.02610284]\n",
      "iteration: 0 and result is: [-0.28357586  2.27609394  1.10589848  1.02610284] in 9 emit\n",
      "Iteration:  0 Improvement:  0.022017380104364825 Model:  [-0.19500676  2.23650542  1.05303139  1.03284663]\n",
      "Iteration:  0 Improvement:  0.0257672132233738 Model:  [-0.21009536  2.28472546  1.08902657  1.03600203]\n",
      "Iteration:  0 Improvement:  0.021457821014627874 Model:  [-0.19551169  2.23491806  1.06850998  1.01807921]\n",
      "Iteration:  0 Improvement:  0.02827273594153167 Model:  [-0.20959769  2.28350144  1.06102582  1.03231967]\n",
      "Iteration:  0 Improvement:  inf Model:  [-7.33117849e-05  1.84761518e+00  8.65827545e-01  8.67049167e-01]\n",
      "Iteration:  0 Improvement:  0.01884332584088807 Model:  [-0.19539746  2.23453038  1.05199108  1.00902197]\n",
      "Iteration:  0 Improvement:  0.012637041529711497 Model:  [-0.20967578  2.28612834  1.06684191  1.04322661]\n",
      "****Converged***\n",
      "Iteration:  0 Improvement:  0.0058288863230775536 Model:  [-0.19508193  2.23640659  1.05750028  1.00909222]\n",
      "iteration: 0 and result is: [-0.19508193  2.23640659  1.05750028  1.00909222] in 11 emit\n",
      "Iteration:  0 Improvement:  0.026729910370839976 Model:  [-0.20997565  2.2852819   1.09183083  1.05267307]\n",
      "Iteration:  0 Improvement:  0.37739398668800495 Model:  [-0.09772572  2.1554005   1.02692654  0.97752786]\n",
      "Iteration:  0 Improvement:  0.0408092050819383 Model:  [-0.20991772  2.28211781  1.05473226  1.03596761]\n",
      "Iteration:  0 Improvement:  0.04747205663740826 Model:  [-0.13432137  2.18107659  1.01291161  0.98518774]\n",
      "Iteration:  0 Improvement:  inf Model:  [-1.11015689e-03  1.81831008e+00  8.03958659e-01  9.46187722e-01]\n",
      "****Converged***\n",
      "Iteration:  0 Improvement:  0.0076047763247390635 Model:  [-0.20990985  2.28619583  1.06022531  1.03264665]\n",
      "iteration: 0 and result is: [-0.20990985  2.28619583  1.06022531  1.03264665] in 16 emit\n",
      "Iteration:  0 Improvement:  0.01636295181464317 Model:  [-0.14751155  2.18709588  1.02049651  0.98524185]\n",
      "Iteration:  0 Improvement:  0.37483712032337835 Model:  [-0.09683411  2.13241058  0.96837418  1.02134227]\n",
      "Iteration:  0 Improvement:  0.01968733422157999 Model:  [-0.15185241  2.18793724  1.02913885  1.00236931]\n",
      "Iteration:  0 Improvement:  inf Model:  [0.0089144  1.86689789 0.92273257 0.92405336]\n",
      "Iteration:  0 Improvement:  0.014772178090874086 Model:  [-0.15362106  2.18626156  1.03984622  0.99248835]\n",
      "Iteration:  0 Improvement:  0.052412012350006885 Model:  [-0.13255222  2.16573743  0.95131211  1.02967544]\n",
      "Iteration:  0 Improvement:  0.01109098621711471 Model:  [-0.15367292  2.18588772  1.05092363  0.99209001]\n",
      "Iteration:  0 Improvement:  0.36860407759398073 Model:  [-0.07757057  2.17770883  1.06314627  1.03391629]\n",
      "Iteration:  0 Improvement:  0.024593183981869278 Model:  [-0.14466037  2.17277131  0.97116071  1.03351927]\n",
      "Iteration:  0 Improvement:  0.0480728845173081 Model:  [-0.15349959  2.18496584  1.03233035  1.0364117 ]\n",
      "Iteration:  0 Improvement:  0.011558022766544366 Model:  [-0.14854464  2.17271174  0.98146078  1.03704138]\n",
      "Iteration:  0 Improvement:  0.0527798944136776 Model:  [-0.11488086  2.21076452  1.04761117  1.04163913]\n",
      "Iteration:  0 Improvement:  0.05097532799483034 Model:  [-0.15489714  2.18310943  1.03358059  0.98550471]\n",
      "Iteration:  0 Improvement:  0.018163468002154567 Model:  [-0.14977339  2.1719271   0.99788382  1.04466175]\n",
      "Iteration:  0 Improvement:  0.02403356697005479 Model:  [-0.12859613  2.21840064  1.06569877  1.04364717]\n",
      "Iteration:  0 Improvement:  0.01877084780915012 Model:  [-0.15033035  2.17032155  0.97927221  1.04291105]\n",
      "Iteration:  0 Improvement:  0.015146567502174918 Model:  [-0.15390279  2.18644482  1.04243015  0.99729413]\n",
      "****Converged***\n",
      "Iteration:  0 Improvement:  0.009261589429933534 Model:  [-0.13346314  2.21874137  1.07285777  1.0469216 ]\n",
      "iteration: 0 and result is: [-0.13346314  2.21874137  1.07285777  1.0469216 ] in 5 emit\n",
      "Iteration:  0 Improvement:  0.015054461731806064 Model:  [-0.15043527  2.17139241  0.97057052  1.03067342]\n",
      "****Converged***\n",
      "Iteration:  0 Improvement:  0.005122397913249056 Model:  [-0.15385473  2.1853679   1.04679992  0.99484832]\n",
      "iteration: 0 and result is: [-0.15385473  2.1853679   1.04679992  0.99484832] in 11 emit\n",
      "Iteration:  0 Improvement:  0.032265272323795106 Model:  [-0.15014316  2.17287872  1.00162219  1.03930749]\n",
      "Iteration:  0 Improvement:  inf Model:  [-0.04071685  1.82585244  0.8682746   0.88806989]\n",
      "Iteration:  0 Improvement:  0.03230330599194623 Model:  [-0.15029106  2.1705606   0.96963335  1.03545758]\n",
      "Iteration:  0 Improvement:  inf Model:  [-0.01390549  1.84490019  0.84542559  0.9337807 ]\n",
      "Iteration:  0 Improvement:  0.4246390093342814 Model:  [-0.19429243  2.16435671  1.04335637  0.99528027]\n",
      "****Converged***\n",
      "Iteration:  0 Improvement:  0.004251577034753135 Model:  [-0.15022026  2.17251457  0.97263556  1.03316856]\n",
      "iteration: 0 and result is: [-0.15022026  2.17251457  0.97263556  1.03316856] in 11 emit\n",
      "Iteration:  0 Improvement:  0.3638352092101133 Model:  [-0.09768411  2.15754903  0.97467179  1.03819969]\n",
      "Iteration:  0 Improvement:  0.07043871659653979 Model:  [-0.25174404  2.19977876  1.02437415  1.00205362]\n",
      "Iteration:  0 Improvement:  0.04897489409152809 Model:  [-0.12900715  2.1922699   0.96746695  1.05084714]\n",
      "Iteration:  0 Improvement:  inf Model:  [-0.05993302  1.92414158  0.91675852  0.93096593]\n",
      "Iteration:  0 Improvement:  0.023166689648207433 Model:  [-0.27195531  2.20905515  1.03069896  1.00351843]\n",
      "Iteration:  0 Improvement:  0.018484896182801743 Model:  [-0.13927826  2.19853713  0.98026899  1.05659391]\n",
      "Iteration:  0 Improvement:  0.011666918577307011 Model:  [-0.27885794  2.21094339  1.03964169  1.00573941]\n",
      "Iteration:  0 Improvement:  0.35843459698119445 Model:  [-0.13873882  2.21764988  1.06798267  1.04607084]\n",
      "Iteration:  0 Improvement:  0.016139108588001726 Model:  [-0.14255664  2.19863286  0.99550498  1.06078658]\n",
      "Iteration:  0 Improvement:  0.02685105354451367 Model:  [-0.28124043  2.21076261  1.06088303  1.02198981]\n",
      "Iteration:  0 Improvement:  0.051034412093293444 Model:  [-0.17315423  2.24780672  1.04777808  1.0561916 ]\n",
      "****Converged***\n",
      "Iteration:  0 Improvement:  0.005568045102317584 Model:  [-0.14363601  2.19745844  0.99083506  1.0582077 ]\n",
      "iteration: 0 and result is: [-0.14363601  2.19745844  0.99083506  1.0582077 ] in 6 emit\n",
      "Iteration:  0 Improvement:  0.03429120913715206 Model:  [-0.28250583  2.20817124  1.03345078  1.00161723]\n",
      "Iteration:  0 Improvement:  0.027444945019351873 Model:  [-0.18559874  2.25537062  1.06964515  1.06412748]\n",
      "****Converged***\n",
      "Iteration:  0 Improvement:  0.00767395907876487 Model:  [-0.28215271  2.21118784  1.03596694  1.00820009]\n",
      "iteration: 0 and result is: [-0.28215271  2.21118784  1.03596694  1.00820009] in 8 emit\n",
      "Iteration:  0 Improvement:  inf Model:  [-0.10319809  1.86345171  0.95345373  0.92793771]\n",
      "Iteration:  0 Improvement:  0.016310325574845023 Model:  [-0.19025372  2.25498455  1.05659973  1.05552365]\n",
      "Iteration:  0 Improvement:  0.024767826756295012 Model:  [-0.19160315  2.25680152  1.08032584  1.06226119]\n",
      "Iteration:  0 Improvement:  inf Model:  [-0.01019806  1.85349796  0.91088546  0.914635  ]\n",
      "Iteration:  0 Improvement:  0.37525259779422354 Model:  [-0.22581464  2.19270885  1.0635052   1.00045049]\n",
      "****Converged***\n",
      "Iteration:  0 Improvement:  0.007408310873554437 Model:  [-0.19238845  2.25486576  1.07420164  1.05865379]\n",
      "iteration: 0 and result is: [-0.19238845  2.25486576  1.07420164  1.05865379] in 7 emit\n",
      "Iteration:  0 Improvement:  0.06846968789081602 Model:  [-0.27578384  2.23590235  1.06497075  1.01843244]\n",
      "Iteration:  0 Improvement:  0.4570058114734489 Model:  [-0.14641096  2.24774526  1.07402192  1.0054971 ]\n",
      "Iteration:  0 Improvement:  0.024250387501455046 Model:  [-0.29392676  2.2442867   1.0780968   1.0224729 ]\n",
      "Iteration:  0 Improvement:  inf Model:  [0.01475883 1.88204081 0.84371027 0.92485821]\n",
      "Iteration:  0 Improvement:  0.07413172567797915 Model:  [-0.1962392   2.29688335  1.06182125  1.02669261]\n",
      "Iteration:  0 Improvement:  0.015865919063769447 Model:  [-0.30011364  2.24524921  1.07970637  1.03696196]\n",
      "Iteration:  0 Improvement:  0.024378069342988674 Model:  [-0.21372832  2.30718584  1.07493552  1.02990131]\n",
      "Iteration:  0 Improvement:  0.37468632389941686 Model:  [-0.07438468  2.17921382  1.01755221  1.04280084]\n",
      "Iteration:  0 Improvement:  0.013996557785729622 Model:  [-0.30232953  2.24456255  1.09050405  1.02836358]\n",
      "****Converged***\n",
      "Iteration:  0 Improvement:  0.005990568735029868 Model:  [-0.21945507  2.30833816  1.07365787  1.03026322]\n",
      "iteration: 0 and result is: [-0.21945507  2.30833816  1.07365787  1.03026322] in 5 emit\n",
      "Iteration:  0 Improvement:  0.05549470288244955 Model:  [-0.11103863  2.20771843  0.98840042  1.05139215]\n",
      "****Converged***\n",
      "Iteration:  0 Improvement:  0.006858121861561147 Model:  [-0.30287351  2.24427934  1.08381347  1.02973975]\n",
      "iteration: 0 and result is: [-0.30287351  2.24427934  1.08381347  1.02973975] in 7 emit\n",
      "Iteration:  0 Improvement:  0.024218744539125762 Model:  [-0.12414     2.21530693  1.00719873  1.05337711]\n",
      "Iteration:  0 Improvement:  inf Model:  [-0.05325331  1.84694225  0.9332123   0.92165006]\n",
      "Iteration:  0 Improvement:  inf Model:  [0.01301043 1.8566687  0.8658193  0.95157298]\n",
      "****Converged***\n",
      "Iteration:  0 Improvement:  0.005645090211549277 Model:  [-0.1287857   2.21557397  1.01006521  1.05479009]\n",
      "iteration: 0 and result is: [-0.1287857   2.21557397  1.01006521  1.05479009] in 5 emit\n",
      "Iteration:  0 Improvement:  0.4331321075794601 Model:  [-0.17053159  2.22856091  1.07158139  1.01688882]\n",
      "Iteration:  0 Improvement:  0.3485114982291574 Model:  [-0.06110775  2.1450604   1.0292907   1.02950945]\n",
      "Iteration:  0 Improvement:  0.07075023005676635 Model:  [-0.21781688  2.27854317  1.06910523  1.03317805]\n",
      "Iteration:  0 Improvement:  inf Model:  [-0.04757942  1.89179725  0.85777094  0.90296169]\n",
      "Iteration:  0 Improvement:  0.04486499074440012 Model:  [-0.0914053   2.17285967  1.01433331  1.03942925]\n",
      "Iteration:  0 Improvement:  0.022785989518615577 Model:  [-0.23501688  2.28879318  1.07950549  1.0363613 ]\n",
      "Iteration:  0 Improvement:  0.407192911339692 Model:  [-0.15124209  2.20999917  1.04828339  1.03529709]\n",
      "Iteration:  0 Improvement:  0.020033595715370587 Model:  [-0.1025185   2.17949408  1.02803008  1.04622815]\n",
      "Iteration:  0 Improvement:  0.012220610427387622 Model:  [-0.24093702  2.29033378  1.07948903  1.0469406 ]\n",
      "****Converged***\n",
      "Iteration:  0 Improvement:  0.00820430470547871 Model:  [-0.10637628  2.17923028  1.02875602  1.03902874]\n",
      "iteration: 0 and result is: [-0.10637628  2.17923028  1.02875602  1.03902874] in 5 emit\n",
      "Iteration:  0 Improvement:  0.06689555991690924 Model:  [-0.20235657  2.24928678  1.03349666  1.04530518]\n",
      "Iteration:  0 Improvement:  0.02192658379820089 Model:  [-0.2430609   2.2900318   1.10070709  1.0520364 ]\n",
      "Iteration:  0 Improvement:  0.02804986810974527 Model:  [-0.22198556  2.25985274  1.0504176   1.04718675]\n",
      "Iteration:  0 Improvement:  0.01772191496030791 Model:  [-0.24378482  2.28788164  1.09063938  1.03762945]\n",
      "Iteration:  0 Improvement:  inf Model:  [-0.08191158  1.91878009  0.88617977  0.96554067]\n",
      "Iteration:  0 Improvement:  0.012852262767873933 Model:  [-0.22908039  2.26113962  1.0585379   1.05406052]\n",
      "****Converged***\n",
      "Iteration:  0 Improvement:  0.009912667386542161 Model:  [-0.24374701  2.28949402  1.08108627  1.03972654]\n",
      "iteration: 0 and result is: [-0.24374701  2.28949402  1.08108627  1.03972654] in 8 emit\n",
      "Iteration:  0 Improvement:  0.0287179365476914 Model:  [-0.23165443  2.26038705  1.07909723  1.07393114]\n",
      "Iteration:  0 Improvement:  0.4000194188899725 Model:  [-0.22955169  2.24913953  1.0270241   1.06168355]\n",
      "Iteration:  0 Improvement:  0.023535657825010894 Model:  [-0.23260883  2.25670776  1.07370978  1.0513379 ]\n",
      "Iteration:  0 Improvement:  inf Model:  [-0.10563085  1.93079524  0.86637955  0.91435305]\n",
      "Iteration:  0 Improvement:  0.07533687533065213 Model:  [-0.28755018  2.29463965  1.02168936  1.07628149]\n",
      "Iteration:  0 Improvement:  0.013748571528430144 Model:  [-0.23246657  2.25849648  1.06065988  1.05527537]\n",
      "Iteration:  0 Improvement:  0.026196215354140275 Model:  [-0.30908702  2.30630197  1.02986684  1.07186272]\n",
      "Iteration:  0 Improvement:  0.39333616991529147 Model:  [-0.23253459  2.24650272  1.02812926  1.02737785]\n",
      "Iteration:  0 Improvement:  0.012926604850612554 Model:  [-0.23269625  2.25969954  1.07352282  1.05565187]\n",
      "Iteration:  0 Improvement:  0.016902085304989472 Model:  [-0.31607295  2.30953404  1.041668    1.08119886]\n",
      "****Converged***\n",
      "Iteration:  0 Improvement:  0.009778430126258796 Model:  [-0.23270809  2.25873879  1.06989567  1.06468172]\n",
      "iteration: 0 and result is: [-0.23270809  2.25873879  1.06989567  1.06468172] in 10 emit\n",
      "Iteration:  0 Improvement:  0.06397560730624183 Model:  [-0.28304012  2.28141423  1.01188479  1.0350833 ]\n",
      "****Converged***\n",
      "Iteration:  0 Improvement:  0.008082287815387461 Model:  [-0.31835925  2.30874949  1.04744955  1.07609451]\n",
      "iteration: 0 and result is: [-0.31835925  2.30874949  1.04744955  1.07609451] in 6 emit\n",
      "Iteration:  0 Improvement:  0.02610529040989206 Model:  [-0.30208747  2.2912978   1.02637557  1.03840246]\n",
      "Iteration:  0 Improvement:  inf Model:  [-0.01164351  1.81908907  0.88301139  0.94534696]\n",
      "****Converged***\n",
      "Iteration:  0 Improvement:  0.008851349012390349 Model:  [-0.30891574  2.29284184  1.02097307  1.03878978]\n",
      "iteration: 0 and result is: [-0.30891574  2.29284184  1.02097307  1.03878978] in 5 emit\n",
      "Iteration:  0 Improvement:  inf Model:  [-0.04470983  1.83194215  0.80818886  0.90974015]\n",
      "Iteration:  0 Improvement:  0.3841302505776376 Model:  [-0.14398672  2.15374438  1.01236666  0.98160108]\n",
      "Iteration:  0 Improvement:  inf Model:  [-0.08899473  1.9024017   0.86796716  0.90723877]\n",
      "Iteration:  0 Improvement:  0.37105160339782034 Model:  [-0.12182178  2.14524266  0.96533367  1.00398099]\n",
      "Iteration:  0 Improvement:  0.06335808838772149 Model:  [-0.18980583  2.19453952  1.01037199  0.99730568]\n",
      "Iteration:  0 Improvement:  0.04957715530629664 Model:  [-0.15643665  2.17632914  0.95274681  1.01559595]\n",
      "Iteration:  0 Improvement:  0.37000410051933486 Model:  [-0.21417414  2.19696203  1.01806144  1.0165048 ]\n",
      "Iteration:  0 Improvement:  0.020756012162306298 Model:  [-0.20636891  2.20150741  1.02071866  0.99637219]\n",
      "Iteration:  0 Improvement:  0.029494779869109984 Model:  [-0.16910639  2.18301849  0.97741324  1.02309522]\n",
      "Iteration:  0 Improvement:  0.018431007496023076 Model:  [-0.21161445  2.2024222   1.03652587  1.00421322]\n",
      "Iteration:  0 Improvement:  0.05972324320499298 Model:  [-0.26300594  2.22857787  1.00557587  1.02168854]\n",
      "Iteration:  0 Improvement:  0.011925830870744359 Model:  [-0.17360508  2.18213487  0.98756338  1.02735917]\n",
      "****Converged***\n",
      "Iteration:  0 Improvement:  0.006966216263283564 Model:  [-0.21332816  2.20118114  1.04103522  0.99934321]\n",
      "iteration: 0 and result is: [-0.21332816  2.20118114  1.04103522  0.99934321] in 6 emit\n",
      "Iteration:  0 Improvement:  0.037846581372598595 Model:  [-0.29249523  2.24621425  1.02011996  1.02802672]\n",
      "Iteration:  0 Improvement:  0.024326645461819122 Model:  [-0.17515246  2.1810545   1.00969151  1.03728742]\n",
      "Iteration:  0 Improvement:  0.010708662923870323 Model:  [-0.30243298  2.2492164   1.0190142   1.03041022]\n",
      "Iteration:  0 Improvement:  0.02868000239936674 Model:  [-0.17581738  2.17850743  0.98688315  1.02010045]\n",
      "Iteration:  0 Improvement:  inf Model:  [-0.04698857  1.92586907  0.87205563  0.93172478]\n",
      "****Converged***\n",
      "Iteration:  0 Improvement:  0.009824131145882443 Model:  [-0.30568609  2.25016814  1.02823386  1.03056129]\n",
      "iteration: 0 and result is: [-0.30568609  2.25016814  1.02823386  1.03056129] in 6 emit\n",
      "****Converged***\n",
      "Iteration:  0 Improvement:  0.007073037439380036 Model:  [-0.17555892  2.18110773  0.98031053  1.02008505]\n",
      "iteration: 0 and result is: [-0.17555892  2.18110773  0.98031053  1.02008505] in 8 emit\n",
      "Iteration:  0 Improvement:  0.38442096123993813 Model:  [-0.14986263  2.23832139  1.01703054  1.06793135]\n",
      "Iteration:  0 Improvement:  inf Model:  [-0.04541707  1.83504025  0.8485456   0.89453375]\n",
      "Iteration:  0 Improvement:  inf Model:  [-0.04024846  1.84989118  0.85771698  0.89308659]\n",
      "Iteration:  0 Improvement:  0.05538112742504391 Model:  [-0.19152902  2.27126167  1.00256556  1.07398799]\n",
      "Iteration:  0 Improvement:  0.400001519748727 Model:  [-0.12794244  2.18388566  0.99444591  0.99558201]\n",
      "Iteration:  0 Improvement:  0.020412860423072988 Model:  [-0.20495116  2.27896964  1.01481947  1.07918029]\n",
      "Iteration:  0 Improvement:  0.4137908954765284 Model:  [-0.17605675  2.19423875  1.00676552  1.0025777 ]\n",
      "****Converged***\n",
      "Iteration:  0 Improvement:  0.006741427847122319 Model:  [-0.20968517  2.27940755  1.01031477  1.08077773]\n",
      "iteration: 0 and result is: [-0.20968517  2.27940755  1.01031477  1.08077773] in 5 emit\n",
      "Iteration:  0 Improvement:  0.052599509922969294 Model:  [-0.16105671  2.2220106   0.98876346  1.00915967]\n",
      "Iteration:  0 Improvement:  0.07299455289764385 Model:  [-0.22922643  2.23726953  0.98775784  1.0195556 ]\n",
      "Iteration:  0 Improvement:  0.02221655865988097 Model:  [-0.17308762  2.22942374  1.00423023  1.01655271]\n",
      "Iteration:  0 Improvement:  0.028320524824547427 Model:  [-0.24878248  2.24792514  1.00495896  1.02274819]\n",
      "Iteration:  0 Improvement:  inf Model:  [-0.02740205  1.81621887  0.88113871  0.92066827]\n",
      "****Converged***\n",
      "Iteration:  0 Improvement:  0.005050228255519085 Model:  [-0.1769406   2.22927184  1.00641773  1.0141338 ]\n",
      "iteration: 0 and result is: [-0.1769406   2.22927184  1.00641773  1.0141338 ] in 5 emit\n",
      "****Converged***\n",
      "Iteration:  0 Improvement:  0.009586461843077234 Model:  [-0.25521898  2.24945236  1.00815681  1.02890555]\n",
      "iteration: 0 and result is: [-0.25521898  2.24945236  1.00815681  1.02890555] in 5 emit\n",
      "Iteration:  0 Improvement:  0.4427372122481199 Model:  [-0.1647528   2.1976743   1.02935889  1.01902241]\n",
      "Iteration:  0 Improvement:  inf Model:  [-0.04220828  1.80007267  0.88730763  0.94964453]\n",
      "Iteration:  0 Improvement:  0.07590789267793877 Model:  [-0.2172157   2.24653233  1.02082171  1.04246729]\n",
      "Iteration:  0 Improvement:  inf Model:  [0.02218718 1.88100336 0.90153303 0.91552874]\n",
      "Iteration:  0 Improvement:  0.4013769187254793 Model:  [-0.14670485  2.16094671  1.01208468  1.01586016]\n",
      "Iteration:  0 Improvement:  0.02476828632930424 Model:  [-0.23630937  2.25697786  1.03263173  1.0419064 ]\n",
      "Iteration:  0 Improvement:  0.3606351356966419 Model:  [-0.08209754  2.17914687  1.04785943  1.00977007]\n",
      "Iteration:  0 Improvement:  0.07085810447077345 Model:  [-0.19366842  2.21003648  1.01307778  1.0359724 ]\n",
      "Iteration:  0 Improvement:  0.011205984937421852 Model:  [-0.24243046  2.25895507  1.03394101  1.0509884 ]\n",
      "Iteration:  0 Improvement:  0.05410726345067278 Model:  [-0.12243874  2.20958812  1.03175035  1.02044769]\n",
      "Iteration:  0 Improvement:  0.011384722381620692 Model:  [-0.24450789  2.25867576  1.03971707  1.06057252]\n",
      "Iteration:  0 Improvement:  0.026909625825056557 Model:  [-0.21250953  2.21952839  1.02884523  1.04148892]\n",
      "Iteration:  0 Improvement:  0.028679159939840382 Model:  [-0.14141414  2.21709808  1.05164188  1.02366573]\n",
      "Iteration:  0 Improvement:  0.03194520912897836 Model:  [-0.24514711  2.25732059  1.07096416  1.06704326]\n",
      "****Converged***\n",
      "Iteration:  0 Improvement:  0.00702927608792473 Model:  [-0.21910317  2.22038101  1.02859309  1.03922086]\n",
      "iteration: 0 and result is: [-0.21910317  2.22038101  1.02859309  1.03922086] in 5 emit\n",
      "****Converged***\n",
      "Iteration:  0 Improvement:  0.00667806685899939 Model:  [-0.14783493  2.21733048  1.05319716  1.02271855]\n",
      "iteration: 0 and result is: [-0.14783493  2.21733048  1.05319716  1.02271855] in 5 emit\n",
      "Iteration:  0 Improvement:  0.04484144680659264 Model:  [-0.24477155  2.25376246  1.03724589  1.03769991]\n",
      "Iteration:  0 Improvement:  inf Model:  [-0.01197045  1.86683154  0.85238122  0.86546437]\n",
      "Iteration:  0 Improvement:  0.015244127603263503 Model:  [-0.24472834  2.25874477  1.03599515  1.05205239]\n",
      "Iteration:  0 Improvement:  inf Model:  [-0.05040178  1.88897308  0.87185447  0.90344664]\n",
      "Iteration:  0 Improvement:  0.04738481575483858 Model:  [-0.24517217  2.25846588  1.08312578  1.05692579]\n",
      "Iteration:  0 Improvement:  0.3895027213435354 Model:  [-0.13201941  2.17599332  1.02006591  0.98208965]\n",
      "Iteration:  0 Improvement:  0.3948696326481867 Model:  [-0.15658569  2.19974048  1.0543032   1.02503237]\n",
      "Iteration:  0 Improvement:  0.06495983148207471 Model:  [-0.24447708  2.25387555  1.02059764  1.03994174]\n",
      "Iteration:  0 Improvement:  0.07871724635712854 Model:  [-0.19215599  2.21970298  1.00728139  1.00458451]\n",
      "Iteration:  0 Improvement:  0.01433958840385516 Model:  [-0.24498569  2.26002551  1.03354112  1.04003953]\n",
      "Iteration:  0 Improvement:  0.0733560585666269 Model:  [-0.21139435  2.24062307  1.03417632  1.04237147]\n",
      "Iteration:  0 Improvement:  0.024782018272300414 Model:  [-0.21318075  2.22877063  1.01640827  1.00201822]\n",
      "Iteration:  0 Improvement:  0.03538452030712272 Model:  [-0.24519732  2.26007987  1.0607699   1.06263622]\n",
      "Iteration:  0 Improvement:  0.024653299352494856 Model:  [-0.23054797  2.25086544  1.04471548  1.04736587]\n",
      "Iteration:  0 Improvement:  0.01934510777238969 Model:  [-0.21986417  2.23073542  1.0278675   1.01596062]\n",
      "Iteration:  0 Improvement:  0.04049035618875736 Model:  [-0.2450608   2.25559236  1.02374841  1.0468653 ]\n",
      "****Converged***\n",
      "Iteration:  0 Improvement:  0.008358335507362619 Model:  [-0.23713139  2.25239429  1.04594299  1.05212782]\n",
      "iteration: 0 and result is: [-0.23713139  2.25239429  1.04594299  1.05212782] in 5 emit\n",
      "Iteration:  0 Improvement:  0.013279163778633767 Model:  [-0.22210823  2.22929547  1.03797104  1.02415485]\n",
      "Iteration:  0 Improvement:  0.018288923458111513 Model:  [-0.24528752  2.25944901  1.04158684  1.0457034 ]\n",
      "****Converged***\n",
      "Iteration:  0 Improvement:  0.006205085522376482 Model:  [-0.22277816  2.22768969  1.03237773  1.02620193]\n",
      "iteration: 0 and result is: [-0.22277816  2.22768969  1.03237773  1.02620193] in 7 emit\n",
      "****Converged***\n",
      "Iteration:  0 Improvement:  0.008320641058568482 Model:  [-0.24518905  2.25873132  1.04377488  1.05369844]\n",
      "iteration: 0 and result is: [-0.24518905  2.25873132  1.04377488  1.05369844] in 16 emit\n",
      "Iteration:  0 Improvement:  inf Model:  [-0.05004182  1.90540658  0.89102283  0.91088895]\n",
      "Iteration:  0 Improvement:  inf Model:  [-0.01021319  1.92723001  0.87022614  0.95993575]\n",
      "Iteration:  0 Improvement:  0.4048169523418632 Model:  [-0.13947509  2.24986342  1.04470439  1.02755052]\n",
      "Iteration:  0 Improvement:  inf Model:  [-0.07926081  1.91552103  0.89194076  0.9265642 ]\n",
      "Iteration:  0 Improvement:  0.05483995678730877 Model:  [-0.17433237  2.28630387  1.02793537  1.04108876]\n",
      "Iteration:  0 Improvement:  0.3429922940041732 Model:  [-0.0670533   2.22069613  1.00097399  1.06574478]\n",
      "Iteration:  0 Improvement:  0.3851502991620565 Model:  [-0.21126622  2.22141067  1.0679181   1.00643177]\n",
      "Iteration:  0 Improvement:  0.02270369604494175 Model:  [-0.18606168  2.2939525   1.04400555  1.04890725]\n",
      "Iteration:  0 Improvement:  0.04415532231296393 Model:  [-0.09305258  2.25340739  0.99225017  1.07704077]\n",
      "Iteration:  0 Improvement:  0.06376187858599712 Model:  [-0.26157075  2.25619513  1.05529114  1.01930161]\n",
      "****Converged***\n",
      "Iteration:  0 Improvement:  0.004151449995307743 Model:  [-0.19007135  2.29383179  1.04373863  1.0499423 ]\n",
      "iteration: 0 and result is: [-0.19007135  2.29383179  1.04373863  1.0499423 ] in 5 emit\n",
      "Iteration:  0 Improvement:  0.014480878383569654 Model:  [-0.10240561  2.25967743  1.0010481   1.07938587]\n",
      "Iteration:  0 Improvement:  0.025486550889832104 Model:  [-0.28147782  2.26557571  1.06804707  1.01770049]\n",
      "Iteration:  0 Improvement:  0.018222090205449914 Model:  [-0.10572664  2.26027589  1.01390533  1.09184977]\n",
      "Iteration:  0 Improvement:  0.014745663954721233 Model:  [-0.28835666  2.26724494  1.07270942  1.02976666]\n",
      "Iteration:  0 Improvement:  inf Model:  [-0.01179875  1.89848276  0.88966589  0.89174135]\n",
      "****Converged***\n",
      "Iteration:  0 Improvement:  0.005835105523310204 Model:  [-0.10722563  2.25857417  1.01021274  1.08794204]\n",
      "iteration: 0 and result is: [-0.10722563  2.25857417  1.01021274  1.08794204] in 6 emit\n",
      "Iteration:  0 Improvement:  0.013895042668812385 Model:  [-0.29107925  2.26667972  1.08311846  1.03854117]\n",
      "Iteration:  0 Improvement:  0.38462271231166606 Model:  [-0.12262677  2.20934222  1.06243284  0.98750022]\n",
      "Iteration:  0 Improvement:  0.010201786091030333 Model:  [-0.29200105  2.26514706  1.08037406  1.0288796 ]\n",
      "Iteration:  0 Improvement:  inf Model:  [-0.00480321  1.86842407  0.88557682  0.90454794]\n",
      "Iteration:  0 Improvement:  0.061162811746487834 Model:  [-0.16497407  2.24090126  1.03462873  1.00086262]\n",
      "Iteration:  0 Improvement:  0.08657495548048509 Model:  [-0.29204158  2.26579339  1.1662101   1.04014808]\n",
      "Iteration:  0 Improvement:  0.3689948677237277 Model:  [-0.1084112   2.16481378  1.04306221  1.01757045]\n",
      "Iteration:  0 Improvement:  0.025143807941669934 Model:  [-0.18138332  2.24947721  1.05154994  0.99910955]\n",
      "Iteration:  0 Improvement:  0.12062851773643582 Model:  [-0.29029694  2.25733899  1.04813644  1.01701086]\n",
      "Iteration:  0 Improvement:  0.014902243792079673 Model:  [-0.1869025   2.25038832  1.06046768  1.00965751]\n",
      "Iteration:  0 Improvement:  0.054176337555280465 Model:  [-0.14932732  2.19348031  1.02473295  1.02772995]\n",
      "Iteration:  0 Improvement:  0.026189362559267397 Model:  [-0.29148727  2.26817439  1.07190404  1.01848102]\n",
      "Iteration:  0 Improvement:  0.018669159145902496 Model:  [-0.18897964  2.24924595  1.07133689  1.02465012]\n",
      "Iteration:  0 Improvement:  0.024151833278021 Model:  [-0.16368574  2.20053019  1.04281116  1.02693977]\n",
      "****Converged***\n",
      "Iteration:  0 Improvement:  0.009248785127133428 Model:  [-0.29185804  2.26784099  1.07403429  1.02746731]\n",
      "iteration: 0 and result is: [-0.29185804  2.26784099  1.07403429  1.02746731] in 11 emit\n",
      "Iteration:  0 Improvement:  0.0169399002179071 Model:  [-0.18990027  2.24712189  1.06770484  1.00826692]\n",
      "****Converged***\n",
      "Iteration:  0 Improvement:  0.0052557765433103336 Model:  [-0.16858731  2.20106188  1.04397389  1.0283409 ]\n",
      "iteration: 0 and result is: [-0.16858731  2.20106188  1.04397389  1.0283409 ] in 5 emit\n",
      "Iteration:  0 Improvement:  0.024798551940362963 Model:  [-0.18973295  2.24827016  1.09057597  1.0177818 ]\n",
      "Iteration:  0 Improvement:  inf Model:  [-0.07900382  1.94288822  0.87899436  0.89834079]\n",
      "Iteration:  0 Improvement:  0.029558370347842415 Model:  [-0.18964927  2.24589639  1.06373783  1.00562575]\n",
      "Iteration:  0 Improvement:  inf Model:  [-0.05264804  1.85388402  0.8940973   0.90893513]\n",
      "Iteration:  0 Improvement:  0.3718287812234166 Model:  [-0.19858639  2.23358514  1.02378608  1.03430885]\n",
      "****Converged***\n",
      "Iteration:  0 Improvement:  0.007995951650655508 Model:  [-0.18956561  2.24855812  1.06881683  1.00005376]\n",
      "iteration: 0 and result is: [-0.18956561  2.24855812  1.06881683  1.00005376] in 10 emit\n",
      "Iteration:  0 Improvement:  0.4598822014975664 Model:  [-0.22358208  2.21993468  1.08239959  1.02217097]\n",
      "Iteration:  0 Improvement:  0.05704450847773481 Model:  [-0.24564611  2.26251421  1.00961368  1.03561692]\n",
      "Iteration:  0 Improvement:  0.08656424999001386 Model:  [-0.29549239  2.26159037  1.05892254  1.02816329]\n",
      "Iteration:  0 Improvement:  inf Model:  [-0.03325154  1.88221553  0.89051701  0.87133865]\n",
      "Iteration:  0 Improvement:  0.022145181093286025 Model:  [-0.2620793   2.27126664  1.02149967  1.03719092]\n",
      "****Converged***\n",
      "Iteration:  0 Improvement:  0.007108399988836016 Model:  [-0.2675654   2.27262942  1.01839279  1.04017792]\n",
      "iteration: 0 and result is: [-0.2675654   2.27262942  1.01839279  1.04017792] in 5 emit\n",
      "Iteration:  0 Improvement:  0.03275730898540312 Model:  [-0.32407467  2.27476897  1.06799189  1.02775595]\n",
      "Iteration:  0 Improvement:  0.3825584839463324 Model:  [-0.15365786  2.17802753  1.05335024  1.00488233]\n",
      "Iteration:  0 Improvement:  0.01154237253422842 Model:  [-0.33482338  2.27825012  1.06771537  1.03010044]\n",
      "Iteration:  0 Improvement:  0.06016245278901777 Model:  [-0.20074834  2.20528547  1.02808128  1.00940906]\n",
      "Iteration:  0 Improvement:  inf Model:  [-0.03214764  1.88368644  0.86035698  0.92155681]\n",
      "****Converged***\n",
      "Iteration:  0 Improvement:  0.008848856051185046 Model:  [-0.33888335  2.27945083  1.07547023  1.03058976]\n",
      "iteration: 0 and result is: [-0.33888335  2.27945083  1.07547023  1.03058976] in 6 emit\n",
      "Iteration:  0 Improvement:  0.02229456098658784 Model:  [-0.21695203  2.21408096  1.03994207  1.0134648 ]\n",
      "Iteration:  0 Improvement:  0.33339290570682667 Model:  [-0.11380216  2.14926409  1.01515575  1.02150291]\n",
      "Iteration:  0 Improvement:  0.014512875123376968 Model:  [-0.22244055  2.21510467  1.03988249  1.02686063]\n",
      "Iteration:  0 Improvement:  inf Model:  [-0.00305237  1.83742741  0.92378548  0.8434268 ]\n",
      "Iteration:  0 Improvement:  0.048702987453423836 Model:  [-0.15009     2.17415649  0.99512868  1.02737308]\n",
      "Iteration:  0 Improvement:  0.020184406103529656 Model:  [-0.22429244  2.21440806  1.05901817  1.03296976]\n",
      "Iteration:  0 Improvement:  0.41955356194603577 Model:  [-0.11469667  2.18733388  1.05769108  0.99572747]\n",
      "Iteration:  0 Improvement:  0.01991454771223507 Model:  [-0.16348931  2.18053633  1.00836709  1.02841698]\n",
      "Iteration:  0 Improvement:  0.01576569284921536 Model:  [-0.22496225  2.21234108  1.04439624  1.02748933]\n",
      "Iteration:  0 Improvement:  0.05890373850929637 Model:  [-0.15940309  2.22025445  1.03878475  1.00118402]\n",
      "Iteration:  0 Improvement:  0.016260377969134356 Model:  [-0.22498977  2.21361107  1.05451316  1.01482307]\n",
      "****Converged***\n",
      "Iteration:  0 Improvement:  0.009692803411399947 Model:  [-0.16836322  2.181034    1.01409913  1.03450725]\n",
      "iteration: 0 and result is: [-0.16836322  2.181034    1.01409913  1.03450725] in 5 emit\n",
      "Iteration:  0 Improvement:  0.018574387037880096 Model:  [-0.17425906  2.22877465  1.04356738  1.00655434]\n",
      "Iteration:  0 Improvement:  0.012826463979243972 Model:  [-0.22501209  2.21411342  1.0424766   1.01922611]\n",
      "Iteration:  0 Improvement:  0.010249497228824104 Model:  [-0.17923402  2.23005248  1.04528642  1.01525572]\n",
      "Iteration:  0 Improvement:  inf Model:  [0.00776753 1.88968508 0.90558149 0.9244268 ]\n",
      "Iteration:  0 Improvement:  0.02381722094830777 Model:  [-0.22500287  2.21478249  1.06458148  1.02806844]\n",
      "Iteration:  0 Improvement:  0.030518897397275785 Model:  [-0.18088868  2.22960462  1.06742933  1.0361879 ]\n",
      "Iteration:  0 Improvement:  0.03353114825938756 Model:  [-0.22519344  2.21241702  1.03526816  1.01196145]\n",
      "Iteration:  0 Improvement:  0.3739241320172053 Model:  [-0.10234375  2.20307126  1.05482178  1.00934558]\n",
      "Iteration:  0 Improvement:  0.04010801154116785 Model:  [-0.18185868  2.22617318  1.04823951  1.00114953]\n",
      "Iteration:  0 Improvement:  0.01304184811571202 Model:  [-0.22489964  2.21567679  1.04750267  1.01507498]\n",
      "Iteration:  0 Improvement:  0.06046694280758685 Model:  [-0.14681515  2.24033088  1.04470337  1.02305267]\n",
      "Iteration:  0 Improvement:  0.013394281041858792 Model:  [-0.18150133  2.22999777  1.05839503  1.0089928 ]\n",
      "Iteration:  0 Improvement:  0.012106355975417302 Model:  [-0.22502929  2.21501562  1.04217903  1.02592711]\n",
      "Iteration:  0 Improvement:  0.02376072748218384 Model:  [-0.16344464  2.24914745  1.05772248  1.02944039]\n",
      "Iteration:  0 Improvement:  0.03790896407474776 Model:  [-0.22509561  2.21440631  1.07844002  1.03696588]\n",
      "Iteration:  0 Improvement:  0.021543696418811983 Model:  [-0.18174484  2.22922614  1.07969675  1.01210938]\n",
      "Iteration:  0 Improvement:  0.01162508797269167 Model:  [-0.16913099  2.24982503  1.06204833  1.03858566]\n",
      "Iteration:  0 Improvement:  0.028203191690346793 Model:  [-0.18215212  2.22724967  1.05452103  1.02466053]\n",
      "Iteration:  0 Improvement:  0.05421537106405148 Model:  [-0.22531012  2.21053087  1.03190269  1.00942468]\n",
      "Iteration:  0 Improvement:  0.012136750665269105 Model:  [-0.17106568  2.24901767  1.07368889  1.04130659]\n",
      "Iteration:  0 Improvement:  0.019651432735128985 Model:  [-0.18188123  2.22772138  1.06089439  1.00607927]\n",
      "Iteration:  0 Improvement:  0.015181063611218308 Model:  [-0.22481763  2.21582757  1.04490145  1.01518657]\n",
      "****Converged***\n",
      "Iteration:  0 Improvement:  0.003267641040898022 Model:  [-0.17154833  2.24767378  1.07525264  1.03881799]\n",
      "iteration: 0 and result is: [-0.17154833  2.24767378  1.07525264  1.03881799] in 7 emit\n",
      "Iteration:  0 Improvement:  0.03665403300728356 Model:  [-0.18179551  2.22889711  1.09557381  1.01788882]\n",
      "****Converged***\n",
      "Iteration:  0 Improvement:  0.009521617840111733 Model:  [-0.22501049  2.21523831  1.04318766  1.02453214]\n",
      "iteration: 0 and result is: [-0.22501049  2.21523831  1.04318766  1.02453214] in 17 emit\n",
      "Iteration:  0 Improvement:  0.04877618806184797 Model:  [-0.18243393  2.2255475   1.04966341  1.00177287]\n",
      "Iteration:  0 Improvement:  inf Model:  [-0.01896058  1.91069154  0.83065562  0.87217715]\n",
      "Iteration:  0 Improvement:  0.012758218065696334 Model:  [-0.18168499  2.22974908  1.06044133  1.00710152]\n",
      "Iteration:  0 Improvement:  inf Model:  [-0.11083767  1.94541787  0.86824756  0.95097686]\n",
      "****Converged***\n",
      "Iteration:  0 Improvement:  0.0073377554450565746 Model:  [-0.18182741  2.22919861  1.06583428  1.01204473]\n",
      "iteration: 0 and result is: [-0.18182741  2.22919861  1.06583428  1.01204473] in 15 emit\n",
      "Iteration:  0 Improvement:  0.4224351331149643 Model:  [-0.14584216  2.23281336  1.02593135  1.01520662]\n",
      "Iteration:  0 Improvement:  0.3589482983866087 Model:  [-0.24189309  2.23439295  1.02687471  1.00574169]\n",
      "Iteration:  0 Improvement:  0.061008406708167165 Model:  [-0.19384164  2.26154978  1.00205888  1.01993936]\n",
      "Iteration:  0 Improvement:  0.05476441495411259 Model:  [-0.2824725   2.26588448  1.01250098  1.01815669]\n",
      "Iteration:  0 Improvement:  inf Model:  [-0.06685176  1.84552737  0.86077562  0.94991533]\n",
      "Iteration:  0 Improvement:  0.02280974759627552 Model:  [-0.21185649  2.2724098   1.01070798  1.0216721 ]\n",
      "Iteration:  0 Improvement:  0.02195882094975472 Model:  [-0.29555442  2.27256281  1.02835564  1.02204035]\n",
      "Iteration:  0 Improvement:  0.4162959929380343 Model:  [-0.1954148   2.19063729  1.0314959   1.04226051]\n",
      "****Converged***\n",
      "Iteration:  0 Improvement:  0.009682768061298266 Model:  [-0.21815522  2.27467197  1.01205273  1.02853914]\n",
      "iteration: 0 and result is: [-0.21815522  2.27467197  1.01205273  1.02853914] in 5 emit\n",
      "****Converged***\n",
      "Iteration:  0 Improvement:  0.006059617051456888 Model:  [-0.29935612  2.27261918  1.02977157  1.02654124]\n",
      "iteration: 0 and result is: [-0.29935612  2.27261918  1.02977157  1.02654124] in 5 emit\n",
      "Iteration:  0 Improvement:  0.07202356315672871 Model:  [-0.24741665  2.23361701  1.01044949  1.0561527 ]\n",
      "Iteration:  0 Improvement:  inf Model:  [-0.03783125  1.77875909  0.90063608  0.91333546]\n",
      "Iteration:  0 Improvement:  inf Model:  [-0.01359335  1.85699278  0.90291859  0.92692886]\n",
      "Iteration:  0 Improvement:  0.029938543125603772 Model:  [-0.26628812  2.24392397  1.02950604  1.06456689]\n",
      "****Converged***\n",
      "Iteration:  0 Improvement:  0.00845555276997647 Model:  [-0.27304712  2.24454379  1.02450967  1.06388544]\n",
      "iteration: 0 and result is: [-0.27304712  2.24454379  1.02450967  1.06388544] in 5 emit\n",
      "Iteration:  0 Improvement:  0.42341680989001795 Model:  [-0.1736834   2.15116302  1.01675553  1.00638158]\n",
      "Iteration:  0 Improvement:  0.37835242016019793 Model:  [-0.11256335  2.18133673  1.03596926  1.02917372]\n",
      "Iteration:  0 Improvement:  0.07579861596394045 Model:  [-0.23137229  2.19799742  1.01153148  1.02040548]\n",
      "Iteration:  0 Improvement:  0.052778169538878913 Model:  [-0.15095959  2.21427347  1.02368608  1.03786615]\n",
      "Iteration:  0 Improvement:  inf Model:  [-0.06170422  1.93126261  0.8495695   0.9280347 ]\n",
      "Iteration:  0 Improvement:  0.029468240700502538 Model:  [-0.25249792  2.20792271  1.02899705  1.02470982]\n",
      "Iteration:  0 Improvement:  0.018682317513004372 Model:  [-0.16317047  2.22055076  1.03480148  1.04394621]\n",
      "Iteration:  0 Improvement:  0.39532761517392273 Model:  [-0.17870393  2.25004634  1.02770122  1.0241649 ]\n",
      "****Converged***\n",
      "Iteration:  0 Improvement:  0.008058960259407597 Model:  [-0.26005819  2.20905238  1.02680983  1.02602476]\n",
      "iteration: 0 and result is: [-0.26005819  2.20905238  1.02680983  1.02602476] in 5 emit\n",
      "Iteration:  0 Improvement:  0.016071883100529913 Model:  [-0.16734673  2.22067031  1.04966374  1.04841421]\n",
      "****Converged***\n",
      "Iteration:  0 Improvement:  0.004089779929801812 Model:  [-0.16905528  2.21951791  1.05237747  1.04615261]\n",
      "iteration: 0 and result is: [-0.16905528  2.21951791  1.05237747  1.04615261] in 6 emit\n",
      "Iteration:  0 Improvement:  0.05508279453317582 Model:  [-0.22157272  2.28185964  1.01597855  1.03101129]\n",
      "Iteration:  0 Improvement:  inf Model:  [-0.05758231  1.86530814  0.88670803  0.94686761]\n",
      "Iteration:  0 Improvement:  0.01957239266551364 Model:  [-0.23635259  2.28899063  1.02647664  1.0329016 ]\n",
      "Iteration:  0 Improvement:  inf Model:  [0.05076424 1.88651452 0.85137802 0.90434286]\n",
      "****Converged***\n",
      "Iteration:  0 Improvement:  0.009829941260514476 Model:  [-0.24138285  2.28965271  1.02828101  1.04112536]\n",
      "iteration: 0 and result is: [-0.24138285  2.28965271  1.02828101  1.04112536] in 5 emit\n",
      "Iteration:  0 Improvement:  0.40723087253415974 Model:  [-0.20812549  2.20247733  1.03896794  1.02628795]\n",
      "Iteration:  0 Improvement:  0.40918019103339714 Model:  [-0.0325435   2.21512329  1.04111402  1.03281378]\n",
      "Iteration:  0 Improvement:  0.07468334967384534 Model:  [-0.2657739   2.24648038  1.02422796  1.03632428]\n",
      "Iteration:  0 Improvement:  inf Model:  [-0.03919925  1.93750896  0.86224004  0.87202867]\n",
      "Iteration:  0 Improvement:  0.026824228672003236 Model:  [-0.28699365  2.25756592  1.03541538  1.04093016]\n",
      "Iteration:  0 Improvement:  0.053285391498048555 Model:  [-0.06757822  2.24904134  1.02203689  1.0426895 ]\n",
      "Iteration:  0 Improvement:  0.36987591464588754 Model:  [-0.10571881  2.23223183  1.02217338  1.0132487 ]\n",
      "Iteration:  0 Improvement:  0.014558969725458117 Model:  [-0.29439661  2.25940822  1.04611705  1.04719434]\n",
      "Iteration:  0 Improvement:  0.023283522318189972 Model:  [-0.08158076  2.25933202  1.03399973  1.05254057]\n",
      "Iteration:  0 Improvement:  0.01902686234848004 Model:  [-0.29695052  2.25883499  1.06247316  1.0565564 ]\n",
      "Iteration:  0 Improvement:  0.04301026030368158 Model:  [-0.13480671  2.25517731  1.00075067  1.01753231]\n",
      "****Converged***\n",
      "Iteration:  0 Improvement:  0.005206477586023271 Model:  [-0.08659367  2.25993597  1.03509988  1.05190569]\n",
      "iteration: 0 and result is: [-0.08659367  2.25993597  1.03509988  1.05190569] in 5 emit\n",
      "Iteration:  0 Improvement:  0.014861654694498209 Model:  [-0.29783517  2.25694395  1.04868509  1.05141838]\n",
      "Iteration:  0 Improvement:  0.023388658828641763 Model:  [-0.14426423  2.2608967   1.02099555  1.02140764]\n",
      "Iteration:  0 Improvement:  0.012622933888479319 Model:  [-0.2980163   2.25806024  1.05777704  1.04273529]\n",
      "Iteration:  0 Improvement:  inf Model:  [-0.02506883  1.76645613  0.88081779  0.92277978]\n",
      "Iteration:  0 Improvement:  0.011485422177675182 Model:  [-0.14768655  2.26033025  1.01048176  1.02446412]\n",
      "Iteration:  0 Improvement:  0.011377166944812328 Model:  [-0.29787487  2.25819215  1.05361063  1.05332035]\n",
      "Iteration:  0 Improvement:  0.024967441934915503 Model:  [-0.14869454  2.26080386  1.03348009  1.03411865]\n",
      "Iteration:  0 Improvement:  0.4016183094602607 Model:  [-0.14921956  2.12350704  0.99230824  1.00003514]\n",
      "Iteration:  0 Improvement:  0.03887755143028477 Model:  [-0.29809812  2.25778204  1.09216054  1.0583354 ]\n",
      "Iteration:  0 Improvement:  0.015119555316277726 Model:  [-0.14962515  2.25854249  1.02073929  1.02635378]\n",
      "Iteration:  0 Improvement:  0.06967072646608483 Model:  [-0.20140635  2.16832794  0.99122056  1.01101022]\n",
      "Iteration:  0 Improvement:  0.06387315100166772 Model:  [-0.2979934   2.25446546  1.03332856  1.03368653]\n",
      "Iteration:  0 Improvement:  0.020904493622778422 Model:  [-0.14947301  2.25964994  1.04089791  1.0209336 ]\n",
      "Iteration:  0 Improvement:  0.02176541569105652 Model:  [-0.22016709  2.17742157  0.99716435  1.00907492]\n",
      "Iteration:  0 Improvement:  0.01180272282371843 Model:  [-0.2976634   2.26007776  1.04142053  1.04018402]\n",
      "Iteration:  0 Improvement:  0.025816737387308705 Model:  [-0.14954464  2.25884932  1.0154629   1.01658411]\n",
      "Iteration:  0 Improvement:  0.01618651475600603 Model:  [-0.22630157  2.17947946  1.00992651  1.01664221]\n",
      "Iteration:  0 Improvement:  0.026532763654634743 Model:  [-0.29793502  2.25999054  1.06334024  1.05513169]\n",
      "Iteration:  0 Improvement:  0.01153316261923554 Model:  [-0.14909144  2.26083673  1.0184782   1.0275279 ]\n",
      "Iteration:  0 Improvement:  0.02596487185998804 Model:  [-0.22839866  2.17864715  1.03422569  1.02550977]\n",
      "Iteration:  0 Improvement:  0.0198366242230195 Model:  [-0.29818374  2.25724197  1.04388817  1.05239446]\n",
      "Iteration:  0 Improvement:  0.05867497528984343 Model:  [-0.14932727  2.26011681  1.07664458  1.03519932]\n",
      "Iteration:  0 Improvement:  0.03810659620512283 Model:  [-0.22902798  2.17622353  0.99767117  1.0150403 ]\n",
      "Iteration:  0 Improvement:  0.011402950441774187 Model:  [-0.29821376  2.25843594  1.03377207  1.04726949]\n",
      "Iteration:  0 Improvement:  0.0866037905342743 Model:  [-0.15035354  2.25539149  0.99302966  1.01316801]\n",
      "Iteration:  0 Improvement:  0.04222651227743906 Model:  [-0.29823743  2.25980373  1.07523598  1.0551404 ]\n",
      "****Converged***\n",
      "Iteration:  0 Improvement:  0.00913789148918939 Model:  [-0.2291666   2.17927245  1.0062832   1.01490255]\n",
      "iteration: 0 and result is: [-0.2291666   2.17927245  1.0062832   1.01490255] in 8 emit\n",
      "Iteration:  0 Improvement:  0.026820073160701053 Model:  [-0.14885421  2.26212162  1.01797125  1.02021718]\n",
      "Iteration:  0 Improvement:  0.040795681594204665 Model:  [-0.2981925   2.25632559  1.03812576  1.03855669]\n",
      "Iteration:  0 Improvement:  0.012370726812768816 Model:  [-0.1490704   2.26093741  1.01572578  1.0323227 ]\n",
      "Iteration:  0 Improvement:  inf Model:  [-0.04124019  1.82616477  0.90567636  0.91393352]\n",
      "Iteration:  0 Improvement:  0.010227689362621934 Model:  [-0.29789543  2.25969997  1.04756264  1.04057564]\n",
      "Iteration:  0 Improvement:  0.0682260410779884 Model:  [-0.14945002  2.2599585   1.08392286  1.03401068]\n",
      "****Converged***\n",
      "Iteration:  0 Improvement:  0.00913306671920734 Model:  [-0.29795506  2.25942722  1.05348879  1.0475194 ]\n",
      "iteration: 0 and result is: [-0.29795506  2.25942722  1.05348879  1.0475194 ] in 19 emit\n",
      "Iteration:  0 Improvement:  0.09119413836729709 Model:  [-0.15044757  2.2549688   0.99378078  1.02116994]\n",
      "Iteration:  0 Improvement:  0.45609561240327323 Model:  [-0.19549477  2.21127384  1.05819327  1.02644279]\n",
      "Iteration:  0 Improvement:  0.018207711838837997 Model:  [-0.14913511  2.2613653   1.00998307  1.01603488]\n",
      "Iteration:  0 Improvement:  0.08285816730495286 Model:  [-0.25890801  2.261506    1.04517329  1.03874913]\n",
      "Iteration:  0 Improvement:  inf Model:  [0.01207856 1.84596866 0.83613195 0.91676905]\n",
      "Iteration:  0 Improvement:  0.028466144590147763 Model:  [-0.14891105  2.26170635  1.03354947  1.0319967 ]\n",
      "Iteration:  0 Improvement:  0.032582570335670934 Model:  [-0.28406042  2.27498527  1.05930284  1.04565167]\n",
      "Iteration:  0 Improvement:  0.026890828748197707 Model:  [-0.14964106  2.25886178  1.01106409  1.01754332]\n",
      "Iteration:  0 Improvement:  0.40897029708700783 Model:  [-0.08937626  2.1850095   1.0096218   1.02593045]\n",
      "****Converged***\n",
      "Iteration:  0 Improvement:  0.0098162210101738 Model:  [-0.29345302  2.27727601  1.06065967  1.04462751]\n",
      "iteration: 0 and result is: [-0.29345302  2.27727601  1.06065967  1.04462751] in 5 emit\n",
      "Iteration:  0 Improvement:  0.013940845648910204 Model:  [-0.14907993  2.26107786  1.02481262  1.01785838]\n",
      "Iteration:  0 Improvement:  0.05976413624913901 Model:  [-0.13150606  2.22095597  0.99094344  1.0384125 ]\n",
      "Iteration:  0 Improvement:  0.016374190824905283 Model:  [-0.14915382  2.26045497  1.03168382  1.03270787]\n",
      "Iteration:  0 Improvement:  0.029946035141510494 Model:  [-0.14813297  2.22992214  1.01240018  1.04733029]\n",
      "Iteration:  0 Improvement:  inf Model:  [0.0158508  1.89418887 0.85959661 0.95574149]\n",
      "Iteration:  0 Improvement:  0.012466635158632127 Model:  [-0.14969155  2.25872306  1.03863012  1.02251585]\n",
      "****Converged***\n",
      "Iteration:  0 Improvement:  0.00719514599109125 Model:  [-0.15380828  2.22986363  1.0146316   1.04351214]\n",
      "iteration: 0 and result is: [-0.15380828  2.22986363  1.0146316   1.04351214] in 5 emit\n",
      "Iteration:  0 Improvement:  0.406999280057989 Model:  [-0.06016878  2.22179079  1.03917941  1.09820705]\n",
      "****Converged***\n",
      "Iteration:  0 Improvement:  0.00750940916149488 Model:  [-0.14962077  2.25872909  1.03112613  1.02279199]\n",
      "iteration: 0 and result is: [-0.14962077  2.25872909  1.03112613  1.02279199] in 23 emit\n",
      "Iteration:  0 Improvement:  0.05147982705813314 Model:  [-0.09322063  2.25264842  1.01474456  1.10112132]\n",
      "Iteration:  0 Improvement:  inf Model:  [-0.0740939   1.92871606  0.87713427  0.9225977 ]\n",
      "Iteration:  0 Improvement:  inf Model:  [-0.06644387  1.85865569  0.88799437  0.88946986]\n",
      "Iteration:  0 Improvement:  0.017720376829702348 Model:  [-0.10425411  2.26017825  1.02630057  1.10254757]\n",
      "Iteration:  0 Improvement:  0.3546848451319569 Model:  [-0.18919482  2.21065061  1.0328852   1.0164469 ]\n",
      "Iteration:  0 Improvement:  0.01263122527614066 Model:  [-0.10826888  2.26091412  1.03671925  1.10840754]\n",
      "Iteration:  0 Improvement:  0.3955572787475164 Model:  [-0.18343336  2.19098596  1.02993436  0.9998721 ]\n",
      "Iteration:  0 Improvement:  0.052058665620897955 Model:  [-0.22820725  2.23700744  1.01328361  1.02689822]\n",
      "Iteration:  0 Improvement:  0.018916407532417155 Model:  [-0.10995188  2.25993311  1.05553394  1.10861533]\n",
      "Iteration:  0 Improvement:  0.062396991152115056 Model:  [-0.22975377  2.22964965  1.01740197  1.00966306]\n",
      "Iteration:  0 Improvement:  0.020653753070642832 Model:  [-0.2407487   2.24300948  1.02836605  1.02449301]\n",
      "Iteration:  0 Improvement:  0.04826692587796762 Model:  [-0.11090184  2.25860294  1.03663467  1.15299823]\n",
      "Iteration:  0 Improvement:  0.0227549995809664 Model:  [-0.24655004  2.23932195  1.02931822  1.0100159 ]\n",
      "Iteration:  0 Improvement:  0.022902807971663074 Model:  [-0.24437954  2.2434224   1.03940826  1.04422255]\n",
      "Iteration:  0 Improvement:  0.05470328478515639 Model:  [-0.11207954  2.25562416  1.0278144   1.09910582]\n",
      "Iteration:  0 Improvement:  0.019224140222671778 Model:  [-0.25201355  2.24086762  1.04356868  1.02160266]\n",
      "Iteration:  0 Improvement:  0.018363871035476723 Model:  [-0.24604011  2.24142534  1.02419426  1.03427167]\n",
      "Iteration:  0 Improvement:  0.011412669264272705 Model:  [-0.11072447  2.26037445  1.02532229  1.10908764]\n",
      "****Converged***\n",
      "Iteration:  0 Improvement:  0.004608350089183634 Model:  [-0.25378726  2.23937155  1.04232875  1.01781912]\n",
      "iteration: 0 and result is: [-0.25378726  2.23937155  1.04232875  1.01781912] in 6 emit\n",
      "Iteration:  0 Improvement:  0.023669044734673666 Model:  [-0.24620209  2.24292255  1.04770834  1.03202582]\n",
      "Iteration:  0 Improvement:  0.06045751796610503 Model:  [-0.11059588  2.26052144  1.08399779  1.12365674]\n",
      "Iteration:  0 Improvement:  0.013567401192819434 Model:  [-0.24615472  2.24166812  1.03688577  1.04011103]\n",
      "Iteration:  0 Improvement:  0.065928338038329 Model:  [-0.11206384  2.25567455  1.02342095  1.09813528]\n",
      "Iteration:  0 Improvement:  inf Model:  [-0.04746812  1.90128586  0.90656574  0.94582326]\n",
      "****Converged***\n",
      "Iteration:  0 Improvement:  0.009054702217407427 Model:  [-0.24638298  2.24165408  1.04592689  1.03967105]\n",
      "iteration: 0 and result is: [-0.24638298  2.24165408  1.04592689  1.03967105] in 9 emit\n",
      "Iteration:  0 Improvement:  0.01050748901364101 Model:  [-0.11060326  2.260746    1.02864163  1.10557161]\n",
      "Iteration:  0 Improvement:  0.3567014639980022 Model:  [-0.14340104  2.19390064  1.06053481  1.03911275]\n",
      "Iteration:  0 Improvement:  0.10326780624084564 Model:  [-0.11048167  2.26069875  1.12769746  1.13476346]\n",
      "Iteration:  0 Improvement:  inf Model:  [-0.13330375  1.87830025  0.91446248  0.89582663]\n",
      "Iteration:  0 Improvement:  0.04817125391983623 Model:  [-0.17923291  2.22208238  1.04796155  1.04829148]\n",
      "Iteration:  0 Improvement:  0.13190099594775145 Model:  [-0.11308899  2.25216476  1.00363297  1.09087444]\n",
      "Iteration:  0 Improvement:  0.016006146695968834 Model:  [-0.19164496  2.22806414  1.05605929  1.04740677]\n",
      "Iteration:  0 Improvement:  0.4108385758549137 Model:  [-0.29448101  2.22879629  1.03555121  0.96862959]\n",
      "Iteration:  0 Improvement:  0.031339151504806526 Model:  [-0.1102614   2.26199791  1.03012085  1.10413521]\n",
      "Iteration:  0 Improvement:  0.01503948818068395 Model:  [-0.19565719  2.22873357  1.06659166  1.05734203]\n",
      "****Converged***\n",
      "Iteration:  0 Improvement:  0.0020403030443694745 Model:  [-0.11041375  2.26096787  1.03124544  1.10548204]\n",
      "iteration: 0 and result is: [-0.11041375  2.26096787  1.03124544  1.10548204] in 16 emit\n",
      "Iteration:  0 Improvement:  0.07506341503442222 Model:  [-0.35220171  2.27366056  1.03118461  0.98509066]\n",
      "Iteration:  0 Improvement:  0.024660748900509583 Model:  [-0.19731437  2.22739206  1.09013484  1.06436522]\n",
      "Iteration:  0 Improvement:  0.0226653661862768 Model:  [-0.37083595  2.28297454  1.04000943  0.98372822]\n",
      "Iteration:  0 Improvement:  0.03163251725762627 Model:  [-0.19806088  2.22480204  1.06190455  1.05035089]\n",
      "Iteration:  0 Improvement:  inf Model:  [-0.05617038  1.83670852  0.90043722  0.91502907]\n",
      "Iteration:  0 Improvement:  0.010669112564833775 Model:  [-0.37654027  2.28482354  1.04669771  0.98948486]\n",
      "****Converged***\n",
      "Iteration:  0 Improvement:  0.0048944083803894554 Model:  [-0.19773791  2.22762033  1.06270019  1.04644255]\n",
      "iteration: 0 and result is: [-0.19773791  2.22762033  1.06270019  1.04644255] in 8 emit\n",
      "Iteration:  0 Improvement:  0.03995985710250413 Model:  [-0.37835525  2.28453069  1.07277799  1.01970454]\n",
      "Iteration:  0 Improvement:  0.37392690115073357 Model:  [-0.17625616  2.15297219  1.04610572  0.97951717]\n",
      "Iteration:  0 Improvement:  0.054778445650701765 Model:  [-0.37938834  2.28071059  1.03301668  0.98223381]\n",
      "Iteration:  0 Improvement:  0.060047749903300106 Model:  [-0.22303421  2.18726346  1.0357237   0.99108735]\n",
      "Iteration:  0 Improvement:  inf Model:  [-0.03573543  1.85046986  0.94639009  0.88914501]\n",
      "Iteration:  0 Improvement:  0.020032804936735305 Model:  [-0.37879378  2.28551318  1.05029947  0.99113324]\n",
      "Iteration:  0 Improvement:  0.024591547871949036 Model:  [-0.24078815  2.19493196  1.05091005  0.9914201 ]\n",
      "Iteration:  0 Improvement:  0.4239101456369664 Model:  [-0.16866063  2.21634075  1.075555    0.99631602]\n",
      "Iteration:  0 Improvement:  0.016279189475371967 Model:  [-0.37906867  2.28437623  1.06281798  1.00147397]\n",
      "Iteration:  0 Improvement:  0.014861820460094858 Model:  [-0.24688082  2.19547456  1.06338362  0.99669917]\n",
      "****Converged***\n",
      "Iteration:  0 Improvement:  0.0038951611409240193 Model:  [-0.37929334  2.28260082  1.06612413  1.00045462]\n",
      "iteration: 0 and result is: [-0.37929334  2.28260082  1.06612413  1.00045462] in 10 emit\n",
      "Iteration:  0 Improvement:  0.06812983964150411 Model:  [-0.21850642  2.25713315  1.06026822  1.01242089]\n",
      "****Converged***\n",
      "Iteration:  0 Improvement:  0.005762242118897773 Model:  [-0.24896248  2.19436485  1.06863971  0.9968094 ]\n",
      "iteration: 0 and result is: [-0.24896248  2.19436485  1.06863971  0.9968094 ] in 6 emit\n",
      "Iteration:  0 Improvement:  0.01976764240835355 Model:  [-0.23415385  2.2654627   1.06853988  1.01526969]\n",
      "Iteration:  0 Improvement:  inf Model:  [-0.01427376  1.85200639  0.89902653  0.96293471]\n",
      "Iteration:  0 Improvement:  0.012062389933509691 Model:  [-0.23921067  2.26664819  1.0737212   1.02484458]\n",
      "Iteration:  0 Improvement:  inf Model:  [-0.05259168  1.86815611  0.86408197  0.89300641]\n",
      "Iteration:  0 Improvement:  0.01606101800054618 Model:  [-0.24088214  2.26581131  1.08769161  1.03254455]\n",
      "Iteration:  0 Improvement:  0.36208122851918356 Model:  [-0.10853405  2.16971216  1.02932345  1.02853632]\n",
      "Iteration:  0 Improvement:  0.39148393042420426 Model:  [-0.18140329  2.16963267  1.04945851  0.99984582]\n",
      "Iteration:  0 Improvement:  0.011267571423302414 Model:  [-0.24174914  2.2640934   1.08331072  1.02234342]\n",
      "Iteration:  0 Improvement:  0.05862193464362303 Model:  [-0.14824028  2.2093569   1.02246909  1.04406883]\n",
      "Iteration:  0 Improvement:  0.05525617673775192 Model:  [-0.24181454  2.26504839  1.13774105  1.03181274]\n",
      "Iteration:  0 Improvement:  0.05992965363734944 Model:  [-0.22874476  2.19736083  1.02627154  1.00646863]\n",
      "Iteration:  0 Improvement:  0.018570261508648486 Model:  [-0.1629417   2.21698641  1.03057267  1.0462701 ]\n",
      "Iteration:  0 Improvement:  0.07568600697816713 Model:  [-0.24331865  2.26074911  1.06476721  1.01225658]\n",
      "Iteration:  0 Improvement:  0.022958575783270863 Model:  [-0.24508432  2.20591332  1.03984078  1.00815546]\n",
      "****Converged***\n",
      "Iteration:  0 Improvement:  0.005385675916406892 Model:  [-0.16817919  2.21805875  1.03107544  1.04668422]\n",
      "iteration: 0 and result is: [-0.16817919  2.21805875  1.03107544  1.04668422] in 5 emit\n",
      "Iteration:  0 Improvement:  0.011728851898360825 Model:  [-0.24159311  2.26671146  1.0739399   1.01611671]\n",
      "****Converged***\n",
      "Iteration:  0 Improvement:  0.009714331048885385 Model:  [-0.25039285  2.2069392   1.0446217   1.01465762]\n",
      "iteration: 0 and result is: [-0.25039285  2.2069392   1.0446217   1.01465762] in 5 emit\n",
      "Iteration:  0 Improvement:  0.029253287207917575 Model:  [-0.24157688  2.26670146  1.09865684  1.03176367]\n",
      "Iteration:  0 Improvement:  inf Model:  [-0.10755663  1.93213013  0.8711868   0.94704961]\n",
      "Iteration:  0 Improvement:  0.016927305350402263 Model:  [-0.24229526  2.26361599  1.08281825  1.02670043]\n",
      "Iteration:  0 Improvement:  inf Model:  [-0.08121756  1.92527039  0.85775549  0.90353708]\n",
      "****Converged***\n",
      "Iteration:  0 Improvement:  0.0037061142041207038 Model:  [-0.24193109  2.26462068  1.08378478  1.02328589]\n",
      "iteration: 0 and result is: [-0.24193109  2.26462068  1.08378478  1.02328589] in 13 emit\n",
      "Iteration:  0 Improvement:  0.380725411850016 Model:  [-0.23067758  2.24921053  1.01582847  1.03832873]\n",
      "Iteration:  0 Improvement:  0.3703418914658555 Model:  [-0.19183049  2.21672248  1.02507655  1.01297764]\n",
      "Iteration:  0 Improvement:  0.06772189616180714 Model:  [-0.27934088  2.29095798  1.00192114  1.05511786]\n",
      "Iteration:  0 Improvement:  0.05076617548231305 Model:  [-0.23160412  2.24441898  1.01127651  1.01911973]\n",
      "Iteration:  0 Improvement:  inf Model:  [-0.05226516  1.88253627  0.8791063   0.88711784]\n",
      "Iteration:  0 Improvement:  0.024493631882770425 Model:  [-0.2969      2.3004759   1.01512293  1.06028865]\n",
      "Iteration:  0 Improvement:  0.02052448963219909 Model:  [-0.24578652  2.2521766   1.02379442  1.02091845]\n",
      "Iteration:  0 Improvement:  0.3723718282885487 Model:  [-0.14621977  2.18408295  1.04242737  0.99770328]\n",
      "****Converged***\n",
      "Iteration:  0 Improvement:  0.006532220217808526 Model:  [-0.30319523  2.30165904  1.01634442  1.06067354]\n",
      "iteration: 0 and result is: [-0.30319523  2.30165904  1.01634442  1.06067354] in 5 emit\n",
      "Iteration:  0 Improvement:  0.013824370256144936 Model:  [-0.25021516  2.25291645  1.03322702  1.02997267]\n",
      "Iteration:  0 Improvement:  0.05434108259905464 Model:  [-0.18685636  2.21460895  1.02498385  1.00579694]\n",
      "Iteration:  0 Improvement:  0.010404690149161832 Model:  [-0.25157887  2.25167161  1.04337863  1.02863364]\n",
      "Iteration:  0 Improvement:  inf Model:  [-0.020833    1.87828071  0.82614819  0.91102372]\n",
      "Iteration:  0 Improvement:  0.021435899536725127 Model:  [-0.20241993  2.22294781  1.03696272  1.00785684]\n",
      "Iteration:  0 Improvement:  0.027395916565176457 Model:  [-0.25161713  2.25063642  1.04545395  1.05593119]\n",
      "****Converged***\n",
      "Iteration:  0 Improvement:  0.009625597110465189 Model:  [-0.20798854  2.22404633  1.03959264  1.01517255]\n",
      "iteration: 0 and result is: [-0.20798854  2.22404633  1.03959264  1.01517255] in 5 emit\n",
      "Iteration:  0 Improvement:  0.3669157378069856 Model:  [-0.13638953  2.16649461  0.99950026  1.00133239]\n",
      "Iteration:  0 Improvement:  0.03238377943856311 Model:  [-0.25217944  2.2482386   1.03799062  1.02451555]\n",
      "****Converged***\n",
      "Iteration:  0 Improvement:  0.004767725570082702 Model:  [-0.25170951  2.25085152  1.03462697  1.02660575]\n",
      "iteration: 0 and result is: [-0.25170951  2.25085152  1.03462697  1.02660575] in 9 emit\n",
      "Iteration:  0 Improvement:  0.056443158615115466 Model:  [-0.17965578  2.19490675  0.97776422  1.00717676]\n",
      "Iteration:  0 Improvement:  inf Model:  [-0.06325148  1.8069222   0.89047478  0.9332638 ]\n",
      "Iteration:  0 Improvement:  0.02320947951619348 Model:  [-0.19522746  2.20315911  0.99238686  1.01095562]\n",
      "Iteration:  0 Improvement:  inf Model:  [-0.0513339   1.87981939  0.90424657  0.89736175]\n",
      "Iteration:  0 Improvement:  0.39973153606393896 Model:  [-0.18260565  2.15965221  1.01961952  0.99992009]\n",
      "Iteration:  0 Improvement:  0.012759090756541339 Model:  [-0.20045688  2.2037881   1.00152739  1.01813216]\n",
      "Iteration:  0 Improvement:  0.01295995800161772 Model:  [-0.20215939  2.20287615  1.01427019  1.01949285]\n",
      "Iteration:  0 Improvement:  0.06715256015390866 Model:  [-0.23004391  2.20386497  1.01665639  1.01711107]\n",
      "Iteration:  0 Improvement:  0.38576274215274065 Model:  [-0.16676174  2.19203035  1.0646375   1.00821466]\n",
      "Iteration:  0 Improvement:  0.01910135404380092 Model:  [-0.20258744  2.20166135  1.01760099  1.0382574 ]\n",
      "Iteration:  0 Improvement:  0.02129953076709091 Model:  [-0.24760904  2.21238409  1.0251142   1.01609802]\n",
      "Iteration:  0 Improvement:  0.0594963882314994 Model:  [-0.21247593  2.22400443  1.04541392  1.01583996]\n",
      "Iteration:  0 Improvement:  0.04090018098149455 Model:  [-0.20287965  2.19993473  0.98373251  1.01539511]\n",
      "****Converged***\n",
      "Iteration:  0 Improvement:  0.006950979160061011 Model:  [-0.25357076  2.21401801  1.02793005  1.01757292]\n",
      "iteration: 0 and result is: [-0.25357076  2.21401801  1.02793005  1.01757292] in 5 emit\n",
      "Iteration:  0 Improvement:  0.024261680896245245 Model:  [-0.22879733  2.23296901  1.05939019  1.02266209]\n",
      "Iteration:  0 Improvement:  0.010464390078234524 Model:  [-0.20290222  2.20401029  0.99335011  1.01602328]\n",
      "****Converged***\n",
      "Iteration:  0 Improvement:  0.006579643338545277 Model:  [-0.23451123  2.23351501  1.0620376   1.0244886 ]\n",
      "iteration: 0 and result is: [-0.23451123  2.23351501  1.0620376   1.0244886 ] in 5 emit\n",
      "Iteration:  0 Improvement:  0.047708621408643515 Model:  [-0.20303202  2.20386833  1.04063895  1.02233528]\n",
      "Iteration:  0 Improvement:  inf Model:  [-0.0561429   1.88621616  0.88017028  0.90236402]\n",
      "Iteration:  0 Improvement:  0.04940383691268451 Model:  [-0.20272521  2.19954267  0.99215337  1.01390426]\n",
      "Iteration:  0 Improvement:  inf Model:  [-0.01994061  1.87194401  0.91795148  0.93353606]\n",
      "Iteration:  0 Improvement:  0.4081723474301996 Model:  [-0.17711395  2.20943799  1.07233659  1.00517661]\n",
      "****Converged***\n",
      "Iteration:  0 Improvement:  0.006056262127108934 Model:  [-0.20273475  2.20332678  0.99388643  1.01830371]\n",
      "iteration: 0 and result is: [-0.20273475  2.20332678  0.99388643  1.01830371] in 12 emit\n",
      "Iteration:  0 Improvement:  0.06008895181676003 Model:  [-0.2216915   2.24094353  1.048647    1.01352694]\n",
      "Iteration:  0 Improvement:  0.41134502480353685 Model:  [-0.16123573  2.19873263  1.08037517  1.0602963 ]\n",
      "Iteration:  0 Improvement:  inf Model:  [-0.057316    1.89629706  0.90388131  0.90095049]\n",
      "Iteration:  0 Improvement:  0.020019332736108748 Model:  [-0.23809195  2.24966875  1.05610707  1.01339663]\n",
      "Iteration:  0 Improvement:  0.07057574418428027 Model:  [-0.21851055  2.23437773  1.06052536  1.06629151]\n",
      "Iteration:  0 Improvement:  0.01068125216653484 Model:  [-0.24353245  2.25126884  1.0640816   1.01767877]\n",
      "Iteration:  0 Improvement:  0.028285254130337646 Model:  [-0.23934513  2.24499056  1.07579411  1.07078696]\n",
      "Iteration:  0 Improvement:  0.42442566426022543 Model:  [-0.18631319  2.2443736   1.06139634  1.03334614]\n",
      "Iteration:  0 Improvement:  0.01606652221132332 Model:  [-0.24536276  2.25080115  1.0780039   1.02547196]\n",
      "****Converged***\n",
      "Iteration:  0 Improvement:  0.009060431956554654 Model:  [-0.24695399  2.24651441  1.07322417  1.07469463]\n",
      "iteration: 0 and result is: [-0.24695399  2.24651441  1.07322417  1.07469463] in 5 emit\n",
      "Iteration:  0 Improvement:  0.06849969944206634 Model:  [-0.23968523  2.28545105  1.05319244  1.04277869]\n",
      "****Converged***\n",
      "Iteration:  0 Improvement:  0.004363564763539065 Model:  [-0.24599286  2.24908095  1.07596678  1.02207568]\n",
      "iteration: 0 and result is: [-0.24599286  2.24908095  1.07596678  1.02207568] in 7 emit\n",
      "Iteration:  0 Improvement:  0.02720998605303302 Model:  [-0.2601879   2.29671561  1.06512838  1.04989674]\n",
      "Iteration:  0 Improvement:  inf Model:  [-0.12830505  1.94063266  0.86444619  0.92499803]\n",
      "****Converged***\n",
      "Iteration:  0 Improvement:  0.008532147979948333 Model:  [-0.26758679  2.29840736  1.06199     1.04758535]\n",
      "iteration: 0 and result is: [-0.26758679  2.29840736  1.06199     1.04758535] in 5 emit\n",
      "Iteration:  0 Improvement:  inf Model:  [-0.05073245  1.89198219  0.90249296  0.85037473]\n",
      "Iteration:  0 Improvement:  0.3861943984599289 Model:  [-0.23839637  2.26269222  1.00805772  1.0376008 ]\n",
      "Iteration:  0 Improvement:  0.39456780959783755 Model:  [-0.16973668  2.20713945  1.05863381  0.98385765]\n",
      "Iteration:  0 Improvement:  inf Model:  [-0.07960142  1.92424837  0.87362909  0.93680288]\n",
      "Iteration:  0 Improvement:  0.05370113148265441 Model:  [-0.27811076  2.29719428  1.00020122  1.04498067]\n",
      "Iteration:  0 Improvement:  0.05528396605841105 Model:  [-0.21290571  2.2349853   1.03881123  0.98879988]\n",
      "Iteration:  0 Improvement:  0.016595789994023075 Model:  [-0.29128702  2.30486818  1.0065285   1.0466786 ]\n",
      "Iteration:  0 Improvement:  0.37624684258796587 Model:  [-0.17859731  2.22818458  1.03289524  1.05520293]\n",
      "Iteration:  0 Improvement:  0.022738095168902836 Model:  [-0.22651284  2.24243442  1.05441228  0.99454312]\n",
      "Iteration:  0 Improvement:  0.01201072627155439 Model:  [-0.2953807   2.30606197  1.01624802  1.05230044]\n",
      "Iteration:  0 Improvement:  0.048517120267446354 Model:  [-0.21615429  2.25626595  1.02133579  1.05980727]\n",
      "****Converged***\n",
      "Iteration:  0 Improvement:  0.006807086566256724 Model:  [-0.23101641  2.24249452  1.05945458  0.99533422]\n",
      "iteration: 0 and result is: [-0.23101641  2.24249452  1.05945458  0.99533422] in 5 emit\n",
      "Iteration:  0 Improvement:  0.012050548904313877 Model:  [-0.29671652  2.30517803  1.02721879  1.05702191]\n",
      "Iteration:  0 Improvement:  0.02032802952516608 Model:  [-0.22803495  2.26246432  1.03575394  1.06488426]\n",
      "****Converged***\n",
      "Iteration:  0 Improvement:  0.006291911200408859 Model:  [-0.29710768  2.30378844  1.0324557   1.06019665]\n",
      "iteration: 0 and result is: [-0.29710768  2.30378844  1.0324557   1.06019665] in 7 emit\n",
      "Iteration:  0 Improvement:  0.016752106610149323 Model:  [-0.2320277   2.26237366  1.05022051  1.07232747]\n",
      "Iteration:  0 Improvement:  inf Model:  [-0.08421899  1.89085378  0.84140744  0.87120896]\n",
      "****Converged***\n",
      "Iteration:  0 Improvement:  0.009658351512358453 Model:  [-0.2336157   2.26084372  1.04127631  1.06942528]\n",
      "iteration: 0 and result is: [-0.2336157   2.26084372  1.04127631  1.06942528] in 6 emit\n",
      "Iteration:  0 Improvement:  inf Model:  [-0.09822673  1.86465477  0.87915814  0.93828123]\n",
      "Iteration:  0 Improvement:  0.4014045012899138 Model:  [-0.22956599  2.19954727  1.01382323  0.99360565]\n",
      "Iteration:  0 Improvement:  0.06754408658912694 Model:  [-0.28569292  2.23107217  0.9948837   1.00131584]\n",
      "Iteration:  0 Improvement:  0.41474702028097743 Model:  [-0.26342736  2.21010909  1.01917374  1.01431277]\n",
      "Iteration:  0 Improvement:  inf Model:  [-0.01842827  1.71299452  0.90479861  0.97860252]\n",
      "Iteration:  0 Improvement:  0.026616636005681912 Model:  [-0.30643075  2.24054172  1.00853238  1.00287427]\n",
      "Iteration:  0 Improvement:  0.08078129526618526 Model:  [-0.32463476  2.25956157  1.01196582  1.03109879]\n",
      "Iteration:  0 Improvement:  0.5127801899446347 Model:  [-0.21419676  2.16380725  1.04177841  1.02981427]\n",
      "****Converged***\n",
      "Iteration:  0 Improvement:  0.00797713393217866 Model:  [-0.31367986  2.24225665  1.00579282  1.00367354]\n",
      "iteration: 0 and result is: [-0.31367986  2.24225665  1.00579282  1.00367354] in 5 emit\n",
      "Iteration:  0 Improvement:  0.02820829464296347 Model:  [-0.34638776  2.27102997  1.02577862  1.03154273]\n",
      "Iteration:  0 Improvement:  0.1021706672633026 Model:  [-0.28744429  2.23085579  1.04879462  1.05281233]\n",
      "Iteration:  0 Improvement:  0.013129163367717248 Model:  [-0.3534917   2.27322352  1.02791543  1.04215081]\n",
      "Iteration:  0 Improvement:  inf Model:  [-0.00204626  1.82311448  0.88283191  0.86243803]\n",
      "Iteration:  0 Improvement:  0.031142030279789835 Model:  [-0.31455126  2.24359118  1.05707102  1.05072683]\n",
      "****Converged***\n",
      "Iteration:  0 Improvement:  0.004683236871954624 Model:  [-0.3560879   2.27301733  1.02766655  1.04603513]\n",
      "iteration: 0 and result is: [-0.3560879   2.27301733  1.02766655  1.04603513] in 6 emit\n",
      "Iteration:  0 Improvement:  0.015417134525906494 Model:  [-0.32365959  2.24652822  1.06808505  1.05570591]\n",
      "Iteration:  0 Improvement:  0.47308211109908466 Model:  [-0.10487091  2.22933588  1.04399465  1.01158401]\n",
      "Iteration:  0 Improvement:  0.01404001693161374 Model:  [-0.32675436  2.24614996  1.07930392  1.06355055]\n",
      "Iteration:  0 Improvement:  inf Model:  [0.03266678 1.82075974 0.91971757 0.8984991 ]\n",
      "Iteration:  0 Improvement:  0.06582337070673257 Model:  [-0.15151134  2.27238831  1.0276826   1.01773152]\n",
      "****Converged***\n",
      "Iteration:  0 Improvement:  0.004746689472932881 Model:  [-0.32787004  2.24469308  1.07633838  1.0667707 ]\n",
      "iteration: 0 and result is: [-0.32787004  2.24469308  1.07633838  1.0667707 ] in 7 emit\n",
      "Iteration:  0 Improvement:  0.029127324578320568 Model:  [-0.17329701  2.28696559  1.03910757  1.02327756]\n",
      "Iteration:  0 Improvement:  0.43018693138721315 Model:  [-0.05055342  2.18598311  1.07685738  1.04011183]\n",
      "****Converged***\n",
      "Iteration:  0 Improvement:  0.009090269415313585 Model:  [-0.1814662   2.28902276  1.04197068  1.02513983]\n",
      "iteration: 0 and result is: [-0.1814662   2.28902276  1.04197068  1.02513983] in 5 emit\n",
      "Iteration:  0 Improvement:  0.059504391051667264 Model:  [-0.0901116   2.22657928  1.06135667  1.04947139]\n",
      "Iteration:  0 Improvement:  0.025149749679238696 Model:  [-0.1068112   2.23749726  1.07635046  1.05257259]\n",
      "Iteration:  0 Improvement:  0.010377806254347184 Model:  [-0.11296555  2.23867807  1.08459553  1.05190378]\n",
      "Iteration:  0 Improvement:  0.06226416430737688 Model:  [-0.11504897  2.23842531  1.11775626  1.10456105]\n",
      "Iteration:  0 Improvement:  0.08051363844604915 Model:  [-0.11630722  2.23002806  1.06658026  1.04298698]\n",
      "Iteration:  0 Improvement:  0.01731849608707534 Model:  [-0.1160765   2.23943954  1.07629875  1.05379679]\n",
      "Iteration:  0 Improvement:  0.03733895615023118 Model:  [-0.1164263   2.23936115  1.11288403  1.06125241]\n",
      "Iteration:  0 Improvement:  0.03876782500975974 Model:  [-0.11593406  2.23495629  1.07604176  1.05002985]\n",
      "****Converged***\n",
      "Iteration:  0 Improvement:  0.0065931127575698896 Model:  [-0.11612034  2.23879946  1.07973978  1.05390143]\n",
      "iteration: 0 and result is: [-0.11612034  2.23879946  1.07973978  1.05390143] in 11 emit\n",
      "[           alpha       beta\n",
      "0.1_1   0.131692   1.301026\n",
      "0.1_10  0.213141   6.647556\n",
      "0.1_15  0.223529   8.314948\n",
      "0.1_20  0.223417   7.977591\n",
      "0.1_25  0.341503   9.508707\n",
      "...          ...        ...\n",
      "0.9_30  0.655444  14.641470\n",
      "0.9_35  0.690783   9.302566\n",
      "0.9_40  0.699424  13.616960\n",
      "0.9_5   0.810364   7.638906\n",
      "0.9_7   0.775062   6.959910\n",
      "\n",
      "[99 rows x 2 columns],            alpha       beta\n",
      "0.1_1   0.235836   1.204274\n",
      "0.1_10  0.203366   7.031724\n",
      "0.1_15  0.193620  11.772476\n",
      "0.1_20  0.142117  12.860860\n",
      "0.1_25  0.288710   9.139675\n",
      "...          ...        ...\n",
      "0.9_30  0.558494  10.697651\n",
      "0.9_35  0.768380  17.391251\n",
      "0.9_40  0.689962  10.573577\n",
      "0.9_5   0.786318   4.804086\n",
      "0.9_7   0.790594   6.920085\n",
      "\n",
      "[99 rows x 2 columns],            alpha       beta\n",
      "0.1_1   0.130295   2.801869\n",
      "0.1_10  0.163349   8.336872\n",
      "0.1_15  0.402838   6.431908\n",
      "0.1_20  0.214087   8.835295\n",
      "0.1_25  0.209066   8.922129\n",
      "...          ...        ...\n",
      "0.9_30  0.563288  16.560580\n",
      "0.9_35  0.519913  21.458622\n",
      "0.9_40  0.660306  13.165984\n",
      "0.9_5   0.767038   4.704310\n",
      "0.9_7   0.731734   7.818381\n",
      "\n",
      "[99 rows x 2 columns],            alpha       beta\n",
      "0.1_1   0.236109   1.335953\n",
      "0.1_10  0.163559   7.355556\n",
      "0.1_15  0.199392   7.423502\n",
      "0.1_20  0.138480  14.696810\n",
      "0.1_25  0.158911  11.376229\n",
      "...          ...        ...\n",
      "0.9_30  0.678308   8.123165\n",
      "0.9_35  0.674760  15.132434\n",
      "0.9_40  0.489597  19.519563\n",
      "0.9_5   0.849489   5.895068\n",
      "0.9_7   0.887088   5.908000\n",
      "\n",
      "[99 rows x 2 columns],            alpha       beta\n",
      "0.1_1   0.373788   0.767552\n",
      "0.1_10  0.153934   9.712827\n",
      "0.1_15  0.202304   8.572376\n",
      "0.1_20  0.165162   9.347040\n",
      "0.1_25  0.092240  22.433420\n",
      "...          ...        ...\n",
      "0.9_30  0.680389   9.064310\n",
      "0.9_35  0.771133   9.433941\n",
      "0.9_40  0.662945  17.227862\n",
      "0.9_5   0.779238   7.204527\n",
      "0.9_7   0.845764   5.850092\n",
      "\n",
      "[99 rows x 2 columns],            alpha       beta\n",
      "0.1_1   0.125015   1.220264\n",
      "0.1_10  0.147119   5.102489\n",
      "0.1_15  0.166046   6.647032\n",
      "0.1_20  0.127799  20.228601\n",
      "0.1_25  0.202353  10.595334\n",
      "...          ...        ...\n",
      "0.9_30  0.663786   9.937123\n",
      "0.9_35  0.636919  14.141226\n",
      "0.9_40  0.707154  19.377613\n",
      "0.9_5   0.822690   6.752685\n",
      "0.9_7   0.795891   6.485968\n",
      "\n",
      "[99 rows x 2 columns],            alpha       beta\n",
      "0.1_1   0.173170   1.207450\n",
      "0.1_10  0.139057   7.629228\n",
      "0.1_15  0.124828  13.486463\n",
      "0.1_20  0.085203  16.997939\n",
      "0.1_25  0.196615  18.546443\n",
      "...          ...        ...\n",
      "0.9_30  0.548702  15.727286\n",
      "0.9_35  0.571785  10.237803\n",
      "0.9_40  0.671692  10.267569\n",
      "0.9_5   0.769786   6.798982\n",
      "0.9_7   0.724347   7.258883\n",
      "\n",
      "[99 rows x 2 columns],            alpha       beta\n",
      "0.1_1   0.180664   1.826489\n",
      "0.1_10  0.154777   5.753691\n",
      "0.1_15  0.187258  10.287348\n",
      "0.1_20  0.116261  26.310622\n",
      "0.1_25  0.140831  13.879073\n",
      "...          ...        ...\n",
      "0.9_30  0.675928   7.985665\n",
      "0.9_35  0.540890  17.217745\n",
      "0.9_40  0.703562  10.615537\n",
      "0.9_5   0.834083   6.011410\n",
      "0.9_7   0.825680   4.558626\n",
      "\n",
      "[99 rows x 2 columns],            alpha       beta\n",
      "0.1_1   0.261626   2.104944\n",
      "0.1_10  0.177900   6.640608\n",
      "0.1_15  0.159460  10.669861\n",
      "0.1_20  0.147456  10.077931\n",
      "0.1_25  0.142127  26.926936\n",
      "...          ...        ...\n",
      "0.9_30  0.687396  11.201718\n",
      "0.9_35  0.543397  15.895240\n",
      "0.9_40  0.593433  15.187227\n",
      "0.9_5   0.783421   4.659799\n",
      "0.9_7   0.667142   5.891262\n",
      "\n",
      "[99 rows x 2 columns],            alpha       beta\n",
      "0.1_1   0.251573   1.089474\n",
      "0.1_10  0.112143   8.443604\n",
      "0.1_15  0.158496   9.984770\n",
      "0.1_20  0.225914   6.425462\n",
      "0.1_25  0.316691  13.104576\n",
      "...          ...        ...\n",
      "0.9_30  0.685635   8.350067\n",
      "0.9_35  0.709634  14.163153\n",
      "0.9_40  0.615430  13.756253\n",
      "0.9_5   0.861207   5.931370\n",
      "0.9_7   0.781341   7.776584\n",
      "\n",
      "[99 rows x 2 columns],            alpha       beta\n",
      "0.1_1   0.449923   0.993560\n",
      "0.1_10  0.183585   7.410274\n",
      "0.1_15  0.220735  10.212270\n",
      "0.1_20  0.136603  13.430862\n",
      "0.1_25  0.227874   8.946148\n",
      "...          ...        ...\n",
      "0.9_30  0.592054   7.253665\n",
      "0.9_35  0.588597   8.654813\n",
      "0.9_40  0.285968  19.426000\n",
      "0.9_5   0.805468   6.288442\n",
      "0.9_7   0.814511   6.294606\n",
      "\n",
      "[99 rows x 2 columns],            alpha       beta\n",
      "0.1_1   0.334907   1.190355\n",
      "0.1_10  0.119628   8.376340\n",
      "0.1_15  0.281708   5.562425\n",
      "0.1_20  0.144182  15.459640\n",
      "0.1_25  0.267088   7.808314\n",
      "...          ...        ...\n",
      "0.9_30  0.747121   8.254701\n",
      "0.9_35  0.746826  18.206521\n",
      "0.9_40  0.710031   9.423629\n",
      "0.9_5   0.784131   4.166546\n",
      "0.9_7   0.866193   6.060758\n",
      "\n",
      "[99 rows x 2 columns],            alpha       beta\n",
      "0.1_1   0.263179   1.907956\n",
      "0.1_10  0.135255   8.096407\n",
      "0.1_15  0.197022  10.782269\n",
      "0.1_20  0.133460  18.422211\n",
      "0.1_25  0.197528  19.636487\n",
      "...          ...        ...\n",
      "0.9_30  0.612983  10.641313\n",
      "0.9_35  0.501388  31.053416\n",
      "0.9_40  0.716609  12.117165\n",
      "0.9_5   0.876539   5.909768\n",
      "0.9_7   0.754703   4.874710\n",
      "\n",
      "[99 rows x 2 columns],            alpha       beta\n",
      "0.1_1   0.227603   1.120730\n",
      "0.1_10  0.145770  10.425706\n",
      "0.1_15  0.109841  16.490592\n",
      "0.1_20  0.139741  15.958368\n",
      "0.1_25  0.181285  18.632700\n",
      "...          ...        ...\n",
      "0.9_30  0.719625  10.965373\n",
      "0.9_35  0.513656  12.307280\n",
      "0.9_40  0.740470  15.286975\n",
      "0.9_5   0.823917   4.562065\n",
      "0.9_7   0.776435   4.731422\n",
      "\n",
      "[99 rows x 2 columns],            alpha       beta\n",
      "0.1_1   0.163282   0.905455\n",
      "0.1_10  0.133601   6.428421\n",
      "0.1_15  0.137199   9.823898\n",
      "0.1_20  0.138439   9.932629\n",
      "0.1_25  0.227231   9.484173\n",
      "...          ...        ...\n",
      "0.9_30  0.646424   8.216738\n",
      "0.9_35  0.372316  21.760978\n",
      "0.9_40  0.618468   8.364340\n",
      "0.9_5   0.869009   5.963592\n",
      "0.9_7   0.819200   6.235692\n",
      "\n",
      "[99 rows x 2 columns],            alpha       beta\n",
      "0.1_1   0.358993   0.581035\n",
      "0.1_10  0.091247  11.426494\n",
      "0.1_15  0.139141   7.992413\n",
      "0.1_20  0.259350   9.344453\n",
      "0.1_25  0.099919  19.412114\n",
      "...          ...        ...\n",
      "0.9_30  0.550005  14.158609\n",
      "0.9_35  0.700059   8.190065\n",
      "0.9_40  0.688179  14.421766\n",
      "0.9_5   0.893339   5.480240\n",
      "0.9_7   0.792542   6.199702\n",
      "\n",
      "[99 rows x 2 columns],            alpha       beta\n",
      "0.1_1   0.485766   0.885453\n",
      "0.1_10  0.174873   6.645938\n",
      "0.1_15  0.166914   9.338550\n",
      "0.1_20  0.167291  12.484814\n",
      "0.1_25  0.270460   9.308941\n",
      "...          ...        ...\n",
      "0.9_30  0.744807   8.831780\n",
      "0.9_35  0.582564  16.555656\n",
      "0.9_40  0.387628  15.698643\n",
      "0.9_5   0.835165   6.457683\n",
      "0.9_7   0.768777   6.615742\n",
      "\n",
      "[99 rows x 2 columns],            alpha       beta\n",
      "0.1_1   0.209391   1.768740\n",
      "0.1_10  0.350430   5.076182\n",
      "0.1_15  0.165785   8.352499\n",
      "0.1_20  0.164926  15.881038\n",
      "0.1_25  0.186421  10.957564\n",
      "...          ...        ...\n",
      "0.9_30  0.751785   7.409615\n",
      "0.9_35  0.696555  10.012013\n",
      "0.9_40  0.399251  12.438076\n",
      "0.9_5   0.854052   6.258608\n",
      "0.9_7   0.859614   6.199673\n",
      "\n",
      "[99 rows x 2 columns],            alpha       beta\n",
      "0.1_1   0.343317   0.972202\n",
      "0.1_10  0.197400   5.621052\n",
      "0.1_15  0.202802   8.773011\n",
      "0.1_20  0.205129  11.314207\n",
      "0.1_25  0.209606  17.507837\n",
      "...          ...        ...\n",
      "0.9_30  0.587679  14.065315\n",
      "0.9_35  0.722452   9.667923\n",
      "0.9_40  0.679176  12.551093\n",
      "0.9_5   0.825414   4.686648\n",
      "0.9_7   0.824777   6.285380\n",
      "\n",
      "[99 rows x 2 columns],            alpha       beta\n",
      "0.1_1   0.169226   1.748007\n",
      "0.1_10  0.149228   7.189486\n",
      "0.1_15  0.191163   6.545385\n",
      "0.1_20  0.179477  12.201177\n",
      "0.1_25  0.145665  19.217434\n",
      "...          ...        ...\n",
      "0.9_30  0.776087  15.602555\n",
      "0.9_35  0.630336   8.768996\n",
      "0.9_40  0.747313  10.354114\n",
      "0.9_5   0.852296   5.991322\n",
      "0.9_7   0.800129   4.659901\n",
      "\n",
      "[99 rows x 2 columns],            alpha       beta\n",
      "0.1_1   0.265012   0.871158\n",
      "0.1_10  0.249552   7.278045\n",
      "0.1_15  0.145939   8.708447\n",
      "0.1_20  0.129986  10.798560\n",
      "0.1_25  0.124178  21.483879\n",
      "...          ...        ...\n",
      "0.9_30  0.692528   7.380081\n",
      "0.9_35  0.738466  12.041457\n",
      "0.9_40  0.633647   9.388077\n",
      "0.9_5   0.812612   4.045409\n",
      "0.9_7   0.828394   6.068164\n",
      "\n",
      "[99 rows x 2 columns],            alpha       beta\n",
      "0.1_1   0.253523   0.766884\n",
      "0.1_10  0.148422   8.627791\n",
      "0.1_15  0.119888  13.376591\n",
      "0.1_20  0.164805  12.946787\n",
      "0.1_25  0.302012   9.911443\n",
      "...          ...        ...\n",
      "0.9_30  0.496279  11.858659\n",
      "0.9_35  0.472208  18.118253\n",
      "0.9_40  0.556391  19.025249\n",
      "0.9_5   0.834441   4.060860\n",
      "0.9_7   0.782999   6.464624\n",
      "\n",
      "[99 rows x 2 columns],            alpha       beta\n",
      "0.1_1   0.255917   0.940433\n",
      "0.1_10  0.111751  10.507376\n",
      "0.1_15  0.127246   9.988965\n",
      "0.1_20  0.161364  12.534291\n",
      "0.1_25  0.090952  26.123339\n",
      "...          ...        ...\n",
      "0.9_30  0.787609   7.981904\n",
      "0.9_35  0.490257  18.032645\n",
      "0.9_40  0.734793  14.299635\n",
      "0.9_5   0.869205   5.754714\n",
      "0.9_7   0.854358   6.272224\n",
      "\n",
      "[99 rows x 2 columns],            alpha       beta\n",
      "0.1_1   0.277295   1.030968\n",
      "0.1_10  0.119235   8.440339\n",
      "0.1_15  0.304755   7.575091\n",
      "0.1_20  0.226096   8.908261\n",
      "0.1_25  0.100789  28.513303\n",
      "...          ...        ...\n",
      "0.9_30  0.755679   9.194993\n",
      "0.9_35  0.507692  15.589135\n",
      "0.9_40  0.709860  13.119869\n",
      "0.9_5   0.805877   7.255302\n",
      "0.9_7   0.819820   6.307472\n",
      "\n",
      "[99 rows x 2 columns],            alpha       beta\n",
      "0.1_1   0.395791   1.130611\n",
      "0.1_10  0.138360   8.226152\n",
      "0.1_15  0.129638  10.842253\n",
      "0.1_20  0.126610  19.432003\n",
      "0.1_25  0.170235  11.587076\n",
      "...          ...        ...\n",
      "0.9_30  0.593530   9.513398\n",
      "0.9_35  0.670933   9.471928\n",
      "0.9_40  0.784396  18.242178\n",
      "0.9_5   0.869566   4.337846\n",
      "0.9_7   0.831331   5.998647\n",
      "\n",
      "[99 rows x 2 columns],            alpha       beta\n",
      "0.1_1   0.394529   1.126702\n",
      "0.1_10  0.186683   8.181588\n",
      "0.1_15  0.149251  11.344933\n",
      "0.1_20  0.195729  10.864843\n",
      "0.1_25  0.073129  27.634748\n",
      "...          ...        ...\n",
      "0.9_30  0.734855  10.247553\n",
      "0.9_35  0.628654  14.197892\n",
      "0.9_40  0.590542   9.134088\n",
      "0.9_5   0.788965   4.688807\n",
      "0.9_7   0.775574   7.827958\n",
      "\n",
      "[99 rows x 2 columns],            alpha       beta\n",
      "0.1_1   0.196241   1.082417\n",
      "0.1_10  0.149646   7.231602\n",
      "0.1_15  0.188899   9.313826\n",
      "0.1_20  0.119855  18.457933\n",
      "0.1_25  0.192892   8.795772\n",
      "...          ...        ...\n",
      "0.9_30  0.752447  10.464692\n",
      "0.9_35  0.623579   9.218047\n",
      "0.9_40  0.701230  17.905056\n",
      "0.9_5   0.601097   5.392149\n",
      "0.9_7   0.815951   6.233320\n",
      "\n",
      "[99 rows x 2 columns],            alpha       beta\n",
      "0.1_1   0.343236   0.745911\n",
      "0.1_10  0.138158   8.783065\n",
      "0.1_15  0.203599   6.924629\n",
      "0.1_20  0.149411   9.713335\n",
      "0.1_25  0.272392   8.663490\n",
      "...          ...        ...\n",
      "0.9_30  0.541581  21.786246\n",
      "0.9_35  0.568409  11.496611\n",
      "0.9_40  0.699816  10.005612\n",
      "0.9_5   0.620158   5.237385\n",
      "0.9_7   0.759395   4.874206\n",
      "\n",
      "[99 rows x 2 columns],            alpha       beta\n",
      "0.1_1   0.456501   0.914438\n",
      "0.1_10  0.145498   8.978789\n",
      "0.1_15  0.186919   9.047708\n",
      "0.1_20  0.260512   6.362577\n",
      "0.1_25  0.123772  24.887620\n",
      "...          ...        ...\n",
      "0.9_30  0.567657  13.035280\n",
      "0.9_35  0.768914  21.502929\n",
      "0.9_40  0.633007  14.459213\n",
      "0.9_5   0.849112   6.145449\n",
      "0.9_7   0.880271   5.836865\n",
      "\n",
      "[99 rows x 2 columns],            alpha       beta\n",
      "0.1_1   0.215480   0.874708\n",
      "0.1_10  0.127446   7.082706\n",
      "0.1_15  0.156133   8.489767\n",
      "0.1_20  0.139650   9.256253\n",
      "0.1_25  0.120504  26.910529\n",
      "...          ...        ...\n",
      "0.9_30  0.665405   9.895652\n",
      "0.9_35  0.635378  13.244594\n",
      "0.9_40  0.563197  14.341005\n",
      "0.9_5   0.821385   6.392887\n",
      "0.9_7   0.839445   6.165226\n",
      "\n",
      "[99 rows x 2 columns],            alpha       beta\n",
      "0.1_1   0.251970   0.790561\n",
      "0.1_10  0.121974   8.346540\n",
      "0.1_15  0.206298   7.275405\n",
      "0.1_20  0.237899   9.530241\n",
      "0.1_25  0.220185   9.294040\n",
      "...          ...        ...\n",
      "0.9_30  0.617501  10.151825\n",
      "0.9_35  0.741428   9.778827\n",
      "0.9_40  0.602786  17.856215\n",
      "0.9_5   0.787740   4.640149\n",
      "0.9_7   0.793596   8.689197\n",
      "\n",
      "[99 rows x 2 columns],            alpha       beta\n",
      "0.1_1   0.261381   1.162247\n",
      "0.1_10  0.118653   7.248590\n",
      "0.1_15  0.141636   8.607585\n",
      "0.1_20  0.111774  21.494582\n",
      "0.1_25  0.130080  16.110568\n",
      "...          ...        ...\n",
      "0.9_30  0.728644   7.626157\n",
      "0.9_35  0.487812  11.459847\n",
      "0.9_40  0.764790  13.395515\n",
      "0.9_5   0.755101   6.974554\n",
      "0.9_7   0.840572   6.611305\n",
      "\n",
      "[99 rows x 2 columns],            alpha       beta\n",
      "0.1_1   0.294572   0.785432\n",
      "0.1_10  0.176807   7.079039\n",
      "0.1_15  0.080336  18.306539\n",
      "0.1_20  0.170462   8.006327\n",
      "0.1_25  0.219652  10.969990\n",
      "...          ...        ...\n",
      "0.9_30  0.620801   8.822769\n",
      "0.9_35  0.386043  16.896103\n",
      "0.9_40  0.716002  14.059088\n",
      "0.9_5   0.783466   3.871554\n",
      "0.9_7   0.808208   6.087989\n",
      "\n",
      "[99 rows x 2 columns],            alpha       beta\n",
      "0.1_1   0.372799   0.685641\n",
      "0.1_10  0.133113   7.087912\n",
      "0.1_15  0.137917   8.825031\n",
      "0.1_20  0.171713   7.530843\n",
      "0.1_25  0.262374  11.315444\n",
      "...          ...        ...\n",
      "0.9_30  0.780517  12.174949\n",
      "0.9_35  0.501894  16.026655\n",
      "0.9_40  0.472320  29.836657\n",
      "0.9_5   0.746120   5.369152\n",
      "0.9_7   0.765636   7.414157\n",
      "\n",
      "[99 rows x 2 columns],            alpha       beta\n",
      "0.1_1   0.521778   0.832468\n",
      "0.1_10  0.271322   4.443073\n",
      "0.1_15  0.184426   6.994097\n",
      "0.1_20  0.295537   7.251223\n",
      "0.1_25  0.390644   7.042064\n",
      "...          ...        ...\n",
      "0.9_30  0.769697  11.986273\n",
      "0.9_35  0.648673   8.834193\n",
      "0.9_40  0.628078  12.647862\n",
      "0.9_5   0.828790   6.046096\n",
      "0.9_7   0.804271   6.404830\n",
      "\n",
      "[99 rows x 2 columns],            alpha       beta\n",
      "0.1_1   0.344282   0.761121\n",
      "0.1_10  0.167224   8.197787\n",
      "0.1_15  0.170502   8.673128\n",
      "0.1_20  0.152613  11.589594\n",
      "0.1_25  0.080672  29.111583\n",
      "...          ...        ...\n",
      "0.9_30  0.648335  13.494783\n",
      "0.9_35  0.743293  12.463520\n",
      "0.9_40  0.685498   9.767621\n",
      "0.9_5   0.849164   6.537095\n",
      "0.9_7   0.794004   6.354941\n",
      "\n",
      "[99 rows x 2 columns],            alpha       beta\n",
      "0.1_1   0.513079   0.817507\n",
      "0.1_10  0.174182   5.403290\n",
      "0.1_15  0.182076  12.537394\n",
      "0.1_20  0.213565   8.435142\n",
      "0.1_25  0.173740  14.975241\n",
      "...          ...        ...\n",
      "0.9_30  0.686058   9.569354\n",
      "0.9_35  0.638237  15.549920\n",
      "0.9_40  0.738025  16.142331\n",
      "0.9_5   0.635760   9.116730\n",
      "0.9_7   0.878137   5.602856\n",
      "\n",
      "[99 rows x 2 columns],            alpha       beta\n",
      "0.1_1   0.227464   1.116565\n",
      "0.1_10  0.199939   5.936689\n",
      "0.1_15  0.170683   8.737473\n",
      "0.1_20  0.213414  11.013590\n",
      "0.1_25  0.264540  12.579727\n",
      "...          ...        ...\n",
      "0.9_30  0.701691  15.964593\n",
      "0.9_35  0.636517  13.920993\n",
      "0.9_40  0.727071  14.781195\n",
      "0.9_5   0.855267   5.995881\n",
      "0.9_7   0.778253   8.284127\n",
      "\n",
      "[99 rows x 2 columns],            alpha       beta\n",
      "0.1_1   0.140173   1.443031\n",
      "0.1_10  0.090563  12.633911\n",
      "0.1_15  0.162386  10.973787\n",
      "0.1_20  0.147282   9.961359\n",
      "0.1_25  0.075695  38.994715\n",
      "...          ...        ...\n",
      "0.9_30  0.575421   9.362788\n",
      "0.9_35  0.645148   8.922270\n",
      "0.9_40  0.623271  12.395451\n",
      "0.9_5   0.826818   6.494189\n",
      "0.9_7   0.766954   6.920678\n",
      "\n",
      "[99 rows x 2 columns],            alpha       beta\n",
      "0.1_1   0.167583   1.129900\n",
      "0.1_10  0.132300   7.026312\n",
      "0.1_15  0.227457   6.573683\n",
      "0.1_20  0.208108   9.303034\n",
      "0.1_25  0.197701  10.845635\n",
      "...          ...        ...\n",
      "0.9_30  0.420825  20.007110\n",
      "0.9_35  0.614040  10.891490\n",
      "0.9_40  0.687428  12.620165\n",
      "0.9_5   0.821822   4.762972\n",
      "0.9_7   0.877877   5.686976\n",
      "\n",
      "[99 rows x 2 columns],            alpha       beta\n",
      "0.1_1   0.223345   0.764938\n",
      "0.1_10  0.219011   8.113653\n",
      "0.1_15  0.151598  10.059394\n",
      "0.1_20  0.185215  11.152620\n",
      "0.1_25  0.248668  13.001078\n",
      "...          ...        ...\n",
      "0.9_30  0.385909  13.960788\n",
      "0.9_35  0.739097  11.058635\n",
      "0.9_40  0.553647  15.542738\n",
      "0.9_5   0.876700   5.782981\n",
      "0.9_7   0.838871   6.132017\n",
      "\n",
      "[99 rows x 2 columns],            alpha       beta\n",
      "0.1_1   0.542448   0.974321\n",
      "0.1_10  0.242133   5.778295\n",
      "0.1_15  0.239499   7.031105\n",
      "0.1_20  0.140852  11.183564\n",
      "0.1_25  0.207412  10.903346\n",
      "...          ...        ...\n",
      "0.9_30  0.660685   8.970260\n",
      "0.9_35  0.699802  14.142148\n",
      "0.9_40  0.586179   8.626111\n",
      "0.9_5   0.687735   4.212306\n",
      "0.9_7   0.814233   6.907298\n",
      "\n",
      "[99 rows x 2 columns],            alpha       beta\n",
      "0.1_1   0.411986   0.976414\n",
      "0.1_10  0.130449   9.496330\n",
      "0.1_15  0.082424  21.705316\n",
      "0.1_20  0.266097   7.670269\n",
      "0.1_25  0.207392   9.765564\n",
      "...          ...        ...\n",
      "0.9_30  0.643699  10.655881\n",
      "0.9_35  0.511315  14.794824\n",
      "0.9_40  0.570153  16.091578\n",
      "0.9_5   0.805952   6.743689\n",
      "0.9_7   0.731499   7.192675\n",
      "\n",
      "[99 rows x 2 columns],            alpha       beta\n",
      "0.1_1   0.521461   1.211356\n",
      "0.1_10  0.177879   7.249270\n",
      "0.1_15  0.234508   6.866141\n",
      "0.1_20  0.176808  12.304854\n",
      "0.1_25  0.151723  16.236434\n",
      "...          ...        ...\n",
      "0.9_30  0.720138   9.049869\n",
      "0.9_35  0.528994  18.741142\n",
      "0.9_40  0.559033  20.872735\n",
      "0.9_5   0.791652   4.852922\n",
      "0.9_7   0.419485  12.528761\n",
      "\n",
      "[99 rows x 2 columns],            alpha       beta\n",
      "0.1_1   0.341071   0.779231\n",
      "0.1_10  0.152970   7.424831\n",
      "0.1_15  0.196881   8.458213\n",
      "0.1_20  0.230770   6.830898\n",
      "0.1_25  0.106483  27.527045\n",
      "...          ...        ...\n",
      "0.9_30  0.699124  12.310439\n",
      "0.9_35  0.785927  11.228706\n",
      "0.9_40  0.563696  12.710091\n",
      "0.9_5   0.629356   6.087848\n",
      "0.9_7   0.824003   6.861225\n",
      "\n",
      "[99 rows x 2 columns],            alpha       beta\n",
      "0.1_1   0.149548   1.169827\n",
      "0.1_10  0.117750   9.568736\n",
      "0.1_15  0.150681   8.613221\n",
      "0.1_20  0.189399  10.474634\n",
      "0.1_25  0.164959  12.804686\n",
      "...          ...        ...\n",
      "0.9_30  0.667432   7.969937\n",
      "0.9_35  0.621662  14.025680\n",
      "0.9_40  0.578143  30.349666\n",
      "0.9_5   0.796100   6.717059\n",
      "0.9_7   0.740196   4.799120\n",
      "\n",
      "[99 rows x 2 columns],            alpha       beta\n",
      "0.1_1   0.118662   2.091322\n",
      "0.1_10  0.173556   7.538236\n",
      "0.1_15  0.178598   8.936845\n",
      "0.1_20  0.187138  12.585272\n",
      "0.1_25  0.129273  18.265032\n",
      "...          ...        ...\n",
      "0.9_30  0.509286  16.567825\n",
      "0.9_35  0.541959  11.566164\n",
      "0.9_40  0.619866  13.987988\n",
      "0.9_5   0.769298   4.860664\n",
      "0.9_7   0.829070   6.108685\n",
      "\n",
      "[99 rows x 2 columns],            alpha       beta\n",
      "0.1_1   0.277296   0.887823\n",
      "0.1_10  0.154379   7.063116\n",
      "0.1_15  0.160572   7.958028\n",
      "0.1_20  0.169958   9.760029\n",
      "0.1_25  0.177108   9.229711\n",
      "...          ...        ...\n",
      "0.9_30  0.615961  14.488127\n",
      "0.9_35  0.742926   8.042422\n",
      "0.9_40  0.767848   8.169001\n",
      "0.9_5   0.808588   4.918429\n",
      "0.9_7   0.757030   6.840486\n",
      "\n",
      "[99 rows x 2 columns],            alpha       beta\n",
      "0.1_1   0.270174   1.345353\n",
      "0.1_10  0.122625   9.087959\n",
      "0.1_15  0.147970  15.560718\n",
      "0.1_20  0.204373  12.001967\n",
      "0.1_25  0.293027   9.772856\n",
      "...          ...        ...\n",
      "0.9_30  0.717709   9.332657\n",
      "0.9_35  0.680747  13.302476\n",
      "0.9_40  0.660746  13.345430\n",
      "0.9_5   0.889770   5.582565\n",
      "0.9_7   0.808144   7.530450\n",
      "\n",
      "[99 rows x 2 columns],            alpha       beta\n",
      "0.1_1   0.260366   1.395738\n",
      "0.1_10  0.248928   4.758593\n",
      "0.1_15  0.137385  10.765054\n",
      "0.1_20  0.118321  16.736525\n",
      "0.1_25  0.223606  10.390786\n",
      "...          ...        ...\n",
      "0.9_30  0.607379   9.018690\n",
      "0.9_35  0.496219   9.291936\n",
      "0.9_40  0.624058  12.551716\n",
      "0.9_5   0.878018   4.165260\n",
      "0.9_7   0.733385   7.143206\n",
      "\n",
      "[99 rows x 2 columns],            alpha       beta\n",
      "0.1_1   0.392488   1.291461\n",
      "0.1_10  0.168682   9.276729\n",
      "0.1_15  0.131376   8.608407\n",
      "0.1_20  0.219822   9.749457\n",
      "0.1_25  0.269740   9.210835\n",
      "...          ...        ...\n",
      "0.9_30  0.750488   9.767421\n",
      "0.9_35  0.537083  11.532096\n",
      "0.9_40  0.561552  17.549793\n",
      "0.9_5   0.772953   4.963118\n",
      "0.9_7   0.792815   4.933841\n",
      "\n",
      "[99 rows x 2 columns],            alpha       beta\n",
      "0.1_1   0.320054   1.236331\n",
      "0.1_10  0.316109   5.356167\n",
      "0.1_15  0.157998   8.638821\n",
      "0.1_20  0.165782  11.111938\n",
      "0.1_25  0.136102  15.229391\n",
      "...          ...        ...\n",
      "0.9_30  0.543956  25.824281\n",
      "0.9_35  0.720023  11.343898\n",
      "0.9_40  0.745407   8.071962\n",
      "0.9_5   0.772502   5.112240\n",
      "0.9_7   0.808491   6.062189\n",
      "\n",
      "[99 rows x 2 columns],            alpha       beta\n",
      "0.1_1   0.499512   0.804496\n",
      "0.1_10  0.131966   8.467004\n",
      "0.1_15  0.169013  10.919610\n",
      "0.1_20  0.189059   8.238576\n",
      "0.1_25  0.174965  24.364882\n",
      "...          ...        ...\n",
      "0.9_30  0.661517   9.451930\n",
      "0.9_35  0.622205  10.438110\n",
      "0.9_40  0.739290  16.339846\n",
      "0.9_5   0.876241   4.302264\n",
      "0.9_7   0.799402   6.861254\n",
      "\n",
      "[99 rows x 2 columns],            alpha       beta\n",
      "0.1_1   0.176234   1.250838\n",
      "0.1_10  0.143724   6.566734\n",
      "0.1_15  0.186883   9.288451\n",
      "0.1_20  0.136725  15.194143\n",
      "0.1_25  0.101641  23.164013\n",
      "...          ...        ...\n",
      "0.9_30  0.667242  15.140109\n",
      "0.9_35  0.311606  18.175496\n",
      "0.9_40  0.759878  12.168553\n",
      "0.9_5   0.788541   4.467360\n",
      "0.9_7   0.851894   5.988471\n",
      "\n",
      "[99 rows x 2 columns],            alpha       beta\n",
      "0.1_1   0.136000   1.077071\n",
      "0.1_10  0.156951   9.265134\n",
      "0.1_15  0.137687  10.489950\n",
      "0.1_20  0.170096   9.146028\n",
      "0.1_25  0.168236  14.904943\n",
      "...          ...        ...\n",
      "0.9_30  0.488519  10.985501\n",
      "0.9_35  0.662781   8.609984\n",
      "0.9_40  0.544177  13.100978\n",
      "0.9_5   0.871224   4.269756\n",
      "0.9_7   0.814975   6.805993\n",
      "\n",
      "[99 rows x 2 columns],            alpha       beta\n",
      "0.1_1   0.179485   1.083878\n",
      "0.1_10  0.201779   6.978013\n",
      "0.1_15  0.260030   6.144575\n",
      "0.1_20  0.143739  15.126334\n",
      "0.1_25  0.181477  12.005190\n",
      "...          ...        ...\n",
      "0.9_30  0.594605  10.186474\n",
      "0.9_35  0.659767  22.867963\n",
      "0.9_40  0.700136  11.256759\n",
      "0.9_5   0.854397   4.414667\n",
      "0.9_7   0.845015   5.518745\n",
      "\n",
      "[99 rows x 2 columns],            alpha       beta\n",
      "0.1_1   0.347159   0.879031\n",
      "0.1_10  0.149444   8.354985\n",
      "0.1_15  0.196944   8.678032\n",
      "0.1_20  0.202081   8.401598\n",
      "0.1_25  0.194386  11.562352\n",
      "...          ...        ...\n",
      "0.9_30  0.747143   9.152526\n",
      "0.9_35  0.677781  16.012806\n",
      "0.9_40  0.637993  14.873313\n",
      "0.9_5   0.809561   4.673531\n",
      "0.9_7   0.798859   7.291136\n",
      "\n",
      "[99 rows x 2 columns],            alpha       beta\n",
      "0.1_1   0.096869   1.815606\n",
      "0.1_10  0.203162   5.757593\n",
      "0.1_15  0.242803   7.876921\n",
      "0.1_20  0.206931   9.383141\n",
      "0.1_25  0.156944  10.992111\n",
      "...          ...        ...\n",
      "0.9_30  0.649930  10.045806\n",
      "0.9_35  0.699950  16.386863\n",
      "0.9_40  0.417799  20.802012\n",
      "0.9_5   0.831185   6.030527\n",
      "0.9_7   0.865685   6.011545\n",
      "\n",
      "[99 rows x 2 columns],            alpha       beta\n",
      "0.1_1   0.387027   1.121630\n",
      "0.1_10  0.098925  14.534648\n",
      "0.1_15  0.158433   7.548118\n",
      "0.1_20  0.177841  12.746961\n",
      "0.1_25  0.144484   9.360051\n",
      "...          ...        ...\n",
      "0.9_30  0.613313  10.010577\n",
      "0.9_35  0.681072  10.052229\n",
      "0.9_40  0.782290  13.527534\n",
      "0.9_5   0.735016   5.249012\n",
      "0.9_7   0.703930   7.706011\n",
      "\n",
      "[99 rows x 2 columns],            alpha       beta\n",
      "0.1_1   0.288164   1.019715\n",
      "0.1_10  0.260306   5.357455\n",
      "0.1_15  0.191069  11.377182\n",
      "0.1_20  0.221995   8.897178\n",
      "0.1_25  0.337609   5.551169\n",
      "...          ...        ...\n",
      "0.9_30  0.669012   8.612220\n",
      "0.9_35  0.462484  11.622215\n",
      "0.9_40  0.514504  10.884051\n",
      "0.9_5   0.837632   4.017479\n",
      "0.9_7   0.829618   6.143407\n",
      "\n",
      "[99 rows x 2 columns],            alpha       beta\n",
      "0.1_1   0.192425   1.572087\n",
      "0.1_10  0.191862   7.378791\n",
      "0.1_15  0.101739  11.374401\n",
      "0.1_20  0.143901  11.332319\n",
      "0.1_25  0.200293  11.957702\n",
      "...          ...        ...\n",
      "0.9_30  0.706101   8.268516\n",
      "0.9_35  0.662518  12.671550\n",
      "0.9_40  0.771269   9.252933\n",
      "0.9_5   0.771003   6.177528\n",
      "0.9_7   0.874630   6.069783\n",
      "\n",
      "[99 rows x 2 columns],            alpha       beta\n",
      "0.1_1   0.257297   0.720639\n",
      "0.1_10  0.183918   5.522600\n",
      "0.1_15  0.103815  12.366069\n",
      "0.1_20  0.215471   7.970043\n",
      "0.1_25  0.104580  21.719446\n",
      "...          ...        ...\n",
      "0.9_30  0.770370  11.212807\n",
      "0.9_35  0.685199  15.128214\n",
      "0.9_40  0.513707  17.742468\n",
      "0.9_5   0.865006   5.852176\n",
      "0.9_7   0.784088   5.906468\n",
      "\n",
      "[99 rows x 2 columns],            alpha       beta\n",
      "0.1_1   0.478188   1.229813\n",
      "0.1_10  0.184963   7.049030\n",
      "0.1_15  0.187368   8.545939\n",
      "0.1_20  0.344009   7.513938\n",
      "0.1_25  0.162213  15.094190\n",
      "...          ...        ...\n",
      "0.9_30  0.545346  18.705184\n",
      "0.9_35  0.591454  15.463588\n",
      "0.9_40  0.703048  13.843468\n",
      "0.9_5   0.750998   8.304986\n",
      "0.9_7   0.798923   6.401364\n",
      "\n",
      "[99 rows x 2 columns],            alpha       beta\n",
      "0.1_1   0.201730   0.698529\n",
      "0.1_10  0.122562   7.523402\n",
      "0.1_15  0.117613  11.414546\n",
      "0.1_20  0.247885   8.602412\n",
      "0.1_25  0.401308  10.850802\n",
      "...          ...        ...\n",
      "0.9_30  0.610393  14.637332\n",
      "0.9_35  0.568227  11.163604\n",
      "0.9_40  0.716127  15.382634\n",
      "0.9_5   0.801579   4.810410\n",
      "0.9_7   0.856332   6.147434\n",
      "\n",
      "[99 rows x 2 columns],            alpha       beta\n",
      "0.1_1   0.246145   1.144539\n",
      "0.1_10  0.097647   9.377317\n",
      "0.1_15  0.105804  11.068225\n",
      "0.1_20  0.147114  16.218049\n",
      "0.1_25  0.248083   7.852594\n",
      "...          ...        ...\n",
      "0.9_30  0.419438  27.216472\n",
      "0.9_35  0.698214  10.161902\n",
      "0.9_40  0.608273  10.229420\n",
      "0.9_5   0.858571   4.491389\n",
      "0.9_7   0.814537   6.518996\n",
      "\n",
      "[99 rows x 2 columns],            alpha       beta\n",
      "0.1_1   0.283999   1.004739\n",
      "0.1_10  0.107107   8.399782\n",
      "0.1_15  0.152454   8.965366\n",
      "0.1_20  0.101794  17.562019\n",
      "0.1_25  0.253510   7.429339\n",
      "...          ...        ...\n",
      "0.9_30  0.521046  14.460657\n",
      "0.9_35  0.566775  10.580673\n",
      "0.9_40  0.565602  17.278559\n",
      "0.9_5   0.821068   5.908820\n",
      "0.9_7   0.713929   6.966419\n",
      "\n",
      "[99 rows x 2 columns],            alpha       beta\n",
      "0.1_1   0.333924   1.013162\n",
      "0.1_10  0.215947   5.227406\n",
      "0.1_15  0.150065  11.496364\n",
      "0.1_20  0.104332  17.128931\n",
      "0.1_25  0.190923  12.617287\n",
      "...          ...        ...\n",
      "0.9_30  0.769029   9.929404\n",
      "0.9_35  0.660995  11.266263\n",
      "0.9_40  0.685109   9.177352\n",
      "0.9_5   0.804093   7.072190\n",
      "0.9_7   0.821880   6.360999\n",
      "\n",
      "[99 rows x 2 columns],            alpha       beta\n",
      "0.1_1   0.394546   1.106343\n",
      "0.1_10  0.146788   8.527724\n",
      "0.1_15  0.149244  10.000149\n",
      "0.1_20  0.196422  15.237638\n",
      "0.1_25  0.194538  10.070759\n",
      "...          ...        ...\n",
      "0.9_30  0.684416  12.581504\n",
      "0.9_35  0.705035  16.507663\n",
      "0.9_40  0.777993  17.089700\n",
      "0.9_5   0.784229   4.707686\n",
      "0.9_7   0.845125   6.515565\n",
      "\n",
      "[99 rows x 2 columns],            alpha       beta\n",
      "0.1_1   0.327213   0.829544\n",
      "0.1_10  0.124628   9.341355\n",
      "0.1_15  0.174502   7.974355\n",
      "0.1_20  0.089856  32.192555\n",
      "0.1_25  0.245885  14.024829\n",
      "...          ...        ...\n",
      "0.9_30  0.726434  15.701086\n",
      "0.9_35  0.573651  14.710282\n",
      "0.9_40  0.659367   9.093631\n",
      "0.9_5   0.868582   5.728413\n",
      "0.9_7   0.832387   6.070182\n",
      "\n",
      "[99 rows x 2 columns],            alpha       beta\n",
      "0.1_1   0.618019   0.995562\n",
      "0.1_10  0.189805   6.212477\n",
      "0.1_15  0.200773   8.303092\n",
      "0.1_20  0.212135   8.504078\n",
      "0.1_25  0.237202  10.782575\n",
      "...          ...        ...\n",
      "0.9_30  0.740338  10.004763\n",
      "0.9_35  0.704782  15.480641\n",
      "0.9_40  0.710501  13.525774\n",
      "0.9_5   0.816994   4.767175\n",
      "0.9_7   0.759899   7.084273\n",
      "\n",
      "[99 rows x 2 columns],            alpha       beta\n",
      "0.1_1   0.457628   1.437837\n",
      "0.1_10  0.148979   5.209760\n",
      "0.1_15  0.134429   9.179232\n",
      "0.1_20  0.178116  11.307740\n",
      "0.1_25  0.127318  18.746225\n",
      "...          ...        ...\n",
      "0.9_30  0.603274   8.471964\n",
      "0.9_35  0.697036   9.164464\n",
      "0.9_40  0.754767  12.905031\n",
      "0.9_5   0.697788   7.289957\n",
      "0.9_7   0.832018   6.815193\n",
      "\n",
      "[99 rows x 2 columns],            alpha       beta\n",
      "0.1_1   0.326462   0.882457\n",
      "0.1_10  0.162748   6.508983\n",
      "0.1_15  0.174713   9.620488\n",
      "0.1_20  0.152672  15.463722\n",
      "0.1_25  0.077466  29.290956\n",
      "...          ...        ...\n",
      "0.9_30  0.508602  10.284806\n",
      "0.9_35  0.671682   7.772679\n",
      "0.9_40  0.780998  17.175687\n",
      "0.9_5   0.836707   6.259350\n",
      "0.9_7   0.796952   6.875685\n",
      "\n",
      "[99 rows x 2 columns],            alpha       beta\n",
      "0.1_1   0.599425   0.987765\n",
      "0.1_10  0.146387   6.136315\n",
      "0.1_15  0.177315  11.112276\n",
      "0.1_20  0.190669   8.272779\n",
      "0.1_25  0.231026   9.012592\n",
      "...          ...        ...\n",
      "0.9_30  0.697217  14.425564\n",
      "0.9_35  0.648301  11.075011\n",
      "0.9_40  0.632920  15.425665\n",
      "0.9_5   0.834294   5.925725\n",
      "0.9_7   0.778265   7.531730\n",
      "\n",
      "[99 rows x 2 columns],            alpha       beta\n",
      "0.1_1   0.259468   0.709412\n",
      "0.1_10  0.174253   6.024622\n",
      "0.1_15  0.237618   9.347978\n",
      "0.1_20  0.190805   8.723518\n",
      "0.1_25  0.439468   6.655439\n",
      "...          ...        ...\n",
      "0.9_30  0.750110  12.151754\n",
      "0.9_35  0.736543  15.791888\n",
      "0.9_40  0.536647  13.476200\n",
      "0.9_5   0.771639   6.697402\n",
      "0.9_7   0.782200   6.497168\n",
      "\n",
      "[99 rows x 2 columns],            alpha       beta\n",
      "0.1_1   0.441683   0.488315\n",
      "0.1_10  0.135904   7.483418\n",
      "0.1_15  0.208970   7.082818\n",
      "0.1_20  0.154316   9.375502\n",
      "0.1_25  0.226491   8.712160\n",
      "...          ...        ...\n",
      "0.9_30  0.709531   9.503901\n",
      "0.9_35  0.764015   9.762659\n",
      "0.9_40  0.716811  14.866064\n",
      "0.9_5   0.652519   4.795926\n",
      "0.9_7   0.783028   6.819735\n",
      "\n",
      "[99 rows x 2 columns],            alpha       beta\n",
      "0.1_1   0.132633   1.137996\n",
      "0.1_10  0.162186   7.727377\n",
      "0.1_15  0.133132  18.589282\n",
      "0.1_20  0.126895  17.169072\n",
      "0.1_25  0.232220   8.092509\n",
      "...          ...        ...\n",
      "0.9_30  0.706281   8.350226\n",
      "0.9_35  0.671041  13.908236\n",
      "0.9_40  0.685358  14.087559\n",
      "0.9_5   0.638781   6.602449\n",
      "0.9_7   0.841759   6.295942\n",
      "\n",
      "[99 rows x 2 columns],            alpha       beta\n",
      "0.1_1   0.256582   0.722912\n",
      "0.1_10  0.153663   8.002637\n",
      "0.1_15  0.187768   8.253132\n",
      "0.1_20  0.087517  24.605213\n",
      "0.1_25  0.210081  10.150894\n",
      "...          ...        ...\n",
      "0.9_30  0.492223  19.862287\n",
      "0.9_35  0.729737  10.267373\n",
      "0.9_40  0.715223  13.238147\n",
      "0.9_5   0.729145   5.407475\n",
      "0.9_7   0.802727   6.479319\n",
      "\n",
      "[99 rows x 2 columns],            alpha       beta\n",
      "0.1_1   0.491603   0.761656\n",
      "0.1_10  0.128411   7.645516\n",
      "0.1_15  0.238587   7.062576\n",
      "0.1_20  0.250150   7.466897\n",
      "0.1_25  0.135805  18.907566\n",
      "...          ...        ...\n",
      "0.9_30  0.682182  13.406119\n",
      "0.9_35  0.679061  13.883641\n",
      "0.9_40  0.756259  13.680014\n",
      "0.9_5   0.749751   4.323267\n",
      "0.9_7   0.810644   6.158603\n",
      "\n",
      "[99 rows x 2 columns],            alpha       beta\n",
      "0.1_1   0.210020   1.071613\n",
      "0.1_10  0.101417  10.715252\n",
      "0.1_15  0.192563  12.653631\n",
      "0.1_20  0.092970  20.217683\n",
      "0.1_25  0.083521  27.904107\n",
      "...          ...        ...\n",
      "0.9_30  0.672839   7.722118\n",
      "0.9_35  0.559285  10.374851\n",
      "0.9_40  0.514595  17.726070\n",
      "0.9_5   0.722633   7.447535\n",
      "0.9_7   0.835030   6.151411\n",
      "\n",
      "[99 rows x 2 columns],            alpha       beta\n",
      "0.1_1   0.264072   1.440722\n",
      "0.1_10  0.135383   7.595479\n",
      "0.1_15  0.123575  15.794099\n",
      "0.1_20  0.186319   9.037908\n",
      "0.1_25  0.141641  15.167780\n",
      "...          ...        ...\n",
      "0.9_30  0.715761   8.508639\n",
      "0.9_35  0.645678   9.901685\n",
      "0.9_40  0.703909  11.276137\n",
      "0.9_5   0.825475   6.127128\n",
      "0.9_7   0.761315   8.136540\n",
      "\n",
      "[99 rows x 2 columns],            alpha       beta\n",
      "0.1_1   0.378083   1.563581\n",
      "0.1_10  0.177157   6.662285\n",
      "0.1_15  0.231996   7.577118\n",
      "0.1_20  0.224240   7.511714\n",
      "0.1_25  0.120532  22.454650\n",
      "...          ...        ...\n",
      "0.9_30  0.639339   8.298008\n",
      "0.9_35  0.676951  10.857850\n",
      "0.9_40  0.639966  14.198786\n",
      "0.9_5   0.772384   4.815152\n",
      "0.9_7   0.752152   6.915798\n",
      "\n",
      "[99 rows x 2 columns],            alpha       beta\n",
      "0.1_1   0.162300   0.903166\n",
      "0.1_10  0.178455   6.982412\n",
      "0.1_15  0.184092   8.282036\n",
      "0.1_20  0.213365  10.008629\n",
      "0.1_25  0.108647  14.811436\n",
      "...          ...        ...\n",
      "0.9_30  0.622706  14.561338\n",
      "0.9_35  0.657565   9.507424\n",
      "0.9_40  0.674156  17.808433\n",
      "0.9_5   0.744084   5.124602\n",
      "0.9_7   0.773320   6.777108\n",
      "\n",
      "[99 rows x 2 columns],            alpha       beta\n",
      "0.1_1   0.141216   1.378194\n",
      "0.1_10  0.153909   6.458205\n",
      "0.1_15  0.171726   8.770031\n",
      "0.1_20  0.126131  15.389266\n",
      "0.1_25  0.245697  12.337957\n",
      "...          ...        ...\n",
      "0.9_30  0.615502  14.142730\n",
      "0.9_35  0.705856  11.661737\n",
      "0.9_40  0.750791  17.798962\n",
      "0.9_5   0.800426   4.491951\n",
      "0.9_7   0.742318   4.162722\n",
      "\n",
      "[99 rows x 2 columns],            alpha       beta\n",
      "0.1_1   0.110110   2.674453\n",
      "0.1_10  0.158664   6.854575\n",
      "0.1_15  0.178718   8.088376\n",
      "0.1_20  0.184939   9.999932\n",
      "0.1_25  0.273820   9.696919\n",
      "...          ...        ...\n",
      "0.9_30  0.719503  15.221281\n",
      "0.9_35  0.739451  14.840342\n",
      "0.9_40  0.631653  15.720719\n",
      "0.9_5   0.872415   5.968280\n",
      "0.9_7   0.693486   7.503235\n",
      "\n",
      "[99 rows x 2 columns],            alpha       beta\n",
      "0.1_1   0.199064   1.060636\n",
      "0.1_10  0.165187   5.983782\n",
      "0.1_15  0.188339   9.479514\n",
      "0.1_20  0.147601  12.360838\n",
      "0.1_25  0.134127  17.903673\n",
      "...          ...        ...\n",
      "0.9_30  0.717585   9.915893\n",
      "0.9_35  0.603176  12.945157\n",
      "0.9_40  0.615962  17.261662\n",
      "0.9_5   0.858649   4.336256\n",
      "0.9_7   0.790774   7.806281\n",
      "\n",
      "[99 rows x 2 columns],            alpha       beta\n",
      "0.1_1   0.326412   1.033393\n",
      "0.1_10  0.120332   6.453059\n",
      "0.1_15  0.145284   9.202657\n",
      "0.1_20  0.143224  16.451073\n",
      "0.1_25  0.195156  12.321012\n",
      "...          ...        ...\n",
      "0.9_30  0.748060  13.587367\n",
      "0.9_35  0.657770  13.814234\n",
      "0.9_40  0.689546  14.477394\n",
      "0.9_5   0.876839   5.709370\n",
      "0.9_7   0.744057   6.475001\n",
      "\n",
      "[99 rows x 2 columns],            alpha       beta\n",
      "0.1_1   0.391013   0.752025\n",
      "0.1_10  0.143046   8.058092\n",
      "0.1_15  0.167883  10.931875\n",
      "0.1_20  0.217914  11.072706\n",
      "0.1_25  0.172524  15.136006\n",
      "...          ...        ...\n",
      "0.9_30  0.605951  12.030445\n",
      "0.9_35  0.750790  16.334748\n",
      "0.9_40  0.619542  17.608201\n",
      "0.9_5   0.747183   5.262333\n",
      "0.9_7   0.713938   6.271893\n",
      "\n",
      "[99 rows x 2 columns],            alpha       beta\n",
      "0.1_1   0.349954   0.969569\n",
      "0.1_10  0.139813   9.271907\n",
      "0.1_15  0.131330   9.455059\n",
      "0.1_20  0.144947  11.517205\n",
      "0.1_25  0.175746  12.350025\n",
      "...          ...        ...\n",
      "0.9_30  0.457501  11.067533\n",
      "0.9_35  0.678976   7.823630\n",
      "0.9_40  0.697609  16.685074\n",
      "0.9_5   0.819973   3.742785\n",
      "0.9_7   0.758513   7.755168\n",
      "\n",
      "[99 rows x 2 columns],            alpha       beta\n",
      "0.1_1   0.180399   1.175951\n",
      "0.1_10  0.127916   7.979620\n",
      "0.1_15  0.102110  19.265122\n",
      "0.1_20  0.319547   7.420022\n",
      "0.1_25  0.161097  16.832221\n",
      "...          ...        ...\n",
      "0.9_30  0.427629  20.081591\n",
      "0.9_35  0.591512  10.861712\n",
      "0.9_40  0.707636  13.103286\n",
      "0.9_5   0.848675   5.872787\n",
      "0.9_7   0.858205   5.875579\n",
      "\n",
      "[99 rows x 2 columns],            alpha       beta\n",
      "0.1_1   0.341432   0.983165\n",
      "0.1_10  0.164430   6.908859\n",
      "0.1_15  0.152031   9.218617\n",
      "0.1_20  0.173340   9.663244\n",
      "0.1_25  0.169657  14.108308\n",
      "...          ...        ...\n",
      "0.9_30  0.713075  10.613773\n",
      "0.9_35  0.651613  12.161418\n",
      "0.9_40  0.600314  14.355189\n",
      "0.9_5   0.841979   5.823103\n",
      "0.9_7   0.823709   6.671305\n",
      "\n",
      "[99 rows x 2 columns],            alpha       beta\n",
      "0.1_1   0.203481   1.358996\n",
      "0.1_10  0.176384   7.151337\n",
      "0.1_15  0.214202   7.085407\n",
      "0.1_20  0.157480  16.420776\n",
      "0.1_25  0.267201   8.182825\n",
      "...          ...        ...\n",
      "0.9_30  0.658039   9.072783\n",
      "0.9_35  0.655069  13.538528\n",
      "0.9_40  0.713313  15.476922\n",
      "0.9_5   0.841838   3.948053\n",
      "0.9_7   0.814155   6.580174\n",
      "\n",
      "[99 rows x 2 columns],            alpha       beta\n",
      "0.1_1   0.469889   1.325270\n",
      "0.1_10  0.139083   8.487916\n",
      "0.1_15  0.179720   8.238088\n",
      "0.1_20  0.231167   9.856511\n",
      "0.1_25  0.106773  25.708552\n",
      "...          ...        ...\n",
      "0.9_30  0.766122  11.019590\n",
      "0.9_35  0.721521   8.781500\n",
      "0.9_40  0.540484  11.566564\n",
      "0.9_5   0.854960   5.971858\n",
      "0.9_7   0.785016   6.506134\n",
      "\n",
      "[99 rows x 2 columns],            alpha       beta\n",
      "0.1_1   0.220327   0.996236\n",
      "0.1_10  0.209839   6.118628\n",
      "0.1_15  0.172067   8.544657\n",
      "0.1_20  0.150666  11.702395\n",
      "0.1_25  0.188356   9.451787\n",
      "...          ...        ...\n",
      "0.9_30  0.701188  14.307144\n",
      "0.9_35  0.673438  13.452328\n",
      "0.9_40  0.624604  16.647160\n",
      "0.9_5   0.643024   5.224512\n",
      "0.9_7   0.754408   7.060027\n",
      "\n",
      "[99 rows x 2 columns],            alpha       beta\n",
      "0.1_1   0.130077   1.612140\n",
      "0.1_10  0.130661   7.599150\n",
      "0.1_15  0.208461   7.207798\n",
      "0.1_20  0.189183  14.136134\n",
      "0.1_25  0.129037  21.153779\n",
      "...          ...        ...\n",
      "0.9_30  0.732915   8.911907\n",
      "0.9_35  0.718873  10.569937\n",
      "0.9_40  0.729210  10.950582\n",
      "0.9_5   0.807218   6.219978\n",
      "0.9_7   0.891059   5.754382\n",
      "\n",
      "[99 rows x 2 columns],            alpha       beta\n",
      "0.1_1   0.162174   1.172156\n",
      "0.1_10  0.204168   6.287862\n",
      "0.1_15  0.157801   8.235208\n",
      "0.1_20  0.159093   9.358544\n",
      "0.1_25  0.200389  10.231783\n",
      "...          ...        ...\n",
      "0.9_30  0.725951  10.317713\n",
      "0.9_35  0.660240  15.611819\n",
      "0.9_40  0.652186  14.676605\n",
      "0.9_5   0.657015  12.547298\n",
      "0.9_7   0.763138   6.796246\n",
      "\n",
      "[99 rows x 2 columns],            alpha       beta\n",
      "0.1_1   0.436290   1.086780\n",
      "0.1_10  0.144516   6.119914\n",
      "0.1_15  0.192005   9.914875\n",
      "0.1_20  0.251626   6.910995\n",
      "0.1_25  0.184864   9.537769\n",
      "...          ...        ...\n",
      "0.9_30  0.719804   9.986772\n",
      "0.9_35  0.669849   9.161634\n",
      "0.9_40  0.396559  17.532266\n",
      "0.9_5   0.709864   5.612096\n",
      "0.9_7   0.860129   6.107636\n",
      "\n",
      "[99 rows x 2 columns],            alpha       beta\n",
      "0.1_1   0.409424   0.754558\n",
      "0.1_10  0.095220   9.402749\n",
      "0.1_15  0.180840   8.412343\n",
      "0.1_20  0.278907   7.313645\n",
      "0.1_25  0.116116  26.413593\n",
      "...          ...        ...\n",
      "0.9_30  0.596923   8.581442\n",
      "0.9_35  0.670169  11.739253\n",
      "0.9_40  0.655346   9.439028\n",
      "0.9_5   0.862670   4.280024\n",
      "0.9_7   0.810314   6.983453\n",
      "\n",
      "[99 rows x 2 columns],            alpha       beta\n",
      "0.1_1   0.140538   0.900120\n",
      "0.1_10  0.140851   6.979158\n",
      "0.1_15  0.136204  10.222766\n",
      "0.1_20  0.150209  12.522633\n",
      "0.1_25  0.175806  13.288097\n",
      "...          ...        ...\n",
      "0.9_30  0.464904   8.258348\n",
      "0.9_35  0.713891  13.007857\n",
      "0.9_40  0.726802  10.460793\n",
      "0.9_5   0.864311   6.088383\n",
      "0.9_7   0.868098   5.733441\n",
      "\n",
      "[99 rows x 2 columns],            alpha       beta\n",
      "0.1_1   0.355368   1.627052\n",
      "0.1_10  0.182007   9.083208\n",
      "0.1_15  0.269728   8.206500\n",
      "0.1_20  0.149102  12.757778\n",
      "0.1_25  0.311805   7.907584\n",
      "...          ...        ...\n",
      "0.9_30  0.734499  12.871839\n",
      "0.9_35  0.780036  15.893689\n",
      "0.9_40  0.427678  14.466018\n",
      "0.9_5   0.480816   6.148705\n",
      "0.9_7   0.737384   8.421348\n",
      "\n",
      "[99 rows x 2 columns],            alpha       beta\n",
      "0.1_1   0.459771   0.878825\n",
      "0.1_10  0.113315   7.087900\n",
      "0.1_15  0.117464  12.312946\n",
      "0.1_20  0.134356  15.465659\n",
      "0.1_25  0.249153   8.287985\n",
      "...          ...        ...\n",
      "0.9_30  0.710455  14.831550\n",
      "0.9_35  0.721691  11.421579\n",
      "0.9_40  0.724937  14.632359\n",
      "0.9_5   0.823156   7.343327\n",
      "0.9_7   0.831895   6.772682\n",
      "\n",
      "[99 rows x 2 columns]]\n",
      "25742.907636880875\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "from joblib import Parallel, delayed\n",
    "\n",
    "\n",
    "\n",
    "t = time.time()\n",
    "results = Parallel(n_jobs=3)(delayed(simulate_model_experiment)() for _ in range(100))\n",
    "print(results)\n",
    "print(time.time() - t)\n",
    "# takes ~6.3 seconds on medium sized Macbook Pro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "(sum(results)/100).to_csv('simulated_model_experiment_df.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df = (sum(results)/100)\n",
    "results_df.rename(columns={'alpha': 'estimated_alpha', 'beta': 'estimated_beta'}, inplace=True)\n",
    "\n",
    "results_df = results_df.reset_index()\n",
    "\n",
    "results_df['actual_alpha'] = results_df['index'].apply(lambda x: float(x.split('_')[0]))\n",
    "results_df['actual_beta'] = results_df['index'].apply(lambda x: int(x.split('_')[1]))\n",
    "\n",
    "results_df.drop(columns=['index'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>estimated_alpha</th>\n",
       "      <th>estimated_beta</th>\n",
       "      <th>actual_alpha</th>\n",
       "      <th>actual_beta</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.295337</td>\n",
       "      <td>1.132798</td>\n",
       "      <td>0.1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.189836</td>\n",
       "      <td>2.441995</td>\n",
       "      <td>0.1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.154572</td>\n",
       "      <td>4.307274</td>\n",
       "      <td>0.1</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.148389</td>\n",
       "      <td>5.987985</td>\n",
       "      <td>0.1</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.160604</td>\n",
       "      <td>7.556244</td>\n",
       "      <td>0.1</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>0.684454</td>\n",
       "      <td>9.588529</td>\n",
       "      <td>0.9</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>0.677268</td>\n",
       "      <td>10.544107</td>\n",
       "      <td>0.9</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>0.649846</td>\n",
       "      <td>11.727932</td>\n",
       "      <td>0.9</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>0.639310</td>\n",
       "      <td>13.094680</td>\n",
       "      <td>0.9</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>0.645319</td>\n",
       "      <td>14.289724</td>\n",
       "      <td>0.9</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>99 rows  4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    estimated_alpha  estimated_beta  actual_alpha  actual_beta\n",
       "0          0.295337        1.132798           0.1            1\n",
       "5          0.189836        2.441995           0.1            3\n",
       "9          0.154572        4.307274           0.1            5\n",
       "10         0.148389        5.987985           0.1            7\n",
       "1          0.160604        7.556244           0.1           10\n",
       "..              ...             ...           ...          ...\n",
       "91         0.684454        9.588529           0.9           20\n",
       "92         0.677268       10.544107           0.9           25\n",
       "94         0.649846       11.727932           0.9           30\n",
       "95         0.639310       13.094680           0.9           35\n",
       "96         0.645319       14.289724           0.9           40\n",
       "\n",
       "[99 rows x 4 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df.sort_values(['actual_alpha', 'actual_beta'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "actual_alpha\n",
       "0.1    0.188415\n",
       "0.2    0.262891\n",
       "0.3    0.338917\n",
       "0.4    0.410245\n",
       "0.5    0.464666\n",
       "0.6    0.515153\n",
       "0.7    0.572149\n",
       "0.8    0.633270\n",
       "0.9    0.695493\n",
       "dtype: float64"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.pivot_table(results_df, values='estimated_alpha', index=['actual_alpha'], columns=['actual_beta']).mean(axis=1)\n",
    "# .to_csv('simulation_result_pivot_table_alpha.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "actual_beta\n",
       "1      1.298195\n",
       "3      3.237836\n",
       "5      5.548156\n",
       "7      7.806845\n",
       "10    10.469252\n",
       "15    14.283636\n",
       "20    17.001998\n",
       "25    19.190068\n",
       "30    21.142208\n",
       "35    22.682396\n",
       "40    23.679154\n",
       "dtype: float64"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.pivot_table(results_df, values='estimated_beta', index=['actual_alpha'], columns=['actual_beta']).mean()\n",
    "# .to_csv('simulation_result_pivot_table_beta.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "b0fa6594d8f4cbf19f97940f81e996739fb7646882a419484c72d19e05852a7e"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
